{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 予測モデルを構築する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_date</th>\n",
       "      <th>Local Code</th>\n",
       "      <th>log_R</th>\n",
       "      <th>return_5</th>\n",
       "      <th>return_25</th>\n",
       "      <th>return_75</th>\n",
       "      <th>HV_5</th>\n",
       "      <th>HV_25</th>\n",
       "      <th>HV_75</th>\n",
       "      <th>MADR5</th>\n",
       "      <th>MADR25</th>\n",
       "      <th>MADR75</th>\n",
       "      <th>MXDR5</th>\n",
       "      <th>MXDR10</th>\n",
       "      <th>MXDR20</th>\n",
       "      <th>MNDR5</th>\n",
       "      <th>MNDR10</th>\n",
       "      <th>MNDR20</th>\n",
       "      <th>RNDR</th>\n",
       "      <th>RSI</th>\n",
       "      <th>OperatingIncome_NetSales</th>\n",
       "      <th>OrdinaryIncome_NetSales</th>\n",
       "      <th>NetIncome_NetSales</th>\n",
       "      <th>NetSales_Growth</th>\n",
       "      <th>OperatingIncome_Growth</th>\n",
       "      <th>OrdinaryIncome_Growth</th>\n",
       "      <th>NetIncome_Growth</th>\n",
       "      <th>Forecast_NetSales_Growth</th>\n",
       "      <th>Forecast_OperatingIncome_Growth</th>\n",
       "      <th>Forecast_OrdinaryIncome_Growth</th>\n",
       "      <th>Forecast_NetIncome_Growth</th>\n",
       "      <th>Capital_Ratio</th>\n",
       "      <th>ROE</th>\n",
       "      <th>ROA</th>\n",
       "      <th>CF_Operating_pn</th>\n",
       "      <th>CF_Financing_pn</th>\n",
       "      <th>CF_Investing_pn</th>\n",
       "      <th>Dividend_Yeild</th>\n",
       "      <th>label_date_5</th>\n",
       "      <th>label_high_5</th>\n",
       "      <th>label_low_5</th>\n",
       "      <th>label_date_10</th>\n",
       "      <th>label_high_10</th>\n",
       "      <th>label_low_10</th>\n",
       "      <th>label_date_20</th>\n",
       "      <th>label_high_20</th>\n",
       "      <th>label_low_20</th>\n",
       "      <th>high_low_5</th>\n",
       "      <th>high_low_10</th>\n",
       "      <th>high_low_20</th>\n",
       "      <th>center_5</th>\n",
       "      <th>center_10</th>\n",
       "      <th>center_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-05-09</td>\n",
       "      <td>1301</td>\n",
       "      <td>0.011556</td>\n",
       "      <td>-0.003817</td>\n",
       "      <td>-0.003817</td>\n",
       "      <td>-0.015094</td>\n",
       "      <td>0.014385</td>\n",
       "      <td>0.020458</td>\n",
       "      <td>0.019105</td>\n",
       "      <td>0.006168</td>\n",
       "      <td>0.004155</td>\n",
       "      <td>-0.009914</td>\n",
       "      <td>-0.003759</td>\n",
       "      <td>-0.014870</td>\n",
       "      <td>-0.014870</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.023715</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.010736</td>\n",
       "      <td>0.012417</td>\n",
       "      <td>0.007938</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.483731</td>\n",
       "      <td>-0.424579</td>\n",
       "      <td>-0.538024</td>\n",
       "      <td>-0.555309</td>\n",
       "      <td>0.243795</td>\n",
       "      <td>0.077997</td>\n",
       "      <td>0.019015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>2016-05-16</td>\n",
       "      <td>0.01533</td>\n",
       "      <td>-0.01149</td>\n",
       "      <td>2016-05-23</td>\n",
       "      <td>0.02299</td>\n",
       "      <td>-0.01149</td>\n",
       "      <td>2016-06-06</td>\n",
       "      <td>0.03448</td>\n",
       "      <td>-0.01149</td>\n",
       "      <td>0.02682</td>\n",
       "      <td>0.03448</td>\n",
       "      <td>0.04597</td>\n",
       "      <td>0.001920</td>\n",
       "      <td>0.005750</td>\n",
       "      <td>0.011495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-08-05</td>\n",
       "      <td>1301</td>\n",
       "      <td>-0.003837</td>\n",
       "      <td>-0.018868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.007634</td>\n",
       "      <td>0.010664</td>\n",
       "      <td>0.015279</td>\n",
       "      <td>0.015602</td>\n",
       "      <td>-0.006116</td>\n",
       "      <td>-0.010956</td>\n",
       "      <td>-0.012408</td>\n",
       "      <td>-0.011321</td>\n",
       "      <td>-0.015038</td>\n",
       "      <td>-0.015038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007782</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.008945</td>\n",
       "      <td>0.007279</td>\n",
       "      <td>0.010554</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.241122</td>\n",
       "      <td>1.997859</td>\n",
       "      <td>2.421053</td>\n",
       "      <td>0.451906</td>\n",
       "      <td>0.226257</td>\n",
       "      <td>0.023962</td>\n",
       "      <td>0.005422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>2016-08-15</td>\n",
       "      <td>0.02692</td>\n",
       "      <td>0.00385</td>\n",
       "      <td>2016-08-22</td>\n",
       "      <td>0.02692</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2016-09-05</td>\n",
       "      <td>0.02692</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.02307</td>\n",
       "      <td>0.02692</td>\n",
       "      <td>0.02692</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.013460</td>\n",
       "      <td>0.013460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-11-04</td>\n",
       "      <td>1301</td>\n",
       "      <td>-0.023082</td>\n",
       "      <td>-0.025298</td>\n",
       "      <td>-0.013533</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.009818</td>\n",
       "      <td>0.009007</td>\n",
       "      <td>0.010838</td>\n",
       "      <td>-0.019130</td>\n",
       "      <td>-0.019815</td>\n",
       "      <td>0.004634</td>\n",
       "      <td>-0.003242</td>\n",
       "      <td>-0.004676</td>\n",
       "      <td>-0.006463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001111</td>\n",
       "      <td>0.354430</td>\n",
       "      <td>0.010687</td>\n",
       "      <td>0.009163</td>\n",
       "      <td>0.010824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.226887</td>\n",
       "      <td>1.988898</td>\n",
       "      <td>2.286853</td>\n",
       "      <td>0.770658</td>\n",
       "      <td>0.221484</td>\n",
       "      <td>0.050254</td>\n",
       "      <td>0.011131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001854</td>\n",
       "      <td>2016-11-11</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.03967</td>\n",
       "      <td>2016-11-18</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.03967</td>\n",
       "      <td>2016-12-05</td>\n",
       "      <td>0.00779</td>\n",
       "      <td>-0.03967</td>\n",
       "      <td>0.03967</td>\n",
       "      <td>0.03967</td>\n",
       "      <td>0.04746</td>\n",
       "      <td>-0.019835</td>\n",
       "      <td>-0.019835</td>\n",
       "      <td>-0.015940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-02-17</td>\n",
       "      <td>1301</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.029508</td>\n",
       "      <td>0.038207</td>\n",
       "      <td>0.021323</td>\n",
       "      <td>0.007324</td>\n",
       "      <td>0.007095</td>\n",
       "      <td>0.008334</td>\n",
       "      <td>0.005122</td>\n",
       "      <td>0.030920</td>\n",
       "      <td>0.041907</td>\n",
       "      <td>-0.002816</td>\n",
       "      <td>-0.002816</td>\n",
       "      <td>-0.002816</td>\n",
       "      <td>0.019956</td>\n",
       "      <td>0.034216</td>\n",
       "      <td>0.036504</td>\n",
       "      <td>0.009286</td>\n",
       "      <td>0.815068</td>\n",
       "      <td>0.015958</td>\n",
       "      <td>0.015708</td>\n",
       "      <td>0.013607</td>\n",
       "      <td>0.006065</td>\n",
       "      <td>0.164167</td>\n",
       "      <td>0.051711</td>\n",
       "      <td>1.161518</td>\n",
       "      <td>0.355744</td>\n",
       "      <td>0.218663</td>\n",
       "      <td>0.167315</td>\n",
       "      <td>-0.142507</td>\n",
       "      <td>0.220017</td>\n",
       "      <td>0.095000</td>\n",
       "      <td>0.020902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001769</td>\n",
       "      <td>2017-02-24</td>\n",
       "      <td>0.04246</td>\n",
       "      <td>0.00177</td>\n",
       "      <td>2017-03-03</td>\n",
       "      <td>0.07749</td>\n",
       "      <td>0.00177</td>\n",
       "      <td>2017-03-17</td>\n",
       "      <td>0.13588</td>\n",
       "      <td>0.00177</td>\n",
       "      <td>0.04069</td>\n",
       "      <td>0.07572</td>\n",
       "      <td>0.13411</td>\n",
       "      <td>0.022115</td>\n",
       "      <td>0.039630</td>\n",
       "      <td>0.068825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-05-11</td>\n",
       "      <td>1301</td>\n",
       "      <td>0.016579</td>\n",
       "      <td>0.035775</td>\n",
       "      <td>0.009967</td>\n",
       "      <td>0.110705</td>\n",
       "      <td>0.012836</td>\n",
       "      <td>0.012920</td>\n",
       "      <td>0.012303</td>\n",
       "      <td>0.018153</td>\n",
       "      <td>0.036481</td>\n",
       "      <td>0.035992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013988</td>\n",
       "      <td>0.022008</td>\n",
       "      <td>0.041710</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.015738</td>\n",
       "      <td>0.015679</td>\n",
       "      <td>0.010238</td>\n",
       "      <td>0.043839</td>\n",
       "      <td>0.530210</td>\n",
       "      <td>0.318053</td>\n",
       "      <td>0.346304</td>\n",
       "      <td>0.056810</td>\n",
       "      <td>0.074402</td>\n",
       "      <td>0.078458</td>\n",
       "      <td>0.114781</td>\n",
       "      <td>0.260712</td>\n",
       "      <td>0.095388</td>\n",
       "      <td>0.024869</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.019737</td>\n",
       "      <td>2017-05-18</td>\n",
       "      <td>0.01480</td>\n",
       "      <td>-0.02632</td>\n",
       "      <td>2017-05-25</td>\n",
       "      <td>0.04441</td>\n",
       "      <td>-0.02632</td>\n",
       "      <td>2017-06-08</td>\n",
       "      <td>0.04441</td>\n",
       "      <td>-0.02632</td>\n",
       "      <td>0.04112</td>\n",
       "      <td>0.07073</td>\n",
       "      <td>0.07073</td>\n",
       "      <td>-0.005760</td>\n",
       "      <td>0.009045</td>\n",
       "      <td>0.009045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   base_date  Local Code     log_R  return_5  return_25  return_75      HV_5  \\\n",
       "0 2016-05-09        1301  0.011556 -0.003817  -0.003817  -0.015094  0.014385   \n",
       "1 2016-08-05        1301 -0.003837 -0.018868   0.000000  -0.007634  0.010664   \n",
       "2 2016-11-04        1301 -0.023082 -0.025298  -0.013533   0.033333  0.009818   \n",
       "3 2017-02-17        1301  0.000354  0.029508   0.038207   0.021323  0.007324   \n",
       "4 2017-05-11        1301  0.016579  0.035775   0.009967   0.110705  0.012836   \n",
       "\n",
       "      HV_25     HV_75     MADR5    MADR25    MADR75     MXDR5    MXDR10  \\\n",
       "0  0.020458  0.019105  0.006168  0.004155 -0.009914 -0.003759 -0.014870   \n",
       "1  0.015279  0.015602 -0.006116 -0.010956 -0.012408 -0.011321 -0.015038   \n",
       "2  0.009007  0.010838 -0.019130 -0.019815  0.004634 -0.003242 -0.004676   \n",
       "3  0.007095  0.008334  0.005122  0.030920  0.041907 -0.002816 -0.002816   \n",
       "4  0.012920  0.012303  0.018153  0.036481  0.035992  0.000000  0.000000   \n",
       "\n",
       "     MXDR20     MNDR5    MNDR10    MNDR20      RNDR       RSI  \\\n",
       "0 -0.014870  0.015686  0.015686  0.023715  0.003846  0.526316   \n",
       "1 -0.015038  0.000000  0.000000  0.007782  0.000000  0.411765   \n",
       "2 -0.006463  0.000000  0.000000  0.000000 -0.001111  0.354430   \n",
       "3 -0.002816  0.019956  0.034216  0.036504  0.009286  0.815068   \n",
       "4  0.000000  0.013988  0.022008  0.041710  0.013333  0.777778   \n",
       "\n",
       "   OperatingIncome_NetSales  OrdinaryIncome_NetSales  NetIncome_NetSales  \\\n",
       "0                  0.010736                 0.012417            0.007938   \n",
       "1                  0.008945                 0.007279            0.010554   \n",
       "2                  0.010687                 0.009163            0.010824   \n",
       "3                  0.015958                 0.015708            0.013607   \n",
       "4                  0.015738                 0.015679            0.010238   \n",
       "\n",
       "   NetSales_Growth  OperatingIncome_Growth  OrdinaryIncome_Growth  \\\n",
       "0         0.000000                0.000000               0.000000   \n",
       "1         0.000000                0.000000               0.000000   \n",
       "2         0.000000                0.000000               0.000000   \n",
       "3         0.006065                0.164167               0.051711   \n",
       "4         0.043839                0.530210               0.318053   \n",
       "\n",
       "   NetIncome_Growth  Forecast_NetSales_Growth  \\\n",
       "0          0.000000                 -0.483731   \n",
       "1          0.000000                  1.241122   \n",
       "2          0.000000                  1.226887   \n",
       "3          1.161518                  0.355744   \n",
       "4          0.346304                  0.056810   \n",
       "\n",
       "   Forecast_OperatingIncome_Growth  Forecast_OrdinaryIncome_Growth  \\\n",
       "0                        -0.424579                       -0.538024   \n",
       "1                         1.997859                        2.421053   \n",
       "2                         1.988898                        2.286853   \n",
       "3                         0.218663                        0.167315   \n",
       "4                         0.074402                        0.078458   \n",
       "\n",
       "   Forecast_NetIncome_Growth  Capital_Ratio       ROE       ROA  \\\n",
       "0                  -0.555309       0.243795  0.077997  0.019015   \n",
       "1                   0.451906       0.226257  0.023962  0.005422   \n",
       "2                   0.770658       0.221484  0.050254  0.011131   \n",
       "3                  -0.142507       0.220017  0.095000  0.020902   \n",
       "4                   0.114781       0.260712  0.095388  0.024869   \n",
       "\n",
       "   CF_Operating_pn  CF_Financing_pn  CF_Investing_pn  Dividend_Yeild  \\\n",
       "0              1.0              1.0             -1.0        0.001916   \n",
       "1              0.0              0.0              0.0        0.001923   \n",
       "2              0.0              0.0              0.0        0.001854   \n",
       "3              0.0              0.0              0.0        0.001769   \n",
       "4              1.0              1.0             -1.0        0.019737   \n",
       "\n",
       "  label_date_5  label_high_5  label_low_5 label_date_10  label_high_10  \\\n",
       "0   2016-05-16       0.01533     -0.01149    2016-05-23        0.02299   \n",
       "1   2016-08-15       0.02692      0.00385    2016-08-22        0.02692   \n",
       "2   2016-11-11       0.00000     -0.03967    2016-11-18        0.00000   \n",
       "3   2017-02-24       0.04246      0.00177    2017-03-03        0.07749   \n",
       "4   2017-05-18       0.01480     -0.02632    2017-05-25        0.04441   \n",
       "\n",
       "   label_low_10 label_date_20  label_high_20  label_low_20  high_low_5  \\\n",
       "0      -0.01149    2016-06-06        0.03448      -0.01149     0.02682   \n",
       "1       0.00000    2016-09-05        0.02692       0.00000     0.02307   \n",
       "2      -0.03967    2016-12-05        0.00779      -0.03967     0.03967   \n",
       "3       0.00177    2017-03-17        0.13588       0.00177     0.04069   \n",
       "4      -0.02632    2017-06-08        0.04441      -0.02632     0.04112   \n",
       "\n",
       "   high_low_10  high_low_20  center_5  center_10  center_20  \n",
       "0      0.03448      0.04597  0.001920   0.005750   0.011495  \n",
       "1      0.02692      0.02692  0.015385   0.013460   0.013460  \n",
       "2      0.03967      0.04746 -0.019835  -0.019835  -0.015940  \n",
       "3      0.07572      0.13411  0.022115   0.039630   0.068825  \n",
       "4      0.07073      0.07073 -0.005760   0.009045   0.009045  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XY = pd.read_csv('../data/XY.csv')\n",
    "XY.base_date = pd.to_datetime(XY.base_date)\n",
    "XY.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "base_date                             0\n",
       "Local Code                            0\n",
       "log_R                                 0\n",
       "return_5                              0\n",
       "return_25                             0\n",
       "return_75                             0\n",
       "HV_5                                  0\n",
       "HV_25                                 0\n",
       "HV_75                                 0\n",
       "MADR5                                 0\n",
       "MADR25                                0\n",
       "MADR75                                0\n",
       "MXDR5                                 0\n",
       "MXDR10                                0\n",
       "MXDR20                                0\n",
       "MNDR5                                 0\n",
       "MNDR10                                0\n",
       "MNDR20                                0\n",
       "RNDR                                  0\n",
       "RSI                                   0\n",
       "OperatingIncome_NetSales           1992\n",
       "OrdinaryIncome_NetSales             126\n",
       "NetIncome_NetSales                   27\n",
       "NetSales_Growth                       0\n",
       "OperatingIncome_Growth                0\n",
       "OrdinaryIncome_Growth                 0\n",
       "NetIncome_Growth                      0\n",
       "Forecast_NetSales_Growth           5359\n",
       "Forecast_OperatingIncome_Growth    6515\n",
       "Forecast_OrdinaryIncome_Growth     5434\n",
       "Forecast_NetIncome_Growth          4717\n",
       "Capital_Ratio                         1\n",
       "ROE                                   4\n",
       "ROA                                   4\n",
       "CF_Operating_pn                       0\n",
       "CF_Financing_pn                       0\n",
       "CF_Investing_pn                       0\n",
       "Dividend_Yeild                      139\n",
       "label_date_5                         45\n",
       "label_high_5                         73\n",
       "label_low_5                          73\n",
       "label_date_10                        56\n",
       "label_high_10                        57\n",
       "label_low_10                         57\n",
       "label_date_20                       234\n",
       "label_high_20                       234\n",
       "label_low_20                        234\n",
       "high_low_5                           73\n",
       "high_low_10                          57\n",
       "high_low_20                         234\n",
       "center_5                             73\n",
       "center_10                            57\n",
       "center_20                           234\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XY.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null num; 0\n",
      "start: 2016-04-22 00:00:00  end: 2020-12-29 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Local Code</th>\n",
       "      <th>log_R</th>\n",
       "      <th>return_5</th>\n",
       "      <th>return_25</th>\n",
       "      <th>return_75</th>\n",
       "      <th>HV_5</th>\n",
       "      <th>HV_25</th>\n",
       "      <th>HV_75</th>\n",
       "      <th>MADR5</th>\n",
       "      <th>MADR25</th>\n",
       "      <th>MADR75</th>\n",
       "      <th>MXDR5</th>\n",
       "      <th>MXDR10</th>\n",
       "      <th>MXDR20</th>\n",
       "      <th>MNDR5</th>\n",
       "      <th>MNDR10</th>\n",
       "      <th>MNDR20</th>\n",
       "      <th>RNDR</th>\n",
       "      <th>RSI</th>\n",
       "      <th>OperatingIncome_NetSales</th>\n",
       "      <th>OrdinaryIncome_NetSales</th>\n",
       "      <th>NetIncome_NetSales</th>\n",
       "      <th>NetSales_Growth</th>\n",
       "      <th>OperatingIncome_Growth</th>\n",
       "      <th>OrdinaryIncome_Growth</th>\n",
       "      <th>NetIncome_Growth</th>\n",
       "      <th>Forecast_NetSales_Growth</th>\n",
       "      <th>Forecast_OperatingIncome_Growth</th>\n",
       "      <th>Forecast_OrdinaryIncome_Growth</th>\n",
       "      <th>Forecast_NetIncome_Growth</th>\n",
       "      <th>Capital_Ratio</th>\n",
       "      <th>ROE</th>\n",
       "      <th>ROA</th>\n",
       "      <th>CF_Operating_pn</th>\n",
       "      <th>CF_Financing_pn</th>\n",
       "      <th>CF_Investing_pn</th>\n",
       "      <th>Dividend_Yeild</th>\n",
       "      <th>label_high_5</th>\n",
       "      <th>label_low_5</th>\n",
       "      <th>label_high_10</th>\n",
       "      <th>label_low_10</th>\n",
       "      <th>label_high_20</th>\n",
       "      <th>label_low_20</th>\n",
       "      <th>high_low_5</th>\n",
       "      <th>high_low_10</th>\n",
       "      <th>high_low_20</th>\n",
       "      <th>center_5</th>\n",
       "      <th>center_10</th>\n",
       "      <th>center_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.00000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "      <td>64679.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5776.770822</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>0.020698</td>\n",
       "      <td>0.041783</td>\n",
       "      <td>0.030583</td>\n",
       "      <td>0.029787</td>\n",
       "      <td>0.032601</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>0.009483</td>\n",
       "      <td>0.013748</td>\n",
       "      <td>-0.017189</td>\n",
       "      <td>-0.029857</td>\n",
       "      <td>-0.045817</td>\n",
       "      <td>0.020929</td>\n",
       "      <td>0.036353</td>\n",
       "      <td>0.059796</td>\n",
       "      <td>0.002236</td>\n",
       "      <td>0.526674</td>\n",
       "      <td>-0.072047</td>\n",
       "      <td>-0.068704</td>\n",
       "      <td>-0.093042</td>\n",
       "      <td>0.042501</td>\n",
       "      <td>0.012128</td>\n",
       "      <td>-0.025987</td>\n",
       "      <td>-0.007796</td>\n",
       "      <td>0.775380</td>\n",
       "      <td>0.527790</td>\n",
       "      <td>0.609016</td>\n",
       "      <td>0.730927</td>\n",
       "      <td>0.527564</td>\n",
       "      <td>0.017978</td>\n",
       "      <td>0.016644</td>\n",
       "      <td>0.186614</td>\n",
       "      <td>-0.110855</td>\n",
       "      <td>-0.191561</td>\n",
       "      <td>0.010241</td>\n",
       "      <td>0.043496</td>\n",
       "      <td>-0.044861</td>\n",
       "      <td>0.060426</td>\n",
       "      <td>-0.055757</td>\n",
       "      <td>0.087227</td>\n",
       "      <td>-0.072753</td>\n",
       "      <td>0.088357</td>\n",
       "      <td>0.116183</td>\n",
       "      <td>0.15998</td>\n",
       "      <td>-0.000683</td>\n",
       "      <td>0.002334</td>\n",
       "      <td>0.007237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2388.143657</td>\n",
       "      <td>0.031940</td>\n",
       "      <td>0.058558</td>\n",
       "      <td>0.125821</td>\n",
       "      <td>0.250804</td>\n",
       "      <td>0.024327</td>\n",
       "      <td>0.018204</td>\n",
       "      <td>0.016936</td>\n",
       "      <td>0.030827</td>\n",
       "      <td>0.066215</td>\n",
       "      <td>0.109550</td>\n",
       "      <td>0.028321</td>\n",
       "      <td>0.042007</td>\n",
       "      <td>0.057527</td>\n",
       "      <td>0.033661</td>\n",
       "      <td>0.054543</td>\n",
       "      <td>0.085574</td>\n",
       "      <td>0.052172</td>\n",
       "      <td>0.168660</td>\n",
       "      <td>5.812668</td>\n",
       "      <td>5.889131</td>\n",
       "      <td>5.872480</td>\n",
       "      <td>0.476915</td>\n",
       "      <td>9.880387</td>\n",
       "      <td>8.633348</td>\n",
       "      <td>19.164059</td>\n",
       "      <td>2.197658</td>\n",
       "      <td>21.165324</td>\n",
       "      <td>16.083789</td>\n",
       "      <td>20.449841</td>\n",
       "      <td>0.216126</td>\n",
       "      <td>2.232606</td>\n",
       "      <td>0.066707</td>\n",
       "      <td>0.473445</td>\n",
       "      <td>0.495116</td>\n",
       "      <td>0.470743</td>\n",
       "      <td>0.013405</td>\n",
       "      <td>0.092342</td>\n",
       "      <td>0.065769</td>\n",
       "      <td>0.115402</td>\n",
       "      <td>0.072843</td>\n",
       "      <td>0.161456</td>\n",
       "      <td>0.090097</td>\n",
       "      <td>0.071076</td>\n",
       "      <td>0.098448</td>\n",
       "      <td>0.15177</td>\n",
       "      <td>0.071857</td>\n",
       "      <td>0.082999</td>\n",
       "      <td>0.106462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1301.000000</td>\n",
       "      <td>-0.405465</td>\n",
       "      <td>-0.559085</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>-0.792116</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.001584</td>\n",
       "      <td>-0.336934</td>\n",
       "      <td>-0.624353</td>\n",
       "      <td>-0.679285</td>\n",
       "      <td>-0.564162</td>\n",
       "      <td>-0.637681</td>\n",
       "      <td>-0.683424</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-843.000000</td>\n",
       "      <td>-841.000000</td>\n",
       "      <td>-837.000000</td>\n",
       "      <td>-76.142857</td>\n",
       "      <td>-342.750000</td>\n",
       "      <td>-576.312500</td>\n",
       "      <td>-1633.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-2726.000000</td>\n",
       "      <td>-1701.000000</td>\n",
       "      <td>-850.000000</td>\n",
       "      <td>-1.564972</td>\n",
       "      <td>-205.000000</td>\n",
       "      <td>-3.669746</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.272730</td>\n",
       "      <td>-0.578010</td>\n",
       "      <td>-0.272730</td>\n",
       "      <td>-0.588460</td>\n",
       "      <td>-0.272730</td>\n",
       "      <td>-0.720450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.379425</td>\n",
       "      <td>-0.407825</td>\n",
       "      <td>-0.477580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3681.000000</td>\n",
       "      <td>-0.011911</td>\n",
       "      <td>-0.021462</td>\n",
       "      <td>-0.039044</td>\n",
       "      <td>-0.081260</td>\n",
       "      <td>0.015183</td>\n",
       "      <td>0.017953</td>\n",
       "      <td>0.020823</td>\n",
       "      <td>-0.011466</td>\n",
       "      <td>-0.022128</td>\n",
       "      <td>-0.041813</td>\n",
       "      <td>-0.023639</td>\n",
       "      <td>-0.041777</td>\n",
       "      <td>-0.065538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000896</td>\n",
       "      <td>0.007002</td>\n",
       "      <td>-0.016667</td>\n",
       "      <td>0.411290</td>\n",
       "      <td>0.013728</td>\n",
       "      <td>0.018327</td>\n",
       "      <td>0.009891</td>\n",
       "      <td>-0.024291</td>\n",
       "      <td>-0.244403</td>\n",
       "      <td>-0.257507</td>\n",
       "      <td>-0.347088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.223517</td>\n",
       "      <td>-0.271665</td>\n",
       "      <td>-0.378381</td>\n",
       "      <td>0.376175</td>\n",
       "      <td>0.009916</td>\n",
       "      <td>0.003598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.075100</td>\n",
       "      <td>0.002830</td>\n",
       "      <td>-0.089170</td>\n",
       "      <td>0.009625</td>\n",
       "      <td>-0.108230</td>\n",
       "      <td>0.046350</td>\n",
       "      <td>0.060970</td>\n",
       "      <td>0.08153</td>\n",
       "      <td>-0.034223</td>\n",
       "      <td>-0.037485</td>\n",
       "      <td>-0.041788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6060.000000</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.003759</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>0.012155</td>\n",
       "      <td>0.024309</td>\n",
       "      <td>0.025390</td>\n",
       "      <td>0.028720</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>0.006979</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>-0.005747</td>\n",
       "      <td>-0.014993</td>\n",
       "      <td>-0.026723</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>0.021112</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.047216</td>\n",
       "      <td>0.052417</td>\n",
       "      <td>0.034347</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522491</td>\n",
       "      <td>0.248662</td>\n",
       "      <td>0.247465</td>\n",
       "      <td>0.202956</td>\n",
       "      <td>0.535857</td>\n",
       "      <td>0.034402</td>\n",
       "      <td>0.016580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007954</td>\n",
       "      <td>0.022520</td>\n",
       "      <td>-0.034780</td>\n",
       "      <td>0.032550</td>\n",
       "      <td>-0.043310</td>\n",
       "      <td>0.048600</td>\n",
       "      <td>-0.053950</td>\n",
       "      <td>0.071430</td>\n",
       "      <td>0.092720</td>\n",
       "      <td>0.12360</td>\n",
       "      <td>-0.004475</td>\n",
       "      <td>-0.003450</td>\n",
       "      <td>-0.000535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7806.000000</td>\n",
       "      <td>0.015084</td>\n",
       "      <td>0.030121</td>\n",
       "      <td>0.065574</td>\n",
       "      <td>0.120930</td>\n",
       "      <td>0.038325</td>\n",
       "      <td>0.036372</td>\n",
       "      <td>0.040435</td>\n",
       "      <td>0.015592</td>\n",
       "      <td>0.038365</td>\n",
       "      <td>0.058523</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004177</td>\n",
       "      <td>0.029381</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.081575</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.643678</td>\n",
       "      <td>0.090636</td>\n",
       "      <td>0.099860</td>\n",
       "      <td>0.069084</td>\n",
       "      <td>0.077408</td>\n",
       "      <td>0.179754</td>\n",
       "      <td>0.196724</td>\n",
       "      <td>0.217995</td>\n",
       "      <td>1.088084</td>\n",
       "      <td>1.008652</td>\n",
       "      <td>0.981506</td>\n",
       "      <td>0.941748</td>\n",
       "      <td>0.695980</td>\n",
       "      <td>0.071417</td>\n",
       "      <td>0.036491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015276</td>\n",
       "      <td>0.067700</td>\n",
       "      <td>-0.007385</td>\n",
       "      <td>0.088020</td>\n",
       "      <td>-0.012175</td>\n",
       "      <td>0.119050</td>\n",
       "      <td>-0.017605</td>\n",
       "      <td>0.109410</td>\n",
       "      <td>0.141100</td>\n",
       "      <td>0.19123</td>\n",
       "      <td>0.025278</td>\n",
       "      <td>0.031997</td>\n",
       "      <td>0.042950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9997.000000</td>\n",
       "      <td>0.371874</td>\n",
       "      <td>1.294574</td>\n",
       "      <td>7.423963</td>\n",
       "      <td>9.752941</td>\n",
       "      <td>0.553993</td>\n",
       "      <td>0.259735</td>\n",
       "      <td>0.190380</td>\n",
       "      <td>0.424731</td>\n",
       "      <td>1.887739</td>\n",
       "      <td>4.088520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.084615</td>\n",
       "      <td>3.403993</td>\n",
       "      <td>4.172414</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>33.142857</td>\n",
       "      <td>29.857143</td>\n",
       "      <td>29.857143</td>\n",
       "      <td>28.428571</td>\n",
       "      <td>1288.000000</td>\n",
       "      <td>558.666667</td>\n",
       "      <td>2190.000000</td>\n",
       "      <td>388.830508</td>\n",
       "      <td>1499.000000</td>\n",
       "      <td>1013.285714</td>\n",
       "      <td>1799.000000</td>\n",
       "      <td>0.993121</td>\n",
       "      <td>438.142857</td>\n",
       "      <td>1.441441</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.215768</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>0.365300</td>\n",
       "      <td>3.150940</td>\n",
       "      <td>0.365300</td>\n",
       "      <td>6.324220</td>\n",
       "      <td>0.365300</td>\n",
       "      <td>2.180560</td>\n",
       "      <td>3.072320</td>\n",
       "      <td>6.34180</td>\n",
       "      <td>1.159720</td>\n",
       "      <td>1.614780</td>\n",
       "      <td>3.153320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Local Code         log_R      return_5     return_25     return_75  \\\n",
       "count  64679.000000  64679.000000  64679.000000  64679.000000  64679.000000   \n",
       "mean    5776.770822      0.001912      0.005493      0.020698      0.041783   \n",
       "std     2388.143657      0.031940      0.058558      0.125821      0.250804   \n",
       "min     1301.000000     -0.405465     -0.559085     -0.700000     -0.792116   \n",
       "25%     3681.000000     -0.011911     -0.021462     -0.039044     -0.081260   \n",
       "50%     6060.000000      0.000388      0.003759      0.010714      0.012155   \n",
       "75%     7806.000000      0.015084      0.030121      0.065574      0.120930   \n",
       "max     9997.000000      0.371874      1.294574      7.423963      9.752941   \n",
       "\n",
       "               HV_5         HV_25         HV_75         MADR5        MADR25  \\\n",
       "count  64679.000000  64679.000000  64679.000000  64679.000000  64679.000000   \n",
       "mean       0.030583      0.029787      0.032601      0.002433      0.009483   \n",
       "std        0.024327      0.018204      0.016936      0.030827      0.066215   \n",
       "min        0.000000      0.000323      0.001584     -0.336934     -0.624353   \n",
       "25%        0.015183      0.017953      0.020823     -0.011466     -0.022128   \n",
       "50%        0.024309      0.025390      0.028720      0.001599      0.006979   \n",
       "75%        0.038325      0.036372      0.040435      0.015592      0.038365   \n",
       "max        0.553993      0.259735      0.190380      0.424731      1.887739   \n",
       "\n",
       "             MADR75         MXDR5        MXDR10        MXDR20         MNDR5  \\\n",
       "count  64679.000000  64679.000000  64679.000000  64679.000000  64679.000000   \n",
       "mean       0.013748     -0.017189     -0.029857     -0.045817      0.020929   \n",
       "std        0.109550      0.028321      0.042007      0.057527      0.033661   \n",
       "min       -0.679285     -0.564162     -0.637681     -0.683424      0.000000   \n",
       "25%       -0.041813     -0.023639     -0.041777     -0.065538      0.000000   \n",
       "50%        0.006494     -0.005747     -0.014993     -0.026723      0.009901   \n",
       "75%        0.058523      0.000000      0.000000     -0.004177      0.029381   \n",
       "max        4.088520      0.000000      0.000000      0.000000      1.084615   \n",
       "\n",
       "             MNDR10        MNDR20          RNDR           RSI  \\\n",
       "count  64679.000000  64679.000000  64679.000000  64679.000000   \n",
       "mean       0.036353      0.059796      0.002236      0.526674   \n",
       "std        0.054543      0.085574      0.052172      0.168660   \n",
       "min        0.000000      0.000000     -0.300000      0.000000   \n",
       "25%        0.000896      0.007002     -0.016667      0.411290   \n",
       "50%        0.021112      0.037736      0.000000      0.526316   \n",
       "75%        0.050000      0.081575      0.016667      0.643678   \n",
       "max        3.403993      4.172414      0.490000      1.000000   \n",
       "\n",
       "       OperatingIncome_NetSales  OrdinaryIncome_NetSales  NetIncome_NetSales  \\\n",
       "count              64679.000000             64679.000000        64679.000000   \n",
       "mean                  -0.072047                -0.068704           -0.093042   \n",
       "std                    5.812668                 5.889131            5.872480   \n",
       "min                 -843.000000              -841.000000         -837.000000   \n",
       "25%                    0.013728                 0.018327            0.009891   \n",
       "50%                    0.047216                 0.052417            0.034347   \n",
       "75%                    0.090636                 0.099860            0.069084   \n",
       "max                   33.142857                29.857143           29.857143   \n",
       "\n",
       "       NetSales_Growth  OperatingIncome_Growth  OrdinaryIncome_Growth  \\\n",
       "count     64679.000000            64679.000000           64679.000000   \n",
       "mean          0.042501                0.012128              -0.025987   \n",
       "std           0.476915                9.880387               8.633348   \n",
       "min         -76.142857             -342.750000            -576.312500   \n",
       "25%          -0.024291               -0.244403              -0.257507   \n",
       "50%           0.003008                0.000000               0.000000   \n",
       "75%           0.077408                0.179754               0.196724   \n",
       "max          28.428571             1288.000000             558.666667   \n",
       "\n",
       "       NetIncome_Growth  Forecast_NetSales_Growth  \\\n",
       "count      64679.000000              64679.000000   \n",
       "mean          -0.007796                  0.775380   \n",
       "std           19.164059                  2.197658   \n",
       "min        -1633.000000                 -1.000000   \n",
       "25%           -0.347088                  0.000000   \n",
       "50%            0.000000                  0.522491   \n",
       "75%            0.217995                  1.088084   \n",
       "max         2190.000000                388.830508   \n",
       "\n",
       "       Forecast_OperatingIncome_Growth  Forecast_OrdinaryIncome_Growth  \\\n",
       "count                     64679.000000                    64679.000000   \n",
       "mean                          0.527790                        0.609016   \n",
       "std                          21.165324                       16.083789   \n",
       "min                       -2726.000000                    -1701.000000   \n",
       "25%                          -0.223517                       -0.271665   \n",
       "50%                           0.248662                        0.247465   \n",
       "75%                           1.008652                        0.981506   \n",
       "max                        1499.000000                     1013.285714   \n",
       "\n",
       "       Forecast_NetIncome_Growth  Capital_Ratio           ROE           ROA  \\\n",
       "count               64679.000000   64679.000000  64679.000000  64679.000000   \n",
       "mean                    0.730927       0.527564      0.017978      0.016644   \n",
       "std                    20.449841       0.216126      2.232606      0.066707   \n",
       "min                  -850.000000      -1.564972   -205.000000     -3.669746   \n",
       "25%                    -0.378381       0.376175      0.009916      0.003598   \n",
       "50%                     0.202956       0.535857      0.034402      0.016580   \n",
       "75%                     0.941748       0.695980      0.071417      0.036491   \n",
       "max                  1799.000000       0.993121    438.142857      1.441441   \n",
       "\n",
       "       CF_Operating_pn  CF_Financing_pn  CF_Investing_pn  Dividend_Yeild  \\\n",
       "count     64679.000000     64679.000000     64679.000000    64679.000000   \n",
       "mean          0.186614        -0.110855        -0.191561        0.010241   \n",
       "std           0.473445         0.495116         0.470743        0.013405   \n",
       "min          -1.000000        -1.000000        -1.000000        0.000000   \n",
       "25%           0.000000         0.000000         0.000000        0.000000   \n",
       "50%           0.000000         0.000000         0.000000        0.007954   \n",
       "75%           0.000000         0.000000         0.000000        0.015276   \n",
       "max           1.000000         1.000000         1.000000        1.215768   \n",
       "\n",
       "       label_high_5   label_low_5  label_high_10  label_low_10  label_high_20  \\\n",
       "count  64679.000000  64679.000000   64679.000000  64679.000000   64679.000000   \n",
       "mean       0.043496     -0.044861       0.060426     -0.055757       0.087227   \n",
       "std        0.092342      0.065769       0.115402      0.072843       0.161456   \n",
       "min       -0.272730     -0.578010      -0.272730     -0.588460      -0.272730   \n",
       "25%        0.000000     -0.075100       0.002830     -0.089170       0.009625   \n",
       "50%        0.022520     -0.034780       0.032550     -0.043310       0.048600   \n",
       "75%        0.067700     -0.007385       0.088020     -0.012175       0.119050   \n",
       "max        2.250000      0.365300       3.150940      0.365300       6.324220   \n",
       "\n",
       "       label_low_20    high_low_5   high_low_10  high_low_20      center_5  \\\n",
       "count  64679.000000  64679.000000  64679.000000  64679.00000  64679.000000   \n",
       "mean      -0.072753      0.088357      0.116183      0.15998     -0.000683   \n",
       "std        0.090097      0.071076      0.098448      0.15177      0.071857   \n",
       "min       -0.720450      0.000000      0.000000      0.00000     -0.379425   \n",
       "25%       -0.108230      0.046350      0.060970      0.08153     -0.034223   \n",
       "50%       -0.053950      0.071430      0.092720      0.12360     -0.004475   \n",
       "75%       -0.017605      0.109410      0.141100      0.19123      0.025278   \n",
       "max        0.365300      2.180560      3.072320      6.34180      1.159720   \n",
       "\n",
       "          center_10     center_20  \n",
       "count  64679.000000  64679.000000  \n",
       "mean       0.002334      0.007237  \n",
       "std        0.082999      0.106462  \n",
       "min       -0.407825     -0.477580  \n",
       "25%       -0.037485     -0.041788  \n",
       "50%       -0.003450     -0.000535  \n",
       "75%        0.031997      0.042950  \n",
       "max        1.614780      3.153320  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 欠損値はゼロ埋め\n",
    "XY.fillna(0, inplace=True)\n",
    "print('null num;', XY.isnull().sum().sum())\n",
    "\n",
    "# 開始時点と終了時点\n",
    "print('start:', XY.base_date.min(), ' end:', XY.base_date.max())\n",
    "\n",
    "XY.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_date</th>\n",
       "      <th>Local Code</th>\n",
       "      <th>log_R</th>\n",
       "      <th>return_5</th>\n",
       "      <th>return_25</th>\n",
       "      <th>return_75</th>\n",
       "      <th>HV_5</th>\n",
       "      <th>HV_25</th>\n",
       "      <th>HV_75</th>\n",
       "      <th>MADR5</th>\n",
       "      <th>MADR25</th>\n",
       "      <th>MADR75</th>\n",
       "      <th>MXDR5</th>\n",
       "      <th>MXDR10</th>\n",
       "      <th>MXDR20</th>\n",
       "      <th>MNDR5</th>\n",
       "      <th>MNDR10</th>\n",
       "      <th>MNDR20</th>\n",
       "      <th>RNDR</th>\n",
       "      <th>RSI</th>\n",
       "      <th>OperatingIncome_NetSales</th>\n",
       "      <th>OrdinaryIncome_NetSales</th>\n",
       "      <th>NetIncome_NetSales</th>\n",
       "      <th>NetSales_Growth</th>\n",
       "      <th>OperatingIncome_Growth</th>\n",
       "      <th>OrdinaryIncome_Growth</th>\n",
       "      <th>NetIncome_Growth</th>\n",
       "      <th>Forecast_NetSales_Growth</th>\n",
       "      <th>Forecast_OperatingIncome_Growth</th>\n",
       "      <th>Forecast_OrdinaryIncome_Growth</th>\n",
       "      <th>Forecast_NetIncome_Growth</th>\n",
       "      <th>Capital_Ratio</th>\n",
       "      <th>ROE</th>\n",
       "      <th>ROA</th>\n",
       "      <th>CF_Operating_pn</th>\n",
       "      <th>CF_Financing_pn</th>\n",
       "      <th>CF_Investing_pn</th>\n",
       "      <th>Dividend_Yeild</th>\n",
       "      <th>label_date_5</th>\n",
       "      <th>label_high_5</th>\n",
       "      <th>label_low_5</th>\n",
       "      <th>label_date_10</th>\n",
       "      <th>label_high_10</th>\n",
       "      <th>label_low_10</th>\n",
       "      <th>label_date_20</th>\n",
       "      <th>label_high_20</th>\n",
       "      <th>label_low_20</th>\n",
       "      <th>high_low_5</th>\n",
       "      <th>high_low_10</th>\n",
       "      <th>high_low_20</th>\n",
       "      <th>center_5</th>\n",
       "      <th>center_10</th>\n",
       "      <th>center_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10570</th>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>3089</td>\n",
       "      <td>-0.011310</td>\n",
       "      <td>-0.053860</td>\n",
       "      <td>-0.005660</td>\n",
       "      <td>0.079918</td>\n",
       "      <td>0.060074</td>\n",
       "      <td>0.055101</td>\n",
       "      <td>0.034549</td>\n",
       "      <td>0.001711</td>\n",
       "      <td>-0.023785</td>\n",
       "      <td>-0.007284</td>\n",
       "      <td>-0.021838</td>\n",
       "      <td>-0.151539</td>\n",
       "      <td>-0.151539</td>\n",
       "      <td>0.028713</td>\n",
       "      <td>0.028713</td>\n",
       "      <td>0.030754</td>\n",
       "      <td>-0.041818</td>\n",
       "      <td>0.509677</td>\n",
       "      <td>-0.025762</td>\n",
       "      <td>-0.000859</td>\n",
       "      <td>-0.002147</td>\n",
       "      <td>-0.319404</td>\n",
       "      <td>-1.229008</td>\n",
       "      <td>-1.006667</td>\n",
       "      <td>-1.022321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.663590</td>\n",
       "      <td>-0.003477</td>\n",
       "      <td>-0.002307</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.023719</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63497</th>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>9872</td>\n",
       "      <td>0.030153</td>\n",
       "      <td>0.028313</td>\n",
       "      <td>-0.027837</td>\n",
       "      <td>-0.124397</td>\n",
       "      <td>0.021688</td>\n",
       "      <td>0.020078</td>\n",
       "      <td>0.029556</td>\n",
       "      <td>0.039139</td>\n",
       "      <td>0.017116</td>\n",
       "      <td>-0.086470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.044745</td>\n",
       "      <td>0.040094</td>\n",
       "      <td>0.040094</td>\n",
       "      <td>0.041322</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.009765</td>\n",
       "      <td>0.012109</td>\n",
       "      <td>0.012239</td>\n",
       "      <td>-0.049419</td>\n",
       "      <td>-0.358191</td>\n",
       "      <td>-0.302251</td>\n",
       "      <td>0.156415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.469392</td>\n",
       "      <td>0.055044</td>\n",
       "      <td>0.025837</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.027533</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7580</th>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>2685</td>\n",
       "      <td>-0.024915</td>\n",
       "      <td>-0.011677</td>\n",
       "      <td>0.021393</td>\n",
       "      <td>0.136059</td>\n",
       "      <td>0.034737</td>\n",
       "      <td>0.028394</td>\n",
       "      <td>0.034681</td>\n",
       "      <td>-0.023085</td>\n",
       "      <td>-0.000150</td>\n",
       "      <td>0.058524</td>\n",
       "      <td>-0.046278</td>\n",
       "      <td>-0.058590</td>\n",
       "      <td>-0.058590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052389</td>\n",
       "      <td>-0.020000</td>\n",
       "      <td>0.524249</td>\n",
       "      <td>0.008341</td>\n",
       "      <td>0.023458</td>\n",
       "      <td>0.009245</td>\n",
       "      <td>-0.191423</td>\n",
       "      <td>-0.907435</td>\n",
       "      <td>-0.737512</td>\n",
       "      <td>-0.822235</td>\n",
       "      <td>0.422839</td>\n",
       "      <td>-1.902527</td>\n",
       "      <td>-1.353017</td>\n",
       "      <td>-2.791531</td>\n",
       "      <td>0.529382</td>\n",
       "      <td>0.022697</td>\n",
       "      <td>0.012015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008056</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9528</th>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>2925</td>\n",
       "      <td>-0.025270</td>\n",
       "      <td>0.006441</td>\n",
       "      <td>0.048306</td>\n",
       "      <td>0.194115</td>\n",
       "      <td>0.042035</td>\n",
       "      <td>0.029357</td>\n",
       "      <td>0.032627</td>\n",
       "      <td>-0.021603</td>\n",
       "      <td>0.013058</td>\n",
       "      <td>0.044345</td>\n",
       "      <td>-0.015385</td>\n",
       "      <td>-0.015385</td>\n",
       "      <td>-0.016897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059625</td>\n",
       "      <td>0.071306</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>0.543353</td>\n",
       "      <td>0.065112</td>\n",
       "      <td>0.067697</td>\n",
       "      <td>0.045888</td>\n",
       "      <td>0.121172</td>\n",
       "      <td>0.457724</td>\n",
       "      <td>0.416518</td>\n",
       "      <td>0.399134</td>\n",
       "      <td>0.277828</td>\n",
       "      <td>0.090275</td>\n",
       "      <td>0.090604</td>\n",
       "      <td>0.113861</td>\n",
       "      <td>0.569744</td>\n",
       "      <td>0.111510</td>\n",
       "      <td>0.063532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47453</th>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>7649</td>\n",
       "      <td>0.013108</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>-0.004323</td>\n",
       "      <td>-0.064953</td>\n",
       "      <td>0.020539</td>\n",
       "      <td>0.018953</td>\n",
       "      <td>0.026546</td>\n",
       "      <td>-0.002310</td>\n",
       "      <td>-0.009404</td>\n",
       "      <td>-0.031544</td>\n",
       "      <td>-0.017021</td>\n",
       "      <td>-0.042818</td>\n",
       "      <td>-0.042818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.056754</td>\n",
       "      <td>0.058942</td>\n",
       "      <td>0.038825</td>\n",
       "      <td>0.120163</td>\n",
       "      <td>0.257526</td>\n",
       "      <td>0.228562</td>\n",
       "      <td>0.213610</td>\n",
       "      <td>0.345201</td>\n",
       "      <td>0.185115</td>\n",
       "      <td>0.198174</td>\n",
       "      <td>0.154934</td>\n",
       "      <td>0.621394</td>\n",
       "      <td>0.087803</td>\n",
       "      <td>0.054560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005789</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       base_date  Local Code     log_R  return_5  return_25  return_75  \\\n",
       "10570 2020-12-28        3089 -0.011310 -0.053860  -0.005660   0.079918   \n",
       "63497 2020-12-28        9872  0.030153  0.028313  -0.027837  -0.124397   \n",
       "7580  2020-12-29        2685 -0.024915 -0.011677   0.021393   0.136059   \n",
       "9528  2020-12-29        2925 -0.025270  0.006441   0.048306   0.194115   \n",
       "47453 2020-12-29        7649  0.013108  0.001449  -0.004323  -0.064953   \n",
       "\n",
       "           HV_5     HV_25     HV_75     MADR5    MADR25    MADR75     MXDR5  \\\n",
       "10570  0.060074  0.055101  0.034549  0.001711 -0.023785 -0.007284 -0.021838   \n",
       "63497  0.021688  0.020078  0.029556  0.039139  0.017116 -0.086470  0.000000   \n",
       "7580   0.034737  0.028394  0.034681 -0.023085 -0.000150  0.058524 -0.046278   \n",
       "9528   0.042035  0.029357  0.032627 -0.021603  0.013058  0.044345 -0.015385   \n",
       "47453  0.020539  0.018953  0.026546 -0.002310 -0.009404 -0.031544 -0.017021   \n",
       "\n",
       "         MXDR10    MXDR20     MNDR5    MNDR10    MNDR20      RNDR       RSI  \\\n",
       "10570 -0.151539 -0.151539  0.028713  0.028713  0.030754 -0.041818  0.509677   \n",
       "63497  0.000000 -0.044745  0.040094  0.040094  0.041322  0.008889  0.617647   \n",
       "7580  -0.058590 -0.058590  0.000000  0.000000  0.052389 -0.020000  0.524249   \n",
       "9528  -0.015385 -0.016897  0.000000  0.059625  0.071306  0.008065  0.543353   \n",
       "47453 -0.042818 -0.042818  0.000000  0.000000  0.000000  0.001449  0.481481   \n",
       "\n",
       "       OperatingIncome_NetSales  OrdinaryIncome_NetSales  NetIncome_NetSales  \\\n",
       "10570                 -0.025762                -0.000859           -0.002147   \n",
       "63497                  0.009765                 0.012109            0.012239   \n",
       "7580                   0.008341                 0.023458            0.009245   \n",
       "9528                   0.065112                 0.067697            0.045888   \n",
       "47453                  0.056754                 0.058942            0.038825   \n",
       "\n",
       "       NetSales_Growth  OperatingIncome_Growth  OrdinaryIncome_Growth  \\\n",
       "10570        -0.319404               -1.229008              -1.006667   \n",
       "63497        -0.049419               -0.358191              -0.302251   \n",
       "7580         -0.191423               -0.907435              -0.737512   \n",
       "9528          0.121172                0.457724               0.416518   \n",
       "47453         0.120163                0.257526               0.228562   \n",
       "\n",
       "       NetIncome_Growth  Forecast_NetSales_Growth  \\\n",
       "10570         -1.022321                  0.000000   \n",
       "63497          0.156415                  0.000000   \n",
       "7580          -0.822235                  0.422839   \n",
       "9528           0.399134                  0.277828   \n",
       "47453          0.213610                  0.345201   \n",
       "\n",
       "       Forecast_OperatingIncome_Growth  Forecast_OrdinaryIncome_Growth  \\\n",
       "10570                         0.000000                        0.000000   \n",
       "63497                         0.000000                        0.000000   \n",
       "7580                         -1.902527                       -1.353017   \n",
       "9528                          0.090275                        0.090604   \n",
       "47453                         0.185115                        0.198174   \n",
       "\n",
       "       Forecast_NetIncome_Growth  Capital_Ratio       ROE       ROA  \\\n",
       "10570                   0.000000       0.663590 -0.003477 -0.002307   \n",
       "63497                   0.000000       0.469392  0.055044  0.025837   \n",
       "7580                   -2.791531       0.529382  0.022697  0.012015   \n",
       "9528                    0.113861       0.569744  0.111510  0.063532   \n",
       "47453                   0.154934       0.621394  0.087803  0.054560   \n",
       "\n",
       "       CF_Operating_pn  CF_Financing_pn  CF_Investing_pn  Dividend_Yeild  \\\n",
       "10570              1.0              1.0              1.0        0.023719   \n",
       "63497              1.0             -1.0              1.0        0.027533   \n",
       "7580               0.0              0.0              0.0        0.008056   \n",
       "9528               0.0              0.0              0.0        0.000000   \n",
       "47453              0.0              0.0              0.0        0.005789   \n",
       "\n",
       "      label_date_5  label_high_5  label_low_5 label_date_10  label_high_10  \\\n",
       "10570            0           0.0          0.0             0            0.0   \n",
       "63497            0           0.0          0.0             0            0.0   \n",
       "7580             0           0.0          0.0             0            0.0   \n",
       "9528             0           0.0          0.0             0            0.0   \n",
       "47453            0           0.0          0.0             0            0.0   \n",
       "\n",
       "       label_low_10 label_date_20  label_high_20  label_low_20  high_low_5  \\\n",
       "10570           0.0             0            0.0           0.0         0.0   \n",
       "63497           0.0             0            0.0           0.0         0.0   \n",
       "7580            0.0             0            0.0           0.0         0.0   \n",
       "9528            0.0             0            0.0           0.0         0.0   \n",
       "47453           0.0             0            0.0           0.0         0.0   \n",
       "\n",
       "       high_low_10  high_low_20  center_5  center_10  center_20  \n",
       "10570          0.0          0.0       0.0        0.0        0.0  \n",
       "63497          0.0          0.0       0.0        0.0        0.0  \n",
       "7580           0.0          0.0       0.0        0.0        0.0  \n",
       "9528           0.0          0.0       0.0        0.0        0.0  \n",
       "47453          0.0          0.0       0.0        0.0        0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XY.sort_values('base_date').tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<メモ>\n",
    "* データの最大値・最小値を見ると全体的に問題なさそう。\n",
    "  一部、異常な値もあるように思われるが、成長率がかなり高い場合なども考えられるのでこのままのデータを利用するとする。  \n",
    "  (本来なら業界ごとにデータを分けたりしたほうが良いのかもしれない)  \n",
    "* データの最初と終了時点を見る限り、ラベルデータも適切な値となっているので問題なさそう。  \n",
    "  (終了時点はデータが無くて欠損値の穴埋めが行われていないかが気になった)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの分割期間の設定\n",
    "TRAIN_END = \"2017-11-30\"\n",
    "VAL_START = \"2018-01-01\"\n",
    "VAL_END = \"2018-12-01\"\n",
    "TEST_START = \"2019-01-01\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "サンプルを参考に、期間を若干変えたものに設定。評価期間を1年間としたかった。\n",
    "\n",
    "* 訓練期間：2016-01-01 - 2017-11-30※  \n",
    "* 評価期間：2018-01-01 - 2018-12-01  \n",
    "* テスト期間：2019-01-01 - 2020-12-31  \n",
    "\n",
    "※データの分割に際し、各期間に間隔（1か月）を空けている理由は、未来の情報を含ませないようにするため。  \n",
    "例えば、2017年11月30日の目的変数には5営業日、10営業日、20営業日後の株価リターンの情報が入っているため、  \n",
    "2017年11月30日のデータを使って学習したモデルは未来の情報（2017年12月のリターン）を知っていることになる。  \n",
    "  \n",
    "リーダーボードでは、2020年1月1日（水）〜2020年11月30日（月）の期間を対象としている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不要な列を削除\n",
    "XY.drop(['Local Code', 'label_date_5', 'label_date_10', 'label_date_20'], axis=1, inplace=True)\n",
    "\n",
    "# データを分割する\n",
    "XY.set_index('base_date', inplace=True)\n",
    "train_XY = XY.loc[:TRAIN_END]\n",
    "val_XY = XY.loc[VAL_START:VAL_END]\n",
    "test_XY = XY.loc[TEST_START:]\n",
    "\n",
    "# 説明変数と目的変数を分ける\n",
    "Y_cols = ['label_high_5', 'label_low_5', 'label_high_10', 'label_low_10', 'label_high_20', 'label_low_20', \n",
    "          'high_low_5', 'high_low_10', 'high_low_20', 'center_5', 'center_10', 'center_20']\n",
    "\n",
    "train_X = train_XY.drop(Y_cols, axis=1).copy()\n",
    "train_Y = train_XY.loc[:, Y_cols]\n",
    "val_X = val_XY.drop(Y_cols, axis=1).copy()\n",
    "val_Y = val_XY.loc[:, Y_cols]\n",
    "test_X = test_XY.drop(Y_cols, axis=1).copy()\n",
    "test_Y = test_XY.loc[:, Y_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの構築\n",
    "とりあえず、一般的な機械学習モデルから"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, median_absolute_error, r2_score, accuracy_score\n",
    "from scipy.stats import spearmanr\n",
    "import pickle, os\n",
    "\n",
    "SEED = 0\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# モデルの保存先\n",
    "save_dir = '../models/ML'\n",
    "\n",
    "# モデルを定義\n",
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'Ridge':Ridge(random_state=SEED),\n",
    "    'DecisionTreeRegressor':DecisionTreeRegressor(random_state=SEED),\n",
    "    #'LinearSVR':LinearSVR(random_state=SEED),\n",
    "    'Bagging':BaggingRegressor(random_state=SEED),\n",
    "    'AdaBoost':AdaBoostRegressor(random_state=SEED),\n",
    "    'RandomForest':RandomForestRegressor(random_state=SEED),\n",
    "    'GradientBoosting':GradientBoostingRegressor(random_state=SEED),\n",
    "    'LightGBM':LGBMRegressor(random_state=SEED),\n",
    "    'NeuralNetwork':MLPRegressor(random_state=SEED, hidden_layer_sizes=(128,128,128))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標準化処理\n",
    "sc = StandardScaler()\n",
    "sc.fit(train_X)\n",
    "train_X = sc.transform(train_X)\n",
    "val_X = sc.transform(val_X)\n",
    "test_X = sc.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "for model_name, model in models.items():\n",
    "    for label in Y_cols:\n",
    "        model.fit(train_X, train_Y[label])\n",
    "        scores[(label, model_name, 'MSE')] = mean_squared_error(val_Y[label], model.predict(val_X))\n",
    "        scores[(label, model_name, 'MAE')] = mean_absolute_error(val_Y[label], model.predict(val_X))\n",
    "        scores[(label, model_name, 'MedAE')] = median_absolute_error(val_Y[label], model.predict(val_X))\n",
    "        scores[(label, model_name, 'R2')] = r2_score(val_Y[label], model.predict(val_X))\n",
    "        scores[(label, model_name, 'Accuracy')] = accuracy_score(np.sign(val_Y[label]), np.sign(model.predict(val_X)))\n",
    "        scores[(label, model_name, 'Corr')] = np.corrcoef(val_Y[label], model.predict(val_X))[0, 1]\n",
    "        scores[(label, model_name, 'SpearmanCorr')] = spearmanr(val_Y[label], model.predict(val_X))[0]\n",
    "        \n",
    "        # save model\n",
    "        save_model_name = model_name + '_' + label + '.pickle'\n",
    "        save_path = os.path.join(save_dir, save_model_name)\n",
    "        with open(save_path, mode='wb') as fp:\n",
    "            pickle.dump(model, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Corr</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MedAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>SpearmanCorr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">center_10</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.420134</td>\n",
       "      <td>0.024308</td>\n",
       "      <td>0.137910</td>\n",
       "      <td>0.023743</td>\n",
       "      <td>0.132745</td>\n",
       "      <td>-2.506103</td>\n",
       "      <td>0.024630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.529157</td>\n",
       "      <td>0.142673</td>\n",
       "      <td>0.060803</td>\n",
       "      <td>0.007523</td>\n",
       "      <td>0.042488</td>\n",
       "      <td>-0.110913</td>\n",
       "      <td>0.132909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.514840</td>\n",
       "      <td>0.042630</td>\n",
       "      <td>0.082384</td>\n",
       "      <td>0.015517</td>\n",
       "      <td>0.055470</td>\n",
       "      <td>-1.291317</td>\n",
       "      <td>0.052611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.523117</td>\n",
       "      <td>0.182304</td>\n",
       "      <td>0.057013</td>\n",
       "      <td>0.006771</td>\n",
       "      <td>0.039317</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.187757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.545861</td>\n",
       "      <td>0.211869</td>\n",
       "      <td>0.056660</td>\n",
       "      <td>0.006695</td>\n",
       "      <td>0.039192</td>\n",
       "      <td>0.011337</td>\n",
       "      <td>0.205938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.473676</td>\n",
       "      <td>0.142694</td>\n",
       "      <td>0.057490</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>0.040137</td>\n",
       "      <td>-0.009502</td>\n",
       "      <td>0.107155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.521178</td>\n",
       "      <td>0.040402</td>\n",
       "      <td>0.060525</td>\n",
       "      <td>0.007945</td>\n",
       "      <td>0.041319</td>\n",
       "      <td>-0.173178</td>\n",
       "      <td>0.063202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.538404</td>\n",
       "      <td>0.215088</td>\n",
       "      <td>0.057601</td>\n",
       "      <td>0.006812</td>\n",
       "      <td>0.040249</td>\n",
       "      <td>-0.005902</td>\n",
       "      <td>0.203765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.473676</td>\n",
       "      <td>0.142691</td>\n",
       "      <td>0.057490</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>0.040137</td>\n",
       "      <td>-0.009503</td>\n",
       "      <td>0.107155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">center_20</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.422222</td>\n",
       "      <td>-0.043726</td>\n",
       "      <td>0.188177</td>\n",
       "      <td>0.052017</td>\n",
       "      <td>0.167179</td>\n",
       "      <td>-4.778048</td>\n",
       "      <td>-0.087202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.505369</td>\n",
       "      <td>0.124060</td>\n",
       "      <td>0.073593</td>\n",
       "      <td>0.011323</td>\n",
       "      <td>0.052272</td>\n",
       "      <td>-0.257751</td>\n",
       "      <td>0.120921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.506935</td>\n",
       "      <td>0.034175</td>\n",
       "      <td>0.099583</td>\n",
       "      <td>0.030483</td>\n",
       "      <td>0.063645</td>\n",
       "      <td>-2.386030</td>\n",
       "      <td>0.047454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.470619</td>\n",
       "      <td>0.129694</td>\n",
       "      <td>0.068047</td>\n",
       "      <td>0.009725</td>\n",
       "      <td>0.048773</td>\n",
       "      <td>-0.080281</td>\n",
       "      <td>0.141435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.501939</td>\n",
       "      <td>0.157070</td>\n",
       "      <td>0.067977</td>\n",
       "      <td>0.009661</td>\n",
       "      <td>0.048408</td>\n",
       "      <td>-0.073149</td>\n",
       "      <td>0.156370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.433855</td>\n",
       "      <td>0.117598</td>\n",
       "      <td>0.068197</td>\n",
       "      <td>0.009514</td>\n",
       "      <td>0.049734</td>\n",
       "      <td>-0.056841</td>\n",
       "      <td>0.073709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.480239</td>\n",
       "      <td>0.031122</td>\n",
       "      <td>0.085463</td>\n",
       "      <td>0.015097</td>\n",
       "      <td>0.060035</td>\n",
       "      <td>-0.676960</td>\n",
       "      <td>0.037134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.495600</td>\n",
       "      <td>0.168425</td>\n",
       "      <td>0.069705</td>\n",
       "      <td>0.009984</td>\n",
       "      <td>0.050305</td>\n",
       "      <td>-0.109001</td>\n",
       "      <td>0.169386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.433930</td>\n",
       "      <td>0.117602</td>\n",
       "      <td>0.068197</td>\n",
       "      <td>0.009514</td>\n",
       "      <td>0.049732</td>\n",
       "      <td>-0.056840</td>\n",
       "      <td>0.073695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">center_5</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.418121</td>\n",
       "      <td>0.050884</td>\n",
       "      <td>0.092301</td>\n",
       "      <td>0.011706</td>\n",
       "      <td>0.085299</td>\n",
       "      <td>-1.083084</td>\n",
       "      <td>0.061834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.552349</td>\n",
       "      <td>0.160580</td>\n",
       "      <td>0.053799</td>\n",
       "      <td>0.005928</td>\n",
       "      <td>0.037040</td>\n",
       "      <td>-0.054902</td>\n",
       "      <td>0.157430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.522222</td>\n",
       "      <td>0.059820</td>\n",
       "      <td>0.072053</td>\n",
       "      <td>0.010862</td>\n",
       "      <td>0.049425</td>\n",
       "      <td>-0.932837</td>\n",
       "      <td>0.066658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.564952</td>\n",
       "      <td>0.213276</td>\n",
       "      <td>0.050575</td>\n",
       "      <td>0.005436</td>\n",
       "      <td>0.034041</td>\n",
       "      <td>0.032634</td>\n",
       "      <td>0.206408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.575913</td>\n",
       "      <td>0.239190</td>\n",
       "      <td>0.050289</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>0.033998</td>\n",
       "      <td>0.045828</td>\n",
       "      <td>0.230815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.503952</td>\n",
       "      <td>0.120182</td>\n",
       "      <td>0.051432</td>\n",
       "      <td>0.005617</td>\n",
       "      <td>0.034597</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.101465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.543177</td>\n",
       "      <td>0.100149</td>\n",
       "      <td>0.052673</td>\n",
       "      <td>0.005917</td>\n",
       "      <td>0.035364</td>\n",
       "      <td>-0.052852</td>\n",
       "      <td>0.084550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.561372</td>\n",
       "      <td>0.217538</td>\n",
       "      <td>0.051010</td>\n",
       "      <td>0.005479</td>\n",
       "      <td>0.034763</td>\n",
       "      <td>0.025096</td>\n",
       "      <td>0.216564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.503952</td>\n",
       "      <td>0.120178</td>\n",
       "      <td>0.051432</td>\n",
       "      <td>0.005617</td>\n",
       "      <td>0.034598</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.101468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">high_low_10</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.999627</td>\n",
       "      <td>0.263731</td>\n",
       "      <td>0.287472</td>\n",
       "      <td>0.095012</td>\n",
       "      <td>0.287934</td>\n",
       "      <td>-12.359087</td>\n",
       "      <td>0.256781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.999627</td>\n",
       "      <td>0.473107</td>\n",
       "      <td>0.049735</td>\n",
       "      <td>0.006187</td>\n",
       "      <td>0.033184</td>\n",
       "      <td>0.130021</td>\n",
       "      <td>0.557675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.999329</td>\n",
       "      <td>0.279398</td>\n",
       "      <td>0.070124</td>\n",
       "      <td>0.015602</td>\n",
       "      <td>0.041750</td>\n",
       "      <td>-1.193737</td>\n",
       "      <td>0.400595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.999627</td>\n",
       "      <td>0.544686</td>\n",
       "      <td>0.043947</td>\n",
       "      <td>0.005150</td>\n",
       "      <td>0.029389</td>\n",
       "      <td>0.275831</td>\n",
       "      <td>0.627276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.999627</td>\n",
       "      <td>0.535395</td>\n",
       "      <td>0.045206</td>\n",
       "      <td>0.005226</td>\n",
       "      <td>0.030195</td>\n",
       "      <td>0.265179</td>\n",
       "      <td>0.614326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.999553</td>\n",
       "      <td>0.557353</td>\n",
       "      <td>0.044527</td>\n",
       "      <td>0.005110</td>\n",
       "      <td>0.029892</td>\n",
       "      <td>0.281580</td>\n",
       "      <td>0.592527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.991573</td>\n",
       "      <td>0.410532</td>\n",
       "      <td>0.054709</td>\n",
       "      <td>0.007554</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>-0.062193</td>\n",
       "      <td>0.479203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.999627</td>\n",
       "      <td>0.549571</td>\n",
       "      <td>0.045880</td>\n",
       "      <td>0.005102</td>\n",
       "      <td>0.031954</td>\n",
       "      <td>0.282604</td>\n",
       "      <td>0.608181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.999553</td>\n",
       "      <td>0.557355</td>\n",
       "      <td>0.044526</td>\n",
       "      <td>0.005109</td>\n",
       "      <td>0.029892</td>\n",
       "      <td>0.281585</td>\n",
       "      <td>0.592534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">high_low_20</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.318262</td>\n",
       "      <td>0.384869</td>\n",
       "      <td>0.175188</td>\n",
       "      <td>0.359848</td>\n",
       "      <td>-12.074703</td>\n",
       "      <td>0.347164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.408949</td>\n",
       "      <td>0.070104</td>\n",
       "      <td>0.014434</td>\n",
       "      <td>0.042751</td>\n",
       "      <td>-0.077274</td>\n",
       "      <td>0.561044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.219531</td>\n",
       "      <td>0.098577</td>\n",
       "      <td>0.040542</td>\n",
       "      <td>0.054965</td>\n",
       "      <td>-2.025705</td>\n",
       "      <td>0.379155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.491420</td>\n",
       "      <td>0.056553</td>\n",
       "      <td>0.010486</td>\n",
       "      <td>0.036619</td>\n",
       "      <td>0.217389</td>\n",
       "      <td>0.642803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.487026</td>\n",
       "      <td>0.058922</td>\n",
       "      <td>0.010610</td>\n",
       "      <td>0.037573</td>\n",
       "      <td>0.208125</td>\n",
       "      <td>0.616175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.519990</td>\n",
       "      <td>0.055974</td>\n",
       "      <td>0.009858</td>\n",
       "      <td>0.037580</td>\n",
       "      <td>0.264238</td>\n",
       "      <td>0.613436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.990306</td>\n",
       "      <td>0.343723</td>\n",
       "      <td>0.071632</td>\n",
       "      <td>0.015190</td>\n",
       "      <td>0.044098</td>\n",
       "      <td>-0.133639</td>\n",
       "      <td>0.450248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.494399</td>\n",
       "      <td>0.062270</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.040587</td>\n",
       "      <td>0.172270</td>\n",
       "      <td>0.614976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.519998</td>\n",
       "      <td>0.055973</td>\n",
       "      <td>0.009858</td>\n",
       "      <td>0.037578</td>\n",
       "      <td>0.264250</td>\n",
       "      <td>0.613447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">high_low_5</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.998658</td>\n",
       "      <td>0.366141</td>\n",
       "      <td>0.148689</td>\n",
       "      <td>0.025713</td>\n",
       "      <td>0.147549</td>\n",
       "      <td>-4.806153</td>\n",
       "      <td>0.377422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.998658</td>\n",
       "      <td>0.520054</td>\n",
       "      <td>0.038322</td>\n",
       "      <td>0.003369</td>\n",
       "      <td>0.026423</td>\n",
       "      <td>0.239323</td>\n",
       "      <td>0.556814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.996943</td>\n",
       "      <td>0.318502</td>\n",
       "      <td>0.052824</td>\n",
       "      <td>0.007192</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>-0.624011</td>\n",
       "      <td>0.389474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.998658</td>\n",
       "      <td>0.585767</td>\n",
       "      <td>0.034969</td>\n",
       "      <td>0.003029</td>\n",
       "      <td>0.023603</td>\n",
       "      <td>0.316111</td>\n",
       "      <td>0.623022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.998658</td>\n",
       "      <td>0.581828</td>\n",
       "      <td>0.035280</td>\n",
       "      <td>0.003021</td>\n",
       "      <td>0.023929</td>\n",
       "      <td>0.317764</td>\n",
       "      <td>0.615827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.998583</td>\n",
       "      <td>0.564813</td>\n",
       "      <td>0.036349</td>\n",
       "      <td>0.003251</td>\n",
       "      <td>0.024288</td>\n",
       "      <td>0.266019</td>\n",
       "      <td>0.582718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.996644</td>\n",
       "      <td>0.537861</td>\n",
       "      <td>0.038305</td>\n",
       "      <td>0.003421</td>\n",
       "      <td>0.025677</td>\n",
       "      <td>0.227415</td>\n",
       "      <td>0.568824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.998658</td>\n",
       "      <td>0.572924</td>\n",
       "      <td>0.035871</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.025223</td>\n",
       "      <td>0.321972</td>\n",
       "      <td>0.607117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.998583</td>\n",
       "      <td>0.564815</td>\n",
       "      <td>0.036349</td>\n",
       "      <td>0.003251</td>\n",
       "      <td>0.024288</td>\n",
       "      <td>0.266022</td>\n",
       "      <td>0.582723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">label_high_10</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.734228</td>\n",
       "      <td>0.095896</td>\n",
       "      <td>0.390636</td>\n",
       "      <td>0.164861</td>\n",
       "      <td>0.408918</td>\n",
       "      <td>-13.813186</td>\n",
       "      <td>0.092629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.731245</td>\n",
       "      <td>0.249367</td>\n",
       "      <td>0.074167</td>\n",
       "      <td>0.012336</td>\n",
       "      <td>0.049741</td>\n",
       "      <td>-0.108461</td>\n",
       "      <td>0.231632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.637062</td>\n",
       "      <td>0.143386</td>\n",
       "      <td>0.103763</td>\n",
       "      <td>0.031767</td>\n",
       "      <td>0.061110</td>\n",
       "      <td>-1.854325</td>\n",
       "      <td>0.104670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.734228</td>\n",
       "      <td>0.270128</td>\n",
       "      <td>0.067495</td>\n",
       "      <td>0.010773</td>\n",
       "      <td>0.045032</td>\n",
       "      <td>0.031977</td>\n",
       "      <td>0.281553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.733557</td>\n",
       "      <td>0.292331</td>\n",
       "      <td>0.067327</td>\n",
       "      <td>0.010517</td>\n",
       "      <td>0.044672</td>\n",
       "      <td>0.055023</td>\n",
       "      <td>0.285515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.733706</td>\n",
       "      <td>0.284786</td>\n",
       "      <td>0.066946</td>\n",
       "      <td>0.010279</td>\n",
       "      <td>0.044815</td>\n",
       "      <td>0.076416</td>\n",
       "      <td>0.216658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.685086</td>\n",
       "      <td>0.140748</td>\n",
       "      <td>0.082881</td>\n",
       "      <td>0.015665</td>\n",
       "      <td>0.054731</td>\n",
       "      <td>-0.407503</td>\n",
       "      <td>0.103992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.734452</td>\n",
       "      <td>0.310894</td>\n",
       "      <td>0.069915</td>\n",
       "      <td>0.010740</td>\n",
       "      <td>0.048766</td>\n",
       "      <td>0.035011</td>\n",
       "      <td>0.286244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.733706</td>\n",
       "      <td>0.284786</td>\n",
       "      <td>0.066946</td>\n",
       "      <td>0.010279</td>\n",
       "      <td>0.044813</td>\n",
       "      <td>0.076416</td>\n",
       "      <td>0.216656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">label_high_20</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.777256</td>\n",
       "      <td>0.031463</td>\n",
       "      <td>0.533647</td>\n",
       "      <td>0.358765</td>\n",
       "      <td>0.547722</td>\n",
       "      <td>-19.180045</td>\n",
       "      <td>0.009560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.776212</td>\n",
       "      <td>0.244077</td>\n",
       "      <td>0.096826</td>\n",
       "      <td>0.022327</td>\n",
       "      <td>0.065380</td>\n",
       "      <td>-0.255868</td>\n",
       "      <td>0.245048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.682103</td>\n",
       "      <td>0.116297</td>\n",
       "      <td>0.131615</td>\n",
       "      <td>0.060672</td>\n",
       "      <td>0.074005</td>\n",
       "      <td>-2.412704</td>\n",
       "      <td>0.124359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.777256</td>\n",
       "      <td>0.267705</td>\n",
       "      <td>0.084362</td>\n",
       "      <td>0.017709</td>\n",
       "      <td>0.059053</td>\n",
       "      <td>0.003885</td>\n",
       "      <td>0.282070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.777032</td>\n",
       "      <td>0.272255</td>\n",
       "      <td>0.085965</td>\n",
       "      <td>0.018097</td>\n",
       "      <td>0.058706</td>\n",
       "      <td>-0.017958</td>\n",
       "      <td>0.280592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.777032</td>\n",
       "      <td>0.279058</td>\n",
       "      <td>0.083948</td>\n",
       "      <td>0.016847</td>\n",
       "      <td>0.060103</td>\n",
       "      <td>0.052365</td>\n",
       "      <td>0.229728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.744146</td>\n",
       "      <td>0.110115</td>\n",
       "      <td>0.102953</td>\n",
       "      <td>0.027058</td>\n",
       "      <td>0.065840</td>\n",
       "      <td>-0.521957</td>\n",
       "      <td>0.107441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.777256</td>\n",
       "      <td>0.294539</td>\n",
       "      <td>0.091392</td>\n",
       "      <td>0.018920</td>\n",
       "      <td>0.065117</td>\n",
       "      <td>-0.064236</td>\n",
       "      <td>0.290375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.777032</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.083949</td>\n",
       "      <td>0.016847</td>\n",
       "      <td>0.060101</td>\n",
       "      <td>0.052372</td>\n",
       "      <td>0.229734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">label_high_5</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.698210</td>\n",
       "      <td>0.104913</td>\n",
       "      <td>0.197108</td>\n",
       "      <td>0.044630</td>\n",
       "      <td>0.205857</td>\n",
       "      <td>-4.427900</td>\n",
       "      <td>0.089399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.696048</td>\n",
       "      <td>0.246609</td>\n",
       "      <td>0.061397</td>\n",
       "      <td>0.008368</td>\n",
       "      <td>0.041222</td>\n",
       "      <td>-0.017769</td>\n",
       "      <td>0.233531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.599254</td>\n",
       "      <td>0.117590</td>\n",
       "      <td>0.083799</td>\n",
       "      <td>0.016827</td>\n",
       "      <td>0.053015</td>\n",
       "      <td>-1.046539</td>\n",
       "      <td>0.114258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.697390</td>\n",
       "      <td>0.301287</td>\n",
       "      <td>0.056971</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>0.037358</td>\n",
       "      <td>0.089160</td>\n",
       "      <td>0.281053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.698732</td>\n",
       "      <td>0.316480</td>\n",
       "      <td>0.056535</td>\n",
       "      <td>0.007415</td>\n",
       "      <td>0.037203</td>\n",
       "      <td>0.098165</td>\n",
       "      <td>0.296688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.697614</td>\n",
       "      <td>0.248769</td>\n",
       "      <td>0.057793</td>\n",
       "      <td>0.007715</td>\n",
       "      <td>0.037277</td>\n",
       "      <td>0.061650</td>\n",
       "      <td>0.186100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.653020</td>\n",
       "      <td>0.111492</td>\n",
       "      <td>0.063265</td>\n",
       "      <td>0.009516</td>\n",
       "      <td>0.040436</td>\n",
       "      <td>-0.157372</td>\n",
       "      <td>0.103417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.700969</td>\n",
       "      <td>0.318816</td>\n",
       "      <td>0.058133</td>\n",
       "      <td>0.007498</td>\n",
       "      <td>0.039366</td>\n",
       "      <td>0.088148</td>\n",
       "      <td>0.291807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.697614</td>\n",
       "      <td>0.248769</td>\n",
       "      <td>0.057793</td>\n",
       "      <td>0.007715</td>\n",
       "      <td>0.037274</td>\n",
       "      <td>0.061650</td>\n",
       "      <td>0.186101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">label_low_10</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.851380</td>\n",
       "      <td>0.255727</td>\n",
       "      <td>0.055023</td>\n",
       "      <td>0.005887</td>\n",
       "      <td>0.038198</td>\n",
       "      <td>0.014045</td>\n",
       "      <td>0.252602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.836987</td>\n",
       "      <td>0.235640</td>\n",
       "      <td>0.056193</td>\n",
       "      <td>0.006104</td>\n",
       "      <td>0.040099</td>\n",
       "      <td>-0.022414</td>\n",
       "      <td>0.237511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.716331</td>\n",
       "      <td>0.111224</td>\n",
       "      <td>0.073111</td>\n",
       "      <td>0.010037</td>\n",
       "      <td>0.053530</td>\n",
       "      <td>-0.681043</td>\n",
       "      <td>0.112186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.851007</td>\n",
       "      <td>0.303035</td>\n",
       "      <td>0.054244</td>\n",
       "      <td>0.005807</td>\n",
       "      <td>0.037537</td>\n",
       "      <td>0.027315</td>\n",
       "      <td>0.306749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.851380</td>\n",
       "      <td>0.324344</td>\n",
       "      <td>0.053743</td>\n",
       "      <td>0.005681</td>\n",
       "      <td>0.037099</td>\n",
       "      <td>0.048419</td>\n",
       "      <td>0.319544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.850932</td>\n",
       "      <td>0.285087</td>\n",
       "      <td>0.054961</td>\n",
       "      <td>0.005948</td>\n",
       "      <td>0.037519</td>\n",
       "      <td>0.003712</td>\n",
       "      <td>0.298701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.844370</td>\n",
       "      <td>0.205720</td>\n",
       "      <td>0.056041</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>0.039831</td>\n",
       "      <td>-0.023688</td>\n",
       "      <td>0.222281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.849963</td>\n",
       "      <td>0.313238</td>\n",
       "      <td>0.053807</td>\n",
       "      <td>0.005668</td>\n",
       "      <td>0.037649</td>\n",
       "      <td>0.050702</td>\n",
       "      <td>0.309306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.850932</td>\n",
       "      <td>0.285085</td>\n",
       "      <td>0.054961</td>\n",
       "      <td>0.005948</td>\n",
       "      <td>0.037519</td>\n",
       "      <td>0.003713</td>\n",
       "      <td>0.298701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">label_low_20</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.886950</td>\n",
       "      <td>0.250468</td>\n",
       "      <td>0.061071</td>\n",
       "      <td>0.007114</td>\n",
       "      <td>0.043295</td>\n",
       "      <td>-0.027033</td>\n",
       "      <td>0.266205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.875019</td>\n",
       "      <td>0.253723</td>\n",
       "      <td>0.061975</td>\n",
       "      <td>0.007227</td>\n",
       "      <td>0.044873</td>\n",
       "      <td>-0.043450</td>\n",
       "      <td>0.244284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.762192</td>\n",
       "      <td>0.120023</td>\n",
       "      <td>0.078882</td>\n",
       "      <td>0.011334</td>\n",
       "      <td>0.059125</td>\n",
       "      <td>-0.636399</td>\n",
       "      <td>0.114935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.887025</td>\n",
       "      <td>0.334142</td>\n",
       "      <td>0.059890</td>\n",
       "      <td>0.006905</td>\n",
       "      <td>0.042254</td>\n",
       "      <td>0.003065</td>\n",
       "      <td>0.340903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.887025</td>\n",
       "      <td>0.349974</td>\n",
       "      <td>0.059233</td>\n",
       "      <td>0.006719</td>\n",
       "      <td>0.042107</td>\n",
       "      <td>0.029984</td>\n",
       "      <td>0.345673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.886875</td>\n",
       "      <td>0.313163</td>\n",
       "      <td>0.060942</td>\n",
       "      <td>0.007110</td>\n",
       "      <td>0.043209</td>\n",
       "      <td>-0.026582</td>\n",
       "      <td>0.331691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.884340</td>\n",
       "      <td>0.243225</td>\n",
       "      <td>0.060560</td>\n",
       "      <td>0.006973</td>\n",
       "      <td>0.043623</td>\n",
       "      <td>-0.006738</td>\n",
       "      <td>0.250649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.886428</td>\n",
       "      <td>0.323396</td>\n",
       "      <td>0.059563</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>0.042107</td>\n",
       "      <td>0.019025</td>\n",
       "      <td>0.324515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.886875</td>\n",
       "      <td>0.313158</td>\n",
       "      <td>0.060942</td>\n",
       "      <td>0.007110</td>\n",
       "      <td>0.043214</td>\n",
       "      <td>-0.026585</td>\n",
       "      <td>0.331683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">label_low_5</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.816555</td>\n",
       "      <td>0.216448</td>\n",
       "      <td>0.050994</td>\n",
       "      <td>0.005175</td>\n",
       "      <td>0.034500</td>\n",
       "      <td>0.010857</td>\n",
       "      <td>0.230499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.799105</td>\n",
       "      <td>0.225233</td>\n",
       "      <td>0.051877</td>\n",
       "      <td>0.005259</td>\n",
       "      <td>0.036591</td>\n",
       "      <td>-0.005375</td>\n",
       "      <td>0.225451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.680537</td>\n",
       "      <td>0.115531</td>\n",
       "      <td>0.067557</td>\n",
       "      <td>0.008744</td>\n",
       "      <td>0.049270</td>\n",
       "      <td>-0.671439</td>\n",
       "      <td>0.125558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.816033</td>\n",
       "      <td>0.302126</td>\n",
       "      <td>0.049645</td>\n",
       "      <td>0.004951</td>\n",
       "      <td>0.033953</td>\n",
       "      <td>0.053560</td>\n",
       "      <td>0.303306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.817375</td>\n",
       "      <td>0.314652</td>\n",
       "      <td>0.049300</td>\n",
       "      <td>0.004863</td>\n",
       "      <td>0.033761</td>\n",
       "      <td>0.070326</td>\n",
       "      <td>0.310753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.816480</td>\n",
       "      <td>0.260549</td>\n",
       "      <td>0.050540</td>\n",
       "      <td>0.005145</td>\n",
       "      <td>0.034016</td>\n",
       "      <td>0.016543</td>\n",
       "      <td>0.263162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.804176</td>\n",
       "      <td>0.190012</td>\n",
       "      <td>0.051919</td>\n",
       "      <td>0.005354</td>\n",
       "      <td>0.036028</td>\n",
       "      <td>-0.023422</td>\n",
       "      <td>0.202159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.816555</td>\n",
       "      <td>0.303002</td>\n",
       "      <td>0.049504</td>\n",
       "      <td>0.004898</td>\n",
       "      <td>0.033997</td>\n",
       "      <td>0.063808</td>\n",
       "      <td>0.302008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.816480</td>\n",
       "      <td>0.260549</td>\n",
       "      <td>0.050540</td>\n",
       "      <td>0.005145</td>\n",
       "      <td>0.034018</td>\n",
       "      <td>0.016547</td>\n",
       "      <td>0.263167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Accuracy      Corr       MAE       MSE  \\\n",
       "center_10     AdaBoost               0.420134  0.024308  0.137910  0.023743   \n",
       "              Bagging                0.529157  0.142673  0.060803  0.007523   \n",
       "              DecisionTreeRegressor  0.514840  0.042630  0.082384  0.015517   \n",
       "              GradientBoosting       0.523117  0.182304  0.057013  0.006771   \n",
       "              LightGBM               0.545861  0.211869  0.056660  0.006695   \n",
       "              LinearRegression       0.473676  0.142694  0.057490  0.006836   \n",
       "              NeuralNetwork          0.521178  0.040402  0.060525  0.007945   \n",
       "              RandomForest           0.538404  0.215088  0.057601  0.006812   \n",
       "              Ridge                  0.473676  0.142691  0.057490  0.006836   \n",
       "center_20     AdaBoost               0.422222 -0.043726  0.188177  0.052017   \n",
       "              Bagging                0.505369  0.124060  0.073593  0.011323   \n",
       "              DecisionTreeRegressor  0.506935  0.034175  0.099583  0.030483   \n",
       "              GradientBoosting       0.470619  0.129694  0.068047  0.009725   \n",
       "              LightGBM               0.501939  0.157070  0.067977  0.009661   \n",
       "              LinearRegression       0.433855  0.117598  0.068197  0.009514   \n",
       "              NeuralNetwork          0.480239  0.031122  0.085463  0.015097   \n",
       "              RandomForest           0.495600  0.168425  0.069705  0.009984   \n",
       "              Ridge                  0.433930  0.117602  0.068197  0.009514   \n",
       "center_5      AdaBoost               0.418121  0.050884  0.092301  0.011706   \n",
       "              Bagging                0.552349  0.160580  0.053799  0.005928   \n",
       "              DecisionTreeRegressor  0.522222  0.059820  0.072053  0.010862   \n",
       "              GradientBoosting       0.564952  0.213276  0.050575  0.005436   \n",
       "              LightGBM               0.575913  0.239190  0.050289  0.005362   \n",
       "              LinearRegression       0.503952  0.120182  0.051432  0.005617   \n",
       "              NeuralNetwork          0.543177  0.100149  0.052673  0.005917   \n",
       "              RandomForest           0.561372  0.217538  0.051010  0.005479   \n",
       "              Ridge                  0.503952  0.120178  0.051432  0.005617   \n",
       "high_low_10   AdaBoost               0.999627  0.263731  0.287472  0.095012   \n",
       "              Bagging                0.999627  0.473107  0.049735  0.006187   \n",
       "              DecisionTreeRegressor  0.999329  0.279398  0.070124  0.015602   \n",
       "              GradientBoosting       0.999627  0.544686  0.043947  0.005150   \n",
       "              LightGBM               0.999627  0.535395  0.045206  0.005226   \n",
       "              LinearRegression       0.999553  0.557353  0.044527  0.005110   \n",
       "              NeuralNetwork          0.991573  0.410532  0.054709  0.007554   \n",
       "              RandomForest           0.999627  0.549571  0.045880  0.005102   \n",
       "              Ridge                  0.999553  0.557355  0.044526  0.005109   \n",
       "high_low_20   AdaBoost               1.000000  0.318262  0.384869  0.175188   \n",
       "              Bagging                1.000000  0.408949  0.070104  0.014434   \n",
       "              DecisionTreeRegressor  1.000000  0.219531  0.098577  0.040542   \n",
       "              GradientBoosting       1.000000  0.491420  0.056553  0.010486   \n",
       "              LightGBM               1.000000  0.487026  0.058922  0.010610   \n",
       "              LinearRegression       1.000000  0.519990  0.055974  0.009858   \n",
       "              NeuralNetwork          0.990306  0.343723  0.071632  0.015190   \n",
       "              RandomForest           1.000000  0.494399  0.062270  0.011091   \n",
       "              Ridge                  1.000000  0.519998  0.055973  0.009858   \n",
       "high_low_5    AdaBoost               0.998658  0.366141  0.148689  0.025713   \n",
       "              Bagging                0.998658  0.520054  0.038322  0.003369   \n",
       "              DecisionTreeRegressor  0.996943  0.318502  0.052824  0.007192   \n",
       "              GradientBoosting       0.998658  0.585767  0.034969  0.003029   \n",
       "              LightGBM               0.998658  0.581828  0.035280  0.003021   \n",
       "              LinearRegression       0.998583  0.564813  0.036349  0.003251   \n",
       "              NeuralNetwork          0.996644  0.537861  0.038305  0.003421   \n",
       "              RandomForest           0.998658  0.572924  0.035871  0.003003   \n",
       "              Ridge                  0.998583  0.564815  0.036349  0.003251   \n",
       "label_high_10 AdaBoost               0.734228  0.095896  0.390636  0.164861   \n",
       "              Bagging                0.731245  0.249367  0.074167  0.012336   \n",
       "              DecisionTreeRegressor  0.637062  0.143386  0.103763  0.031767   \n",
       "              GradientBoosting       0.734228  0.270128  0.067495  0.010773   \n",
       "              LightGBM               0.733557  0.292331  0.067327  0.010517   \n",
       "              LinearRegression       0.733706  0.284786  0.066946  0.010279   \n",
       "              NeuralNetwork          0.685086  0.140748  0.082881  0.015665   \n",
       "              RandomForest           0.734452  0.310894  0.069915  0.010740   \n",
       "              Ridge                  0.733706  0.284786  0.066946  0.010279   \n",
       "label_high_20 AdaBoost               0.777256  0.031463  0.533647  0.358765   \n",
       "              Bagging                0.776212  0.244077  0.096826  0.022327   \n",
       "              DecisionTreeRegressor  0.682103  0.116297  0.131615  0.060672   \n",
       "              GradientBoosting       0.777256  0.267705  0.084362  0.017709   \n",
       "              LightGBM               0.777032  0.272255  0.085965  0.018097   \n",
       "              LinearRegression       0.777032  0.279058  0.083948  0.016847   \n",
       "              NeuralNetwork          0.744146  0.110115  0.102953  0.027058   \n",
       "              RandomForest           0.777256  0.294539  0.091392  0.018920   \n",
       "              Ridge                  0.777032  0.279070  0.083949  0.016847   \n",
       "label_high_5  AdaBoost               0.698210  0.104913  0.197108  0.044630   \n",
       "              Bagging                0.696048  0.246609  0.061397  0.008368   \n",
       "              DecisionTreeRegressor  0.599254  0.117590  0.083799  0.016827   \n",
       "              GradientBoosting       0.697390  0.301287  0.056971  0.007489   \n",
       "              LightGBM               0.698732  0.316480  0.056535  0.007415   \n",
       "              LinearRegression       0.697614  0.248769  0.057793  0.007715   \n",
       "              NeuralNetwork          0.653020  0.111492  0.063265  0.009516   \n",
       "              RandomForest           0.700969  0.318816  0.058133  0.007498   \n",
       "              Ridge                  0.697614  0.248769  0.057793  0.007715   \n",
       "label_low_10  AdaBoost               0.851380  0.255727  0.055023  0.005887   \n",
       "              Bagging                0.836987  0.235640  0.056193  0.006104   \n",
       "              DecisionTreeRegressor  0.716331  0.111224  0.073111  0.010037   \n",
       "              GradientBoosting       0.851007  0.303035  0.054244  0.005807   \n",
       "              LightGBM               0.851380  0.324344  0.053743  0.005681   \n",
       "              LinearRegression       0.850932  0.285087  0.054961  0.005948   \n",
       "              NeuralNetwork          0.844370  0.205720  0.056041  0.006112   \n",
       "              RandomForest           0.849963  0.313238  0.053807  0.005668   \n",
       "              Ridge                  0.850932  0.285085  0.054961  0.005948   \n",
       "label_low_20  AdaBoost               0.886950  0.250468  0.061071  0.007114   \n",
       "              Bagging                0.875019  0.253723  0.061975  0.007227   \n",
       "              DecisionTreeRegressor  0.762192  0.120023  0.078882  0.011334   \n",
       "              GradientBoosting       0.887025  0.334142  0.059890  0.006905   \n",
       "              LightGBM               0.887025  0.349974  0.059233  0.006719   \n",
       "              LinearRegression       0.886875  0.313163  0.060942  0.007110   \n",
       "              NeuralNetwork          0.884340  0.243225  0.060560  0.006973   \n",
       "              RandomForest           0.886428  0.323396  0.059563  0.006795   \n",
       "              Ridge                  0.886875  0.313158  0.060942  0.007110   \n",
       "label_low_5   AdaBoost               0.816555  0.216448  0.050994  0.005175   \n",
       "              Bagging                0.799105  0.225233  0.051877  0.005259   \n",
       "              DecisionTreeRegressor  0.680537  0.115531  0.067557  0.008744   \n",
       "              GradientBoosting       0.816033  0.302126  0.049645  0.004951   \n",
       "              LightGBM               0.817375  0.314652  0.049300  0.004863   \n",
       "              LinearRegression       0.816480  0.260549  0.050540  0.005145   \n",
       "              NeuralNetwork          0.804176  0.190012  0.051919  0.005354   \n",
       "              RandomForest           0.816555  0.303002  0.049504  0.004898   \n",
       "              Ridge                  0.816480  0.260549  0.050540  0.005145   \n",
       "\n",
       "                                        MedAE         R2  SpearmanCorr  \n",
       "center_10     AdaBoost               0.132745  -2.506103      0.024630  \n",
       "              Bagging                0.042488  -0.110913      0.132909  \n",
       "              DecisionTreeRegressor  0.055470  -1.291317      0.052611  \n",
       "              GradientBoosting       0.039317   0.000153      0.187757  \n",
       "              LightGBM               0.039192   0.011337      0.205938  \n",
       "              LinearRegression       0.040137  -0.009502      0.107155  \n",
       "              NeuralNetwork          0.041319  -0.173178      0.063202  \n",
       "              RandomForest           0.040249  -0.005902      0.203765  \n",
       "              Ridge                  0.040137  -0.009503      0.107155  \n",
       "center_20     AdaBoost               0.167179  -4.778048     -0.087202  \n",
       "              Bagging                0.052272  -0.257751      0.120921  \n",
       "              DecisionTreeRegressor  0.063645  -2.386030      0.047454  \n",
       "              GradientBoosting       0.048773  -0.080281      0.141435  \n",
       "              LightGBM               0.048408  -0.073149      0.156370  \n",
       "              LinearRegression       0.049734  -0.056841      0.073709  \n",
       "              NeuralNetwork          0.060035  -0.676960      0.037134  \n",
       "              RandomForest           0.050305  -0.109001      0.169386  \n",
       "              Ridge                  0.049732  -0.056840      0.073695  \n",
       "center_5      AdaBoost               0.085299  -1.083084      0.061834  \n",
       "              Bagging                0.037040  -0.054902      0.157430  \n",
       "              DecisionTreeRegressor  0.049425  -0.932837      0.066658  \n",
       "              GradientBoosting       0.034041   0.032634      0.206408  \n",
       "              LightGBM               0.033998   0.045828      0.230815  \n",
       "              LinearRegression       0.034597   0.000391      0.101465  \n",
       "              NeuralNetwork          0.035364  -0.052852      0.084550  \n",
       "              RandomForest           0.034763   0.025096      0.216564  \n",
       "              Ridge                  0.034598   0.000392      0.101468  \n",
       "high_low_10   AdaBoost               0.287934 -12.359087      0.256781  \n",
       "              Bagging                0.033184   0.130021      0.557675  \n",
       "              DecisionTreeRegressor  0.041750  -1.193737      0.400595  \n",
       "              GradientBoosting       0.029389   0.275831      0.627276  \n",
       "              LightGBM               0.030195   0.265179      0.614326  \n",
       "              LinearRegression       0.029892   0.281580      0.592527  \n",
       "              NeuralNetwork          0.035088  -0.062193      0.479203  \n",
       "              RandomForest           0.031954   0.282604      0.608181  \n",
       "              Ridge                  0.029892   0.281585      0.592534  \n",
       "high_low_20   AdaBoost               0.359848 -12.074703      0.347164  \n",
       "              Bagging                0.042751  -0.077274      0.561044  \n",
       "              DecisionTreeRegressor  0.054965  -2.025705      0.379155  \n",
       "              GradientBoosting       0.036619   0.217389      0.642803  \n",
       "              LightGBM               0.037573   0.208125      0.616175  \n",
       "              LinearRegression       0.037580   0.264238      0.613436  \n",
       "              NeuralNetwork          0.044098  -0.133639      0.450248  \n",
       "              RandomForest           0.040587   0.172270      0.614976  \n",
       "              Ridge                  0.037578   0.264250      0.613447  \n",
       "high_low_5    AdaBoost               0.147549  -4.806153      0.377422  \n",
       "              Bagging                0.026423   0.239323      0.556814  \n",
       "              DecisionTreeRegressor  0.034300  -0.624011      0.389474  \n",
       "              GradientBoosting       0.023603   0.316111      0.623022  \n",
       "              LightGBM               0.023929   0.317764      0.615827  \n",
       "              LinearRegression       0.024288   0.266019      0.582718  \n",
       "              NeuralNetwork          0.025677   0.227415      0.568824  \n",
       "              RandomForest           0.025223   0.321972      0.607117  \n",
       "              Ridge                  0.024288   0.266022      0.582723  \n",
       "label_high_10 AdaBoost               0.408918 -13.813186      0.092629  \n",
       "              Bagging                0.049741  -0.108461      0.231632  \n",
       "              DecisionTreeRegressor  0.061110  -1.854325      0.104670  \n",
       "              GradientBoosting       0.045032   0.031977      0.281553  \n",
       "              LightGBM               0.044672   0.055023      0.285515  \n",
       "              LinearRegression       0.044815   0.076416      0.216658  \n",
       "              NeuralNetwork          0.054731  -0.407503      0.103992  \n",
       "              RandomForest           0.048766   0.035011      0.286244  \n",
       "              Ridge                  0.044813   0.076416      0.216656  \n",
       "label_high_20 AdaBoost               0.547722 -19.180045      0.009560  \n",
       "              Bagging                0.065380  -0.255868      0.245048  \n",
       "              DecisionTreeRegressor  0.074005  -2.412704      0.124359  \n",
       "              GradientBoosting       0.059053   0.003885      0.282070  \n",
       "              LightGBM               0.058706  -0.017958      0.280592  \n",
       "              LinearRegression       0.060103   0.052365      0.229728  \n",
       "              NeuralNetwork          0.065840  -0.521957      0.107441  \n",
       "              RandomForest           0.065117  -0.064236      0.290375  \n",
       "              Ridge                  0.060101   0.052372      0.229734  \n",
       "label_high_5  AdaBoost               0.205857  -4.427900      0.089399  \n",
       "              Bagging                0.041222  -0.017769      0.233531  \n",
       "              DecisionTreeRegressor  0.053015  -1.046539      0.114258  \n",
       "              GradientBoosting       0.037358   0.089160      0.281053  \n",
       "              LightGBM               0.037203   0.098165      0.296688  \n",
       "              LinearRegression       0.037277   0.061650      0.186100  \n",
       "              NeuralNetwork          0.040436  -0.157372      0.103417  \n",
       "              RandomForest           0.039366   0.088148      0.291807  \n",
       "              Ridge                  0.037274   0.061650      0.186101  \n",
       "label_low_10  AdaBoost               0.038198   0.014045      0.252602  \n",
       "              Bagging                0.040099  -0.022414      0.237511  \n",
       "              DecisionTreeRegressor  0.053530  -0.681043      0.112186  \n",
       "              GradientBoosting       0.037537   0.027315      0.306749  \n",
       "              LightGBM               0.037099   0.048419      0.319544  \n",
       "              LinearRegression       0.037519   0.003712      0.298701  \n",
       "              NeuralNetwork          0.039831  -0.023688      0.222281  \n",
       "              RandomForest           0.037649   0.050702      0.309306  \n",
       "              Ridge                  0.037519   0.003713      0.298701  \n",
       "label_low_20  AdaBoost               0.043295  -0.027033      0.266205  \n",
       "              Bagging                0.044873  -0.043450      0.244284  \n",
       "              DecisionTreeRegressor  0.059125  -0.636399      0.114935  \n",
       "              GradientBoosting       0.042254   0.003065      0.340903  \n",
       "              LightGBM               0.042107   0.029984      0.345673  \n",
       "              LinearRegression       0.043209  -0.026582      0.331691  \n",
       "              NeuralNetwork          0.043623  -0.006738      0.250649  \n",
       "              RandomForest           0.042107   0.019025      0.324515  \n",
       "              Ridge                  0.043214  -0.026585      0.331683  \n",
       "label_low_5   AdaBoost               0.034500   0.010857      0.230499  \n",
       "              Bagging                0.036591  -0.005375      0.225451  \n",
       "              DecisionTreeRegressor  0.049270  -0.671439      0.125558  \n",
       "              GradientBoosting       0.033953   0.053560      0.303306  \n",
       "              LightGBM               0.033761   0.070326      0.310753  \n",
       "              LinearRegression       0.034016   0.016543      0.263162  \n",
       "              NeuralNetwork          0.036028  -0.023422      0.202159  \n",
       "              RandomForest           0.033997   0.063808      0.302008  \n",
       "              Ridge                  0.034018   0.016547      0.263167  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.Series(scores).unstack()\n",
    "result.to_csv('../result/ML_val_result.csv')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Corr</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MedAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>SpearmanCorr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">center_10</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.478334</td>\n",
       "      <td>-0.018609</td>\n",
       "      <td>0.131317</td>\n",
       "      <td>0.022351</td>\n",
       "      <td>0.124837</td>\n",
       "      <td>-2.010599</td>\n",
       "      <td>-0.027991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.520083</td>\n",
       "      <td>0.090203</td>\n",
       "      <td>0.061900</td>\n",
       "      <td>0.008392</td>\n",
       "      <td>0.042218</td>\n",
       "      <td>-0.130367</td>\n",
       "      <td>0.081493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.510692</td>\n",
       "      <td>0.059255</td>\n",
       "      <td>0.085736</td>\n",
       "      <td>0.017572</td>\n",
       "      <td>0.057252</td>\n",
       "      <td>-1.366928</td>\n",
       "      <td>0.048949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.523846</td>\n",
       "      <td>0.095961</td>\n",
       "      <td>0.056892</td>\n",
       "      <td>0.007623</td>\n",
       "      <td>0.037574</td>\n",
       "      <td>-0.026755</td>\n",
       "      <td>0.117475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.523565</td>\n",
       "      <td>0.131547</td>\n",
       "      <td>0.057493</td>\n",
       "      <td>0.007502</td>\n",
       "      <td>0.038505</td>\n",
       "      <td>-0.010480</td>\n",
       "      <td>0.097976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.484630</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>0.057428</td>\n",
       "      <td>0.007762</td>\n",
       "      <td>0.038197</td>\n",
       "      <td>-0.045522</td>\n",
       "      <td>-0.017808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.497819</td>\n",
       "      <td>0.017389</td>\n",
       "      <td>0.062699</td>\n",
       "      <td>0.009266</td>\n",
       "      <td>0.041736</td>\n",
       "      <td>-0.248152</td>\n",
       "      <td>0.014831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.526801</td>\n",
       "      <td>0.129083</td>\n",
       "      <td>0.058123</td>\n",
       "      <td>0.007613</td>\n",
       "      <td>0.039285</td>\n",
       "      <td>-0.025474</td>\n",
       "      <td>0.115414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.484665</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.057428</td>\n",
       "      <td>0.007762</td>\n",
       "      <td>0.038196</td>\n",
       "      <td>-0.045512</td>\n",
       "      <td>-0.017801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">center_20</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.487584</td>\n",
       "      <td>0.074908</td>\n",
       "      <td>0.197171</td>\n",
       "      <td>0.057260</td>\n",
       "      <td>0.174910</td>\n",
       "      <td>-3.468416</td>\n",
       "      <td>0.040184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.504185</td>\n",
       "      <td>0.079143</td>\n",
       "      <td>0.082362</td>\n",
       "      <td>0.015610</td>\n",
       "      <td>0.055407</td>\n",
       "      <td>-0.218167</td>\n",
       "      <td>0.065939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.487479</td>\n",
       "      <td>0.028296</td>\n",
       "      <td>0.110585</td>\n",
       "      <td>0.034094</td>\n",
       "      <td>0.072657</td>\n",
       "      <td>-1.660590</td>\n",
       "      <td>0.002317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.501899</td>\n",
       "      <td>0.097456</td>\n",
       "      <td>0.075057</td>\n",
       "      <td>0.013457</td>\n",
       "      <td>0.049450</td>\n",
       "      <td>-0.050148</td>\n",
       "      <td>0.092979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.509778</td>\n",
       "      <td>0.124375</td>\n",
       "      <td>0.075819</td>\n",
       "      <td>0.013414</td>\n",
       "      <td>0.050081</td>\n",
       "      <td>-0.046832</td>\n",
       "      <td>0.091972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.484806</td>\n",
       "      <td>0.015151</td>\n",
       "      <td>0.075160</td>\n",
       "      <td>0.013422</td>\n",
       "      <td>0.050346</td>\n",
       "      <td>-0.047430</td>\n",
       "      <td>-0.010972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.490398</td>\n",
       "      <td>0.021702</td>\n",
       "      <td>0.094370</td>\n",
       "      <td>0.020238</td>\n",
       "      <td>0.064933</td>\n",
       "      <td>-0.579342</td>\n",
       "      <td>0.013965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.505381</td>\n",
       "      <td>0.117938</td>\n",
       "      <td>0.077196</td>\n",
       "      <td>0.013777</td>\n",
       "      <td>0.051989</td>\n",
       "      <td>-0.075133</td>\n",
       "      <td>0.099631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.484841</td>\n",
       "      <td>0.015186</td>\n",
       "      <td>0.075159</td>\n",
       "      <td>0.013422</td>\n",
       "      <td>0.050339</td>\n",
       "      <td>-0.047394</td>\n",
       "      <td>-0.010932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">center_5</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.460537</td>\n",
       "      <td>-0.003574</td>\n",
       "      <td>0.085981</td>\n",
       "      <td>0.010604</td>\n",
       "      <td>0.079301</td>\n",
       "      <td>-0.896244</td>\n",
       "      <td>-0.001081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.535031</td>\n",
       "      <td>0.117570</td>\n",
       "      <td>0.052278</td>\n",
       "      <td>0.006111</td>\n",
       "      <td>0.035404</td>\n",
       "      <td>-0.092857</td>\n",
       "      <td>0.113192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.506401</td>\n",
       "      <td>0.037868</td>\n",
       "      <td>0.072967</td>\n",
       "      <td>0.011416</td>\n",
       "      <td>0.050205</td>\n",
       "      <td>-1.041484</td>\n",
       "      <td>0.042347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.545371</td>\n",
       "      <td>0.139397</td>\n",
       "      <td>0.048161</td>\n",
       "      <td>0.005538</td>\n",
       "      <td>0.031251</td>\n",
       "      <td>0.009652</td>\n",
       "      <td>0.151832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.550577</td>\n",
       "      <td>0.174177</td>\n",
       "      <td>0.048482</td>\n",
       "      <td>0.005506</td>\n",
       "      <td>0.031594</td>\n",
       "      <td>0.015432</td>\n",
       "      <td>0.150301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.501161</td>\n",
       "      <td>0.013362</td>\n",
       "      <td>0.048790</td>\n",
       "      <td>0.005742</td>\n",
       "      <td>0.031423</td>\n",
       "      <td>-0.026917</td>\n",
       "      <td>0.022006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.517797</td>\n",
       "      <td>0.005810</td>\n",
       "      <td>0.052914</td>\n",
       "      <td>0.007550</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>-0.350227</td>\n",
       "      <td>0.029755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.545231</td>\n",
       "      <td>0.155331</td>\n",
       "      <td>0.049087</td>\n",
       "      <td>0.005586</td>\n",
       "      <td>0.032592</td>\n",
       "      <td>0.001081</td>\n",
       "      <td>0.147102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.501125</td>\n",
       "      <td>0.013375</td>\n",
       "      <td>0.048790</td>\n",
       "      <td>0.005742</td>\n",
       "      <td>0.031425</td>\n",
       "      <td>-0.026902</td>\n",
       "      <td>0.022017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">high_low_10</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.997819</td>\n",
       "      <td>0.297252</td>\n",
       "      <td>0.297183</td>\n",
       "      <td>0.102173</td>\n",
       "      <td>0.294551</td>\n",
       "      <td>-8.864832</td>\n",
       "      <td>0.313208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.997819</td>\n",
       "      <td>0.413359</td>\n",
       "      <td>0.058038</td>\n",
       "      <td>0.009637</td>\n",
       "      <td>0.037468</td>\n",
       "      <td>0.069561</td>\n",
       "      <td>0.510808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.997538</td>\n",
       "      <td>0.236098</td>\n",
       "      <td>0.078607</td>\n",
       "      <td>0.022978</td>\n",
       "      <td>0.043955</td>\n",
       "      <td>-1.218556</td>\n",
       "      <td>0.368528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.997819</td>\n",
       "      <td>0.457151</td>\n",
       "      <td>0.051773</td>\n",
       "      <td>0.008599</td>\n",
       "      <td>0.033226</td>\n",
       "      <td>0.169734</td>\n",
       "      <td>0.587221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.997819</td>\n",
       "      <td>0.480977</td>\n",
       "      <td>0.052337</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.033696</td>\n",
       "      <td>0.214496</td>\n",
       "      <td>0.567521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.997749</td>\n",
       "      <td>0.447606</td>\n",
       "      <td>0.052149</td>\n",
       "      <td>0.008430</td>\n",
       "      <td>0.033827</td>\n",
       "      <td>0.186119</td>\n",
       "      <td>0.536681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.991840</td>\n",
       "      <td>0.348159</td>\n",
       "      <td>0.060552</td>\n",
       "      <td>0.010966</td>\n",
       "      <td>0.036526</td>\n",
       "      <td>-0.058757</td>\n",
       "      <td>0.441758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.997819</td>\n",
       "      <td>0.481564</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.008261</td>\n",
       "      <td>0.036452</td>\n",
       "      <td>0.202381</td>\n",
       "      <td>0.569616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.997749</td>\n",
       "      <td>0.447615</td>\n",
       "      <td>0.052148</td>\n",
       "      <td>0.008430</td>\n",
       "      <td>0.033826</td>\n",
       "      <td>0.186131</td>\n",
       "      <td>0.536692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">high_low_20</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.991735</td>\n",
       "      <td>0.270569</td>\n",
       "      <td>0.380675</td>\n",
       "      <td>0.183563</td>\n",
       "      <td>0.353059</td>\n",
       "      <td>-6.232500</td>\n",
       "      <td>0.295399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.991735</td>\n",
       "      <td>0.325626</td>\n",
       "      <td>0.092074</td>\n",
       "      <td>0.025729</td>\n",
       "      <td>0.056461</td>\n",
       "      <td>-0.013724</td>\n",
       "      <td>0.440898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.991735</td>\n",
       "      <td>0.171144</td>\n",
       "      <td>0.118570</td>\n",
       "      <td>0.055549</td>\n",
       "      <td>0.065400</td>\n",
       "      <td>-1.188648</td>\n",
       "      <td>0.303937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.991735</td>\n",
       "      <td>0.345238</td>\n",
       "      <td>0.083003</td>\n",
       "      <td>0.024412</td>\n",
       "      <td>0.049887</td>\n",
       "      <td>0.038141</td>\n",
       "      <td>0.508551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.991735</td>\n",
       "      <td>0.370231</td>\n",
       "      <td>0.084171</td>\n",
       "      <td>0.023055</td>\n",
       "      <td>0.050663</td>\n",
       "      <td>0.091616</td>\n",
       "      <td>0.487113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.991664</td>\n",
       "      <td>0.367991</td>\n",
       "      <td>0.081610</td>\n",
       "      <td>0.022414</td>\n",
       "      <td>0.051466</td>\n",
       "      <td>0.116861</td>\n",
       "      <td>0.472462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.985017</td>\n",
       "      <td>0.255760</td>\n",
       "      <td>0.093917</td>\n",
       "      <td>0.029102</td>\n",
       "      <td>0.053591</td>\n",
       "      <td>-0.146641</td>\n",
       "      <td>0.362691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.991735</td>\n",
       "      <td>0.376705</td>\n",
       "      <td>0.086946</td>\n",
       "      <td>0.023243</td>\n",
       "      <td>0.054784</td>\n",
       "      <td>0.084194</td>\n",
       "      <td>0.487698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.991664</td>\n",
       "      <td>0.368006</td>\n",
       "      <td>0.081609</td>\n",
       "      <td>0.022414</td>\n",
       "      <td>0.051475</td>\n",
       "      <td>0.116876</td>\n",
       "      <td>0.472480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">high_low_5</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.997327</td>\n",
       "      <td>0.346770</td>\n",
       "      <td>0.156975</td>\n",
       "      <td>0.028636</td>\n",
       "      <td>0.153993</td>\n",
       "      <td>-4.033517</td>\n",
       "      <td>0.367377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.997327</td>\n",
       "      <td>0.460496</td>\n",
       "      <td>0.040782</td>\n",
       "      <td>0.004692</td>\n",
       "      <td>0.027529</td>\n",
       "      <td>0.175178</td>\n",
       "      <td>0.545088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.995076</td>\n",
       "      <td>0.263044</td>\n",
       "      <td>0.056999</td>\n",
       "      <td>0.010329</td>\n",
       "      <td>0.034060</td>\n",
       "      <td>-0.815535</td>\n",
       "      <td>0.368994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.997327</td>\n",
       "      <td>0.526772</td>\n",
       "      <td>0.036676</td>\n",
       "      <td>0.004130</td>\n",
       "      <td>0.024418</td>\n",
       "      <td>0.274102</td>\n",
       "      <td>0.614411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.997327</td>\n",
       "      <td>0.531082</td>\n",
       "      <td>0.037085</td>\n",
       "      <td>0.004099</td>\n",
       "      <td>0.024807</td>\n",
       "      <td>0.279427</td>\n",
       "      <td>0.604291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.997151</td>\n",
       "      <td>0.484786</td>\n",
       "      <td>0.037756</td>\n",
       "      <td>0.004414</td>\n",
       "      <td>0.025178</td>\n",
       "      <td>0.224096</td>\n",
       "      <td>0.566273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.994759</td>\n",
       "      <td>0.461581</td>\n",
       "      <td>0.039990</td>\n",
       "      <td>0.004719</td>\n",
       "      <td>0.026040</td>\n",
       "      <td>0.170455</td>\n",
       "      <td>0.546449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.997327</td>\n",
       "      <td>0.506526</td>\n",
       "      <td>0.038728</td>\n",
       "      <td>0.004283</td>\n",
       "      <td>0.026827</td>\n",
       "      <td>0.247095</td>\n",
       "      <td>0.595250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.997151</td>\n",
       "      <td>0.484799</td>\n",
       "      <td>0.037755</td>\n",
       "      <td>0.004414</td>\n",
       "      <td>0.025179</td>\n",
       "      <td>0.224109</td>\n",
       "      <td>0.566281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">label_high_10</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.779439</td>\n",
       "      <td>0.061282</td>\n",
       "      <td>0.381954</td>\n",
       "      <td>0.159306</td>\n",
       "      <td>0.398873</td>\n",
       "      <td>-10.218295</td>\n",
       "      <td>0.030216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.771103</td>\n",
       "      <td>0.194885</td>\n",
       "      <td>0.079023</td>\n",
       "      <td>0.016503</td>\n",
       "      <td>0.050876</td>\n",
       "      <td>-0.162169</td>\n",
       "      <td>0.190137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.646666</td>\n",
       "      <td>0.098609</td>\n",
       "      <td>0.109624</td>\n",
       "      <td>0.037095</td>\n",
       "      <td>0.064640</td>\n",
       "      <td>-1.612199</td>\n",
       "      <td>0.077939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.779228</td>\n",
       "      <td>0.236709</td>\n",
       "      <td>0.069794</td>\n",
       "      <td>0.013777</td>\n",
       "      <td>0.044770</td>\n",
       "      <td>0.029855</td>\n",
       "      <td>0.257074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.778243</td>\n",
       "      <td>0.269169</td>\n",
       "      <td>0.070171</td>\n",
       "      <td>0.013456</td>\n",
       "      <td>0.044353</td>\n",
       "      <td>0.052453</td>\n",
       "      <td>0.249099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.778665</td>\n",
       "      <td>0.185199</td>\n",
       "      <td>0.070445</td>\n",
       "      <td>0.013943</td>\n",
       "      <td>0.045580</td>\n",
       "      <td>0.018160</td>\n",
       "      <td>0.179212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.712753</td>\n",
       "      <td>0.108316</td>\n",
       "      <td>0.087986</td>\n",
       "      <td>0.019508</td>\n",
       "      <td>0.055530</td>\n",
       "      <td>-0.373744</td>\n",
       "      <td>0.082978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.779192</td>\n",
       "      <td>0.258860</td>\n",
       "      <td>0.072973</td>\n",
       "      <td>0.013997</td>\n",
       "      <td>0.048192</td>\n",
       "      <td>0.014319</td>\n",
       "      <td>0.252100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.778665</td>\n",
       "      <td>0.185212</td>\n",
       "      <td>0.070444</td>\n",
       "      <td>0.013943</td>\n",
       "      <td>0.045577</td>\n",
       "      <td>0.018171</td>\n",
       "      <td>0.179231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">label_high_20</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.815419</td>\n",
       "      <td>0.117124</td>\n",
       "      <td>0.545098</td>\n",
       "      <td>0.368266</td>\n",
       "      <td>0.559415</td>\n",
       "      <td>-12.466396</td>\n",
       "      <td>0.104557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.812570</td>\n",
       "      <td>0.195820</td>\n",
       "      <td>0.106065</td>\n",
       "      <td>0.032572</td>\n",
       "      <td>0.067394</td>\n",
       "      <td>-0.191077</td>\n",
       "      <td>0.208057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.691299</td>\n",
       "      <td>0.092262</td>\n",
       "      <td>0.143060</td>\n",
       "      <td>0.071397</td>\n",
       "      <td>0.081330</td>\n",
       "      <td>-1.610775</td>\n",
       "      <td>0.084727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.815384</td>\n",
       "      <td>0.203916</td>\n",
       "      <td>0.093441</td>\n",
       "      <td>0.029509</td>\n",
       "      <td>0.060109</td>\n",
       "      <td>-0.079054</td>\n",
       "      <td>0.284256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.815032</td>\n",
       "      <td>0.244074</td>\n",
       "      <td>0.094062</td>\n",
       "      <td>0.027364</td>\n",
       "      <td>0.059949</td>\n",
       "      <td>-0.000606</td>\n",
       "      <td>0.258291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.815314</td>\n",
       "      <td>0.207995</td>\n",
       "      <td>0.092055</td>\n",
       "      <td>0.026440</td>\n",
       "      <td>0.062671</td>\n",
       "      <td>0.033155</td>\n",
       "      <td>0.221539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.768676</td>\n",
       "      <td>0.103317</td>\n",
       "      <td>0.110356</td>\n",
       "      <td>0.037319</td>\n",
       "      <td>0.068177</td>\n",
       "      <td>-0.364645</td>\n",
       "      <td>0.101254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.815490</td>\n",
       "      <td>0.251876</td>\n",
       "      <td>0.098735</td>\n",
       "      <td>0.028045</td>\n",
       "      <td>0.065801</td>\n",
       "      <td>-0.025531</td>\n",
       "      <td>0.274139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.815314</td>\n",
       "      <td>0.208039</td>\n",
       "      <td>0.092054</td>\n",
       "      <td>0.026439</td>\n",
       "      <td>0.062674</td>\n",
       "      <td>0.033188</td>\n",
       "      <td>0.221573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">label_high_5</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.734700</td>\n",
       "      <td>0.092733</td>\n",
       "      <td>0.192856</td>\n",
       "      <td>0.043362</td>\n",
       "      <td>0.199650</td>\n",
       "      <td>-3.532514</td>\n",
       "      <td>0.032827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.711557</td>\n",
       "      <td>0.191896</td>\n",
       "      <td>0.062644</td>\n",
       "      <td>0.010009</td>\n",
       "      <td>0.040494</td>\n",
       "      <td>-0.046169</td>\n",
       "      <td>0.165691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.597918</td>\n",
       "      <td>0.089446</td>\n",
       "      <td>0.086861</td>\n",
       "      <td>0.019462</td>\n",
       "      <td>0.053605</td>\n",
       "      <td>-1.034316</td>\n",
       "      <td>0.080623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.733821</td>\n",
       "      <td>0.241204</td>\n",
       "      <td>0.056852</td>\n",
       "      <td>0.009068</td>\n",
       "      <td>0.035396</td>\n",
       "      <td>0.052199</td>\n",
       "      <td>0.246830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.730972</td>\n",
       "      <td>0.271305</td>\n",
       "      <td>0.056939</td>\n",
       "      <td>0.008917</td>\n",
       "      <td>0.035183</td>\n",
       "      <td>0.067889</td>\n",
       "      <td>0.233647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.732942</td>\n",
       "      <td>0.175027</td>\n",
       "      <td>0.057870</td>\n",
       "      <td>0.009343</td>\n",
       "      <td>0.036327</td>\n",
       "      <td>0.023363</td>\n",
       "      <td>0.155636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.664638</td>\n",
       "      <td>0.088963</td>\n",
       "      <td>0.065253</td>\n",
       "      <td>0.011528</td>\n",
       "      <td>0.040325</td>\n",
       "      <td>-0.204936</td>\n",
       "      <td>0.080216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.732907</td>\n",
       "      <td>0.254974</td>\n",
       "      <td>0.058617</td>\n",
       "      <td>0.009080</td>\n",
       "      <td>0.037669</td>\n",
       "      <td>0.050942</td>\n",
       "      <td>0.235183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.732942</td>\n",
       "      <td>0.175053</td>\n",
       "      <td>0.057869</td>\n",
       "      <td>0.009343</td>\n",
       "      <td>0.036328</td>\n",
       "      <td>0.023380</td>\n",
       "      <td>0.155651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">label_low_10</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.839125</td>\n",
       "      <td>0.209199</td>\n",
       "      <td>0.052645</td>\n",
       "      <td>0.005638</td>\n",
       "      <td>0.036069</td>\n",
       "      <td>0.032245</td>\n",
       "      <td>0.194094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.825936</td>\n",
       "      <td>0.167936</td>\n",
       "      <td>0.055790</td>\n",
       "      <td>0.006172</td>\n",
       "      <td>0.039570</td>\n",
       "      <td>-0.059369</td>\n",
       "      <td>0.171865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.721405</td>\n",
       "      <td>0.106890</td>\n",
       "      <td>0.072969</td>\n",
       "      <td>0.010169</td>\n",
       "      <td>0.053115</td>\n",
       "      <td>-0.745397</td>\n",
       "      <td>0.108881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.838738</td>\n",
       "      <td>0.235674</td>\n",
       "      <td>0.052217</td>\n",
       "      <td>0.005591</td>\n",
       "      <td>0.035800</td>\n",
       "      <td>0.040291</td>\n",
       "      <td>0.227156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.838668</td>\n",
       "      <td>0.230371</td>\n",
       "      <td>0.052891</td>\n",
       "      <td>0.005663</td>\n",
       "      <td>0.036842</td>\n",
       "      <td>0.027977</td>\n",
       "      <td>0.226664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.838386</td>\n",
       "      <td>0.186979</td>\n",
       "      <td>0.052660</td>\n",
       "      <td>0.005796</td>\n",
       "      <td>0.035226</td>\n",
       "      <td>0.005158</td>\n",
       "      <td>0.189099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.831669</td>\n",
       "      <td>0.154839</td>\n",
       "      <td>0.056572</td>\n",
       "      <td>0.006546</td>\n",
       "      <td>0.040424</td>\n",
       "      <td>-0.123588</td>\n",
       "      <td>0.163965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.837929</td>\n",
       "      <td>0.222782</td>\n",
       "      <td>0.052983</td>\n",
       "      <td>0.005667</td>\n",
       "      <td>0.037021</td>\n",
       "      <td>0.027309</td>\n",
       "      <td>0.222156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.838386</td>\n",
       "      <td>0.186989</td>\n",
       "      <td>0.052659</td>\n",
       "      <td>0.005796</td>\n",
       "      <td>0.035231</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>0.189107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">label_low_20</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.861635</td>\n",
       "      <td>0.136632</td>\n",
       "      <td>0.070669</td>\n",
       "      <td>0.011431</td>\n",
       "      <td>0.043725</td>\n",
       "      <td>-0.041823</td>\n",
       "      <td>0.133656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.852947</td>\n",
       "      <td>0.097892</td>\n",
       "      <td>0.073458</td>\n",
       "      <td>0.012051</td>\n",
       "      <td>0.047095</td>\n",
       "      <td>-0.098338</td>\n",
       "      <td>0.115693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.744654</td>\n",
       "      <td>0.050631</td>\n",
       "      <td>0.092057</td>\n",
       "      <td>0.016842</td>\n",
       "      <td>0.064200</td>\n",
       "      <td>-0.535023</td>\n",
       "      <td>0.060033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.861459</td>\n",
       "      <td>0.134859</td>\n",
       "      <td>0.070425</td>\n",
       "      <td>0.011492</td>\n",
       "      <td>0.043452</td>\n",
       "      <td>-0.047391</td>\n",
       "      <td>0.144092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.860791</td>\n",
       "      <td>0.131478</td>\n",
       "      <td>0.071171</td>\n",
       "      <td>0.011551</td>\n",
       "      <td>0.044744</td>\n",
       "      <td>-0.052812</td>\n",
       "      <td>0.146309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.861248</td>\n",
       "      <td>0.128364</td>\n",
       "      <td>0.070724</td>\n",
       "      <td>0.011611</td>\n",
       "      <td>0.043049</td>\n",
       "      <td>-0.058265</td>\n",
       "      <td>0.135610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.858434</td>\n",
       "      <td>0.089398</td>\n",
       "      <td>0.073816</td>\n",
       "      <td>0.012785</td>\n",
       "      <td>0.048188</td>\n",
       "      <td>-0.165263</td>\n",
       "      <td>0.112928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.860755</td>\n",
       "      <td>0.123695</td>\n",
       "      <td>0.071145</td>\n",
       "      <td>0.011534</td>\n",
       "      <td>0.044926</td>\n",
       "      <td>-0.051225</td>\n",
       "      <td>0.145896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.861248</td>\n",
       "      <td>0.128389</td>\n",
       "      <td>0.070723</td>\n",
       "      <td>0.011611</td>\n",
       "      <td>0.043047</td>\n",
       "      <td>-0.058244</td>\n",
       "      <td>0.135623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">label_low_5</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.809757</td>\n",
       "      <td>0.203575</td>\n",
       "      <td>0.045896</td>\n",
       "      <td>0.004297</td>\n",
       "      <td>0.031621</td>\n",
       "      <td>0.036864</td>\n",
       "      <td>0.196345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.792945</td>\n",
       "      <td>0.195619</td>\n",
       "      <td>0.048573</td>\n",
       "      <td>0.004674</td>\n",
       "      <td>0.034573</td>\n",
       "      <td>-0.047650</td>\n",
       "      <td>0.201043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.685777</td>\n",
       "      <td>0.080108</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.009258</td>\n",
       "      <td>0.049495</td>\n",
       "      <td>-1.075137</td>\n",
       "      <td>0.093706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.809370</td>\n",
       "      <td>0.261767</td>\n",
       "      <td>0.045258</td>\n",
       "      <td>0.004183</td>\n",
       "      <td>0.031618</td>\n",
       "      <td>0.062387</td>\n",
       "      <td>0.263141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.809159</td>\n",
       "      <td>0.262591</td>\n",
       "      <td>0.045797</td>\n",
       "      <td>0.004240</td>\n",
       "      <td>0.032450</td>\n",
       "      <td>0.049681</td>\n",
       "      <td>0.260743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.809018</td>\n",
       "      <td>0.204451</td>\n",
       "      <td>0.045656</td>\n",
       "      <td>0.004349</td>\n",
       "      <td>0.030967</td>\n",
       "      <td>0.025303</td>\n",
       "      <td>0.209576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.799733</td>\n",
       "      <td>0.150892</td>\n",
       "      <td>0.048196</td>\n",
       "      <td>0.004880</td>\n",
       "      <td>0.033340</td>\n",
       "      <td>-0.093742</td>\n",
       "      <td>0.176873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.807295</td>\n",
       "      <td>0.250070</td>\n",
       "      <td>0.045948</td>\n",
       "      <td>0.004263</td>\n",
       "      <td>0.032554</td>\n",
       "      <td>0.044544</td>\n",
       "      <td>0.252709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.809018</td>\n",
       "      <td>0.204461</td>\n",
       "      <td>0.045655</td>\n",
       "      <td>0.004349</td>\n",
       "      <td>0.030968</td>\n",
       "      <td>0.025313</td>\n",
       "      <td>0.209583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Accuracy      Corr       MAE       MSE  \\\n",
       "center_10     AdaBoost               0.478334 -0.018609  0.131317  0.022351   \n",
       "              Bagging                0.520083  0.090203  0.061900  0.008392   \n",
       "              DecisionTreeRegressor  0.510692  0.059255  0.085736  0.017572   \n",
       "              GradientBoosting       0.523846  0.095961  0.056892  0.007623   \n",
       "              LightGBM               0.523565  0.131547  0.057493  0.007502   \n",
       "              LinearRegression       0.484630  0.000766  0.057428  0.007762   \n",
       "              NeuralNetwork          0.497819  0.017389  0.062699  0.009266   \n",
       "              RandomForest           0.526801  0.129083  0.058123  0.007613   \n",
       "              Ridge                  0.484665  0.000775  0.057428  0.007762   \n",
       "center_20     AdaBoost               0.487584  0.074908  0.197171  0.057260   \n",
       "              Bagging                0.504185  0.079143  0.082362  0.015610   \n",
       "              DecisionTreeRegressor  0.487479  0.028296  0.110585  0.034094   \n",
       "              GradientBoosting       0.501899  0.097456  0.075057  0.013457   \n",
       "              LightGBM               0.509778  0.124375  0.075819  0.013414   \n",
       "              LinearRegression       0.484806  0.015151  0.075160  0.013422   \n",
       "              NeuralNetwork          0.490398  0.021702  0.094370  0.020238   \n",
       "              RandomForest           0.505381  0.117938  0.077196  0.013777   \n",
       "              Ridge                  0.484841  0.015186  0.075159  0.013422   \n",
       "center_5      AdaBoost               0.460537 -0.003574  0.085981  0.010604   \n",
       "              Bagging                0.535031  0.117570  0.052278  0.006111   \n",
       "              DecisionTreeRegressor  0.506401  0.037868  0.072967  0.011416   \n",
       "              GradientBoosting       0.545371  0.139397  0.048161  0.005538   \n",
       "              LightGBM               0.550577  0.174177  0.048482  0.005506   \n",
       "              LinearRegression       0.501161  0.013362  0.048790  0.005742   \n",
       "              NeuralNetwork          0.517797  0.005810  0.052914  0.007550   \n",
       "              RandomForest           0.545231  0.155331  0.049087  0.005586   \n",
       "              Ridge                  0.501125  0.013375  0.048790  0.005742   \n",
       "high_low_10   AdaBoost               0.997819  0.297252  0.297183  0.102173   \n",
       "              Bagging                0.997819  0.413359  0.058038  0.009637   \n",
       "              DecisionTreeRegressor  0.997538  0.236098  0.078607  0.022978   \n",
       "              GradientBoosting       0.997819  0.457151  0.051773  0.008599   \n",
       "              LightGBM               0.997819  0.480977  0.052337  0.008136   \n",
       "              LinearRegression       0.997749  0.447606  0.052149  0.008430   \n",
       "              NeuralNetwork          0.991840  0.348159  0.060552  0.010966   \n",
       "              RandomForest           0.997819  0.481564  0.054054  0.008261   \n",
       "              Ridge                  0.997749  0.447615  0.052148  0.008430   \n",
       "high_low_20   AdaBoost               0.991735  0.270569  0.380675  0.183563   \n",
       "              Bagging                0.991735  0.325626  0.092074  0.025729   \n",
       "              DecisionTreeRegressor  0.991735  0.171144  0.118570  0.055549   \n",
       "              GradientBoosting       0.991735  0.345238  0.083003  0.024412   \n",
       "              LightGBM               0.991735  0.370231  0.084171  0.023055   \n",
       "              LinearRegression       0.991664  0.367991  0.081610  0.022414   \n",
       "              NeuralNetwork          0.985017  0.255760  0.093917  0.029102   \n",
       "              RandomForest           0.991735  0.376705  0.086946  0.023243   \n",
       "              Ridge                  0.991664  0.368006  0.081609  0.022414   \n",
       "high_low_5    AdaBoost               0.997327  0.346770  0.156975  0.028636   \n",
       "              Bagging                0.997327  0.460496  0.040782  0.004692   \n",
       "              DecisionTreeRegressor  0.995076  0.263044  0.056999  0.010329   \n",
       "              GradientBoosting       0.997327  0.526772  0.036676  0.004130   \n",
       "              LightGBM               0.997327  0.531082  0.037085  0.004099   \n",
       "              LinearRegression       0.997151  0.484786  0.037756  0.004414   \n",
       "              NeuralNetwork          0.994759  0.461581  0.039990  0.004719   \n",
       "              RandomForest           0.997327  0.506526  0.038728  0.004283   \n",
       "              Ridge                  0.997151  0.484799  0.037755  0.004414   \n",
       "label_high_10 AdaBoost               0.779439  0.061282  0.381954  0.159306   \n",
       "              Bagging                0.771103  0.194885  0.079023  0.016503   \n",
       "              DecisionTreeRegressor  0.646666  0.098609  0.109624  0.037095   \n",
       "              GradientBoosting       0.779228  0.236709  0.069794  0.013777   \n",
       "              LightGBM               0.778243  0.269169  0.070171  0.013456   \n",
       "              LinearRegression       0.778665  0.185199  0.070445  0.013943   \n",
       "              NeuralNetwork          0.712753  0.108316  0.087986  0.019508   \n",
       "              RandomForest           0.779192  0.258860  0.072973  0.013997   \n",
       "              Ridge                  0.778665  0.185212  0.070444  0.013943   \n",
       "label_high_20 AdaBoost               0.815419  0.117124  0.545098  0.368266   \n",
       "              Bagging                0.812570  0.195820  0.106065  0.032572   \n",
       "              DecisionTreeRegressor  0.691299  0.092262  0.143060  0.071397   \n",
       "              GradientBoosting       0.815384  0.203916  0.093441  0.029509   \n",
       "              LightGBM               0.815032  0.244074  0.094062  0.027364   \n",
       "              LinearRegression       0.815314  0.207995  0.092055  0.026440   \n",
       "              NeuralNetwork          0.768676  0.103317  0.110356  0.037319   \n",
       "              RandomForest           0.815490  0.251876  0.098735  0.028045   \n",
       "              Ridge                  0.815314  0.208039  0.092054  0.026439   \n",
       "label_high_5  AdaBoost               0.734700  0.092733  0.192856  0.043362   \n",
       "              Bagging                0.711557  0.191896  0.062644  0.010009   \n",
       "              DecisionTreeRegressor  0.597918  0.089446  0.086861  0.019462   \n",
       "              GradientBoosting       0.733821  0.241204  0.056852  0.009068   \n",
       "              LightGBM               0.730972  0.271305  0.056939  0.008917   \n",
       "              LinearRegression       0.732942  0.175027  0.057870  0.009343   \n",
       "              NeuralNetwork          0.664638  0.088963  0.065253  0.011528   \n",
       "              RandomForest           0.732907  0.254974  0.058617  0.009080   \n",
       "              Ridge                  0.732942  0.175053  0.057869  0.009343   \n",
       "label_low_10  AdaBoost               0.839125  0.209199  0.052645  0.005638   \n",
       "              Bagging                0.825936  0.167936  0.055790  0.006172   \n",
       "              DecisionTreeRegressor  0.721405  0.106890  0.072969  0.010169   \n",
       "              GradientBoosting       0.838738  0.235674  0.052217  0.005591   \n",
       "              LightGBM               0.838668  0.230371  0.052891  0.005663   \n",
       "              LinearRegression       0.838386  0.186979  0.052660  0.005796   \n",
       "              NeuralNetwork          0.831669  0.154839  0.056572  0.006546   \n",
       "              RandomForest           0.837929  0.222782  0.052983  0.005667   \n",
       "              Ridge                  0.838386  0.186989  0.052659  0.005796   \n",
       "label_low_20  AdaBoost               0.861635  0.136632  0.070669  0.011431   \n",
       "              Bagging                0.852947  0.097892  0.073458  0.012051   \n",
       "              DecisionTreeRegressor  0.744654  0.050631  0.092057  0.016842   \n",
       "              GradientBoosting       0.861459  0.134859  0.070425  0.011492   \n",
       "              LightGBM               0.860791  0.131478  0.071171  0.011551   \n",
       "              LinearRegression       0.861248  0.128364  0.070724  0.011611   \n",
       "              NeuralNetwork          0.858434  0.089398  0.073816  0.012785   \n",
       "              RandomForest           0.860755  0.123695  0.071145  0.011534   \n",
       "              Ridge                  0.861248  0.128389  0.070723  0.011611   \n",
       "label_low_5   AdaBoost               0.809757  0.203575  0.045896  0.004297   \n",
       "              Bagging                0.792945  0.195619  0.048573  0.004674   \n",
       "              DecisionTreeRegressor  0.685777  0.080108  0.068966  0.009258   \n",
       "              GradientBoosting       0.809370  0.261767  0.045258  0.004183   \n",
       "              LightGBM               0.809159  0.262591  0.045797  0.004240   \n",
       "              LinearRegression       0.809018  0.204451  0.045656  0.004349   \n",
       "              NeuralNetwork          0.799733  0.150892  0.048196  0.004880   \n",
       "              RandomForest           0.807295  0.250070  0.045948  0.004263   \n",
       "              Ridge                  0.809018  0.204461  0.045655  0.004349   \n",
       "\n",
       "                                        MedAE         R2  SpearmanCorr  \n",
       "center_10     AdaBoost               0.124837  -2.010599     -0.027991  \n",
       "              Bagging                0.042218  -0.130367      0.081493  \n",
       "              DecisionTreeRegressor  0.057252  -1.366928      0.048949  \n",
       "              GradientBoosting       0.037574  -0.026755      0.117475  \n",
       "              LightGBM               0.038505  -0.010480      0.097976  \n",
       "              LinearRegression       0.038197  -0.045522     -0.017808  \n",
       "              NeuralNetwork          0.041736  -0.248152      0.014831  \n",
       "              RandomForest           0.039285  -0.025474      0.115414  \n",
       "              Ridge                  0.038196  -0.045512     -0.017801  \n",
       "center_20     AdaBoost               0.174910  -3.468416      0.040184  \n",
       "              Bagging                0.055407  -0.218167      0.065939  \n",
       "              DecisionTreeRegressor  0.072657  -1.660590      0.002317  \n",
       "              GradientBoosting       0.049450  -0.050148      0.092979  \n",
       "              LightGBM               0.050081  -0.046832      0.091972  \n",
       "              LinearRegression       0.050346  -0.047430     -0.010972  \n",
       "              NeuralNetwork          0.064933  -0.579342      0.013965  \n",
       "              RandomForest           0.051989  -0.075133      0.099631  \n",
       "              Ridge                  0.050339  -0.047394     -0.010932  \n",
       "center_5      AdaBoost               0.079301  -0.896244     -0.001081  \n",
       "              Bagging                0.035404  -0.092857      0.113192  \n",
       "              DecisionTreeRegressor  0.050205  -1.041484      0.042347  \n",
       "              GradientBoosting       0.031251   0.009652      0.151832  \n",
       "              LightGBM               0.031594   0.015432      0.150301  \n",
       "              LinearRegression       0.031423  -0.026917      0.022006  \n",
       "              NeuralNetwork          0.034188  -0.350227      0.029755  \n",
       "              RandomForest           0.032592   0.001081      0.147102  \n",
       "              Ridge                  0.031425  -0.026902      0.022017  \n",
       "high_low_10   AdaBoost               0.294551  -8.864832      0.313208  \n",
       "              Bagging                0.037468   0.069561      0.510808  \n",
       "              DecisionTreeRegressor  0.043955  -1.218556      0.368528  \n",
       "              GradientBoosting       0.033226   0.169734      0.587221  \n",
       "              LightGBM               0.033696   0.214496      0.567521  \n",
       "              LinearRegression       0.033827   0.186119      0.536681  \n",
       "              NeuralNetwork          0.036526  -0.058757      0.441758  \n",
       "              RandomForest           0.036452   0.202381      0.569616  \n",
       "              Ridge                  0.033826   0.186131      0.536692  \n",
       "high_low_20   AdaBoost               0.353059  -6.232500      0.295399  \n",
       "              Bagging                0.056461  -0.013724      0.440898  \n",
       "              DecisionTreeRegressor  0.065400  -1.188648      0.303937  \n",
       "              GradientBoosting       0.049887   0.038141      0.508551  \n",
       "              LightGBM               0.050663   0.091616      0.487113  \n",
       "              LinearRegression       0.051466   0.116861      0.472462  \n",
       "              NeuralNetwork          0.053591  -0.146641      0.362691  \n",
       "              RandomForest           0.054784   0.084194      0.487698  \n",
       "              Ridge                  0.051475   0.116876      0.472480  \n",
       "high_low_5    AdaBoost               0.153993  -4.033517      0.367377  \n",
       "              Bagging                0.027529   0.175178      0.545088  \n",
       "              DecisionTreeRegressor  0.034060  -0.815535      0.368994  \n",
       "              GradientBoosting       0.024418   0.274102      0.614411  \n",
       "              LightGBM               0.024807   0.279427      0.604291  \n",
       "              LinearRegression       0.025178   0.224096      0.566273  \n",
       "              NeuralNetwork          0.026040   0.170455      0.546449  \n",
       "              RandomForest           0.026827   0.247095      0.595250  \n",
       "              Ridge                  0.025179   0.224109      0.566281  \n",
       "label_high_10 AdaBoost               0.398873 -10.218295      0.030216  \n",
       "              Bagging                0.050876  -0.162169      0.190137  \n",
       "              DecisionTreeRegressor  0.064640  -1.612199      0.077939  \n",
       "              GradientBoosting       0.044770   0.029855      0.257074  \n",
       "              LightGBM               0.044353   0.052453      0.249099  \n",
       "              LinearRegression       0.045580   0.018160      0.179212  \n",
       "              NeuralNetwork          0.055530  -0.373744      0.082978  \n",
       "              RandomForest           0.048192   0.014319      0.252100  \n",
       "              Ridge                  0.045577   0.018171      0.179231  \n",
       "label_high_20 AdaBoost               0.559415 -12.466396      0.104557  \n",
       "              Bagging                0.067394  -0.191077      0.208057  \n",
       "              DecisionTreeRegressor  0.081330  -1.610775      0.084727  \n",
       "              GradientBoosting       0.060109  -0.079054      0.284256  \n",
       "              LightGBM               0.059949  -0.000606      0.258291  \n",
       "              LinearRegression       0.062671   0.033155      0.221539  \n",
       "              NeuralNetwork          0.068177  -0.364645      0.101254  \n",
       "              RandomForest           0.065801  -0.025531      0.274139  \n",
       "              Ridge                  0.062674   0.033188      0.221573  \n",
       "label_high_5  AdaBoost               0.199650  -3.532514      0.032827  \n",
       "              Bagging                0.040494  -0.046169      0.165691  \n",
       "              DecisionTreeRegressor  0.053605  -1.034316      0.080623  \n",
       "              GradientBoosting       0.035396   0.052199      0.246830  \n",
       "              LightGBM               0.035183   0.067889      0.233647  \n",
       "              LinearRegression       0.036327   0.023363      0.155636  \n",
       "              NeuralNetwork          0.040325  -0.204936      0.080216  \n",
       "              RandomForest           0.037669   0.050942      0.235183  \n",
       "              Ridge                  0.036328   0.023380      0.155651  \n",
       "label_low_10  AdaBoost               0.036069   0.032245      0.194094  \n",
       "              Bagging                0.039570  -0.059369      0.171865  \n",
       "              DecisionTreeRegressor  0.053115  -0.745397      0.108881  \n",
       "              GradientBoosting       0.035800   0.040291      0.227156  \n",
       "              LightGBM               0.036842   0.027977      0.226664  \n",
       "              LinearRegression       0.035226   0.005158      0.189099  \n",
       "              NeuralNetwork          0.040424  -0.123588      0.163965  \n",
       "              RandomForest           0.037021   0.027309      0.222156  \n",
       "              Ridge                  0.035231   0.005168      0.189107  \n",
       "label_low_20  AdaBoost               0.043725  -0.041823      0.133656  \n",
       "              Bagging                0.047095  -0.098338      0.115693  \n",
       "              DecisionTreeRegressor  0.064200  -0.535023      0.060033  \n",
       "              GradientBoosting       0.043452  -0.047391      0.144092  \n",
       "              LightGBM               0.044744  -0.052812      0.146309  \n",
       "              LinearRegression       0.043049  -0.058265      0.135610  \n",
       "              NeuralNetwork          0.048188  -0.165263      0.112928  \n",
       "              RandomForest           0.044926  -0.051225      0.145896  \n",
       "              Ridge                  0.043047  -0.058244      0.135623  \n",
       "label_low_5   AdaBoost               0.031621   0.036864      0.196345  \n",
       "              Bagging                0.034573  -0.047650      0.201043  \n",
       "              DecisionTreeRegressor  0.049495  -1.075137      0.093706  \n",
       "              GradientBoosting       0.031618   0.062387      0.263141  \n",
       "              LightGBM               0.032450   0.049681      0.260743  \n",
       "              LinearRegression       0.030967   0.025303      0.209576  \n",
       "              NeuralNetwork          0.033340  -0.093742      0.176873  \n",
       "              RandomForest           0.032554   0.044544      0.252709  \n",
       "              Ridge                  0.030968   0.025313      0.209583  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# テストデータ\n",
    "scores_test = {}\n",
    "for model_name, _ in models.items():\n",
    "    for label in Y_cols:\n",
    "        # load model\n",
    "        load_model_name = model_name + '_' + label + '.pickle'\n",
    "        load_path = os.path.join(save_dir, load_model_name)\n",
    "        with open(load_path, mode='rb') as fp:\n",
    "            model = pickle.load(fp)\n",
    "        \n",
    "        # predict test \n",
    "        scores_test[(label, model_name, 'MSE')] = mean_squared_error(test_Y[label], model.predict(test_X))\n",
    "        scores_test[(label, model_name, 'MAE')] = mean_absolute_error(test_Y[label], model.predict(test_X))\n",
    "        scores_test[(label, model_name, 'MedAE')] = median_absolute_error(test_Y[label], model.predict(test_X))\n",
    "        scores_test[(label, model_name, 'R2')] = r2_score(test_Y[label], model.predict(test_X))\n",
    "        scores_test[(label, model_name, 'Accuracy')] = accuracy_score(np.sign(test_Y[label]), np.sign(model.predict(test_X)))\n",
    "        scores_test[(label, model_name, 'Corr')] = np.corrcoef(test_Y[label], model.predict(test_X))[0, 1]\n",
    "        scores_test[(label, model_name, 'SpearmanCorr')] = spearmanr(test_Y[label], model.predict(test_X))[0]\n",
    "\n",
    "result_test = pd.Series(scores_test).unstack()\n",
    "result_test.to_csv('../result/ML_test_result.csv')\n",
    "result_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 108\n",
    "pd.options.display.max_columns = 108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Corr</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MedAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>SpearmanCorr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">center_10</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.420134</td>\n",
       "      <td>0.024308</td>\n",
       "      <td>0.137910</td>\n",
       "      <td>0.023743</td>\n",
       "      <td>0.132745</td>\n",
       "      <td>-2.506103</td>\n",
       "      <td>0.024630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.529157</td>\n",
       "      <td>0.142673</td>\n",
       "      <td>0.060803</td>\n",
       "      <td>0.007523</td>\n",
       "      <td>0.042488</td>\n",
       "      <td>-0.110913</td>\n",
       "      <td>0.132909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.514840</td>\n",
       "      <td>0.042630</td>\n",
       "      <td>0.082384</td>\n",
       "      <td>0.015517</td>\n",
       "      <td>0.055470</td>\n",
       "      <td>-1.291317</td>\n",
       "      <td>0.052611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.523117</td>\n",
       "      <td>0.182304</td>\n",
       "      <td>0.057013</td>\n",
       "      <td>0.006771</td>\n",
       "      <td>0.039317</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.187757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.545861</td>\n",
       "      <td>0.211869</td>\n",
       "      <td>0.056660</td>\n",
       "      <td>0.006695</td>\n",
       "      <td>0.039192</td>\n",
       "      <td>0.011337</td>\n",
       "      <td>0.205938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.473676</td>\n",
       "      <td>0.142694</td>\n",
       "      <td>0.057490</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>0.040137</td>\n",
       "      <td>-0.009502</td>\n",
       "      <td>0.107155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.521178</td>\n",
       "      <td>0.040402</td>\n",
       "      <td>0.060525</td>\n",
       "      <td>0.007945</td>\n",
       "      <td>0.041319</td>\n",
       "      <td>-0.173178</td>\n",
       "      <td>0.063202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.538404</td>\n",
       "      <td>0.215088</td>\n",
       "      <td>0.057601</td>\n",
       "      <td>0.006812</td>\n",
       "      <td>0.040249</td>\n",
       "      <td>-0.005902</td>\n",
       "      <td>0.203765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.473676</td>\n",
       "      <td>0.142691</td>\n",
       "      <td>0.057490</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>0.040137</td>\n",
       "      <td>-0.009503</td>\n",
       "      <td>0.107155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">center_20</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.422222</td>\n",
       "      <td>-0.043726</td>\n",
       "      <td>0.188177</td>\n",
       "      <td>0.052017</td>\n",
       "      <td>0.167179</td>\n",
       "      <td>-4.778048</td>\n",
       "      <td>-0.087202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.505369</td>\n",
       "      <td>0.124060</td>\n",
       "      <td>0.073593</td>\n",
       "      <td>0.011323</td>\n",
       "      <td>0.052272</td>\n",
       "      <td>-0.257751</td>\n",
       "      <td>0.120921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.506935</td>\n",
       "      <td>0.034175</td>\n",
       "      <td>0.099583</td>\n",
       "      <td>0.030483</td>\n",
       "      <td>0.063645</td>\n",
       "      <td>-2.386030</td>\n",
       "      <td>0.047454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.470619</td>\n",
       "      <td>0.129694</td>\n",
       "      <td>0.068047</td>\n",
       "      <td>0.009725</td>\n",
       "      <td>0.048773</td>\n",
       "      <td>-0.080281</td>\n",
       "      <td>0.141435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.501939</td>\n",
       "      <td>0.157070</td>\n",
       "      <td>0.067977</td>\n",
       "      <td>0.009661</td>\n",
       "      <td>0.048408</td>\n",
       "      <td>-0.073149</td>\n",
       "      <td>0.156370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.433855</td>\n",
       "      <td>0.117598</td>\n",
       "      <td>0.068197</td>\n",
       "      <td>0.009514</td>\n",
       "      <td>0.049734</td>\n",
       "      <td>-0.056841</td>\n",
       "      <td>0.073709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.480239</td>\n",
       "      <td>0.031122</td>\n",
       "      <td>0.085463</td>\n",
       "      <td>0.015097</td>\n",
       "      <td>0.060035</td>\n",
       "      <td>-0.676960</td>\n",
       "      <td>0.037134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.495600</td>\n",
       "      <td>0.168425</td>\n",
       "      <td>0.069705</td>\n",
       "      <td>0.009984</td>\n",
       "      <td>0.050305</td>\n",
       "      <td>-0.109001</td>\n",
       "      <td>0.169386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.433930</td>\n",
       "      <td>0.117602</td>\n",
       "      <td>0.068197</td>\n",
       "      <td>0.009514</td>\n",
       "      <td>0.049732</td>\n",
       "      <td>-0.056840</td>\n",
       "      <td>0.073695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">center_5</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.418121</td>\n",
       "      <td>0.050884</td>\n",
       "      <td>0.092301</td>\n",
       "      <td>0.011706</td>\n",
       "      <td>0.085299</td>\n",
       "      <td>-1.083084</td>\n",
       "      <td>0.061834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.552349</td>\n",
       "      <td>0.160580</td>\n",
       "      <td>0.053799</td>\n",
       "      <td>0.005928</td>\n",
       "      <td>0.037040</td>\n",
       "      <td>-0.054902</td>\n",
       "      <td>0.157430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.522222</td>\n",
       "      <td>0.059820</td>\n",
       "      <td>0.072053</td>\n",
       "      <td>0.010862</td>\n",
       "      <td>0.049425</td>\n",
       "      <td>-0.932837</td>\n",
       "      <td>0.066658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.564952</td>\n",
       "      <td>0.213276</td>\n",
       "      <td>0.050575</td>\n",
       "      <td>0.005436</td>\n",
       "      <td>0.034041</td>\n",
       "      <td>0.032634</td>\n",
       "      <td>0.206408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.575913</td>\n",
       "      <td>0.239190</td>\n",
       "      <td>0.050289</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>0.033998</td>\n",
       "      <td>0.045828</td>\n",
       "      <td>0.230815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.503952</td>\n",
       "      <td>0.120182</td>\n",
       "      <td>0.051432</td>\n",
       "      <td>0.005617</td>\n",
       "      <td>0.034597</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.101465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.543177</td>\n",
       "      <td>0.100149</td>\n",
       "      <td>0.052673</td>\n",
       "      <td>0.005917</td>\n",
       "      <td>0.035364</td>\n",
       "      <td>-0.052852</td>\n",
       "      <td>0.084550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.561372</td>\n",
       "      <td>0.217538</td>\n",
       "      <td>0.051010</td>\n",
       "      <td>0.005479</td>\n",
       "      <td>0.034763</td>\n",
       "      <td>0.025096</td>\n",
       "      <td>0.216564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.503952</td>\n",
       "      <td>0.120178</td>\n",
       "      <td>0.051432</td>\n",
       "      <td>0.005617</td>\n",
       "      <td>0.034598</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.101468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">high_low_10</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.999627</td>\n",
       "      <td>0.263731</td>\n",
       "      <td>0.287472</td>\n",
       "      <td>0.095012</td>\n",
       "      <td>0.287934</td>\n",
       "      <td>-12.359087</td>\n",
       "      <td>0.256781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.999627</td>\n",
       "      <td>0.473107</td>\n",
       "      <td>0.049735</td>\n",
       "      <td>0.006187</td>\n",
       "      <td>0.033184</td>\n",
       "      <td>0.130021</td>\n",
       "      <td>0.557675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.999329</td>\n",
       "      <td>0.279398</td>\n",
       "      <td>0.070124</td>\n",
       "      <td>0.015602</td>\n",
       "      <td>0.041750</td>\n",
       "      <td>-1.193737</td>\n",
       "      <td>0.400595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.999627</td>\n",
       "      <td>0.544686</td>\n",
       "      <td>0.043947</td>\n",
       "      <td>0.005150</td>\n",
       "      <td>0.029389</td>\n",
       "      <td>0.275831</td>\n",
       "      <td>0.627276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.999627</td>\n",
       "      <td>0.535395</td>\n",
       "      <td>0.045206</td>\n",
       "      <td>0.005226</td>\n",
       "      <td>0.030195</td>\n",
       "      <td>0.265179</td>\n",
       "      <td>0.614326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.999553</td>\n",
       "      <td>0.557353</td>\n",
       "      <td>0.044527</td>\n",
       "      <td>0.005110</td>\n",
       "      <td>0.029892</td>\n",
       "      <td>0.281580</td>\n",
       "      <td>0.592527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.991573</td>\n",
       "      <td>0.410532</td>\n",
       "      <td>0.054709</td>\n",
       "      <td>0.007554</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>-0.062193</td>\n",
       "      <td>0.479203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.999627</td>\n",
       "      <td>0.549571</td>\n",
       "      <td>0.045880</td>\n",
       "      <td>0.005102</td>\n",
       "      <td>0.031954</td>\n",
       "      <td>0.282604</td>\n",
       "      <td>0.608181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.999553</td>\n",
       "      <td>0.557355</td>\n",
       "      <td>0.044526</td>\n",
       "      <td>0.005109</td>\n",
       "      <td>0.029892</td>\n",
       "      <td>0.281585</td>\n",
       "      <td>0.592534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">high_low_20</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.318262</td>\n",
       "      <td>0.384869</td>\n",
       "      <td>0.175188</td>\n",
       "      <td>0.359848</td>\n",
       "      <td>-12.074703</td>\n",
       "      <td>0.347164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.408949</td>\n",
       "      <td>0.070104</td>\n",
       "      <td>0.014434</td>\n",
       "      <td>0.042751</td>\n",
       "      <td>-0.077274</td>\n",
       "      <td>0.561044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.219531</td>\n",
       "      <td>0.098577</td>\n",
       "      <td>0.040542</td>\n",
       "      <td>0.054965</td>\n",
       "      <td>-2.025705</td>\n",
       "      <td>0.379155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.491420</td>\n",
       "      <td>0.056553</td>\n",
       "      <td>0.010486</td>\n",
       "      <td>0.036619</td>\n",
       "      <td>0.217389</td>\n",
       "      <td>0.642803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.487026</td>\n",
       "      <td>0.058922</td>\n",
       "      <td>0.010610</td>\n",
       "      <td>0.037573</td>\n",
       "      <td>0.208125</td>\n",
       "      <td>0.616175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.519990</td>\n",
       "      <td>0.055974</td>\n",
       "      <td>0.009858</td>\n",
       "      <td>0.037580</td>\n",
       "      <td>0.264238</td>\n",
       "      <td>0.613436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.990306</td>\n",
       "      <td>0.343723</td>\n",
       "      <td>0.071632</td>\n",
       "      <td>0.015190</td>\n",
       "      <td>0.044098</td>\n",
       "      <td>-0.133639</td>\n",
       "      <td>0.450248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.494399</td>\n",
       "      <td>0.062270</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.040587</td>\n",
       "      <td>0.172270</td>\n",
       "      <td>0.614976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.519998</td>\n",
       "      <td>0.055973</td>\n",
       "      <td>0.009858</td>\n",
       "      <td>0.037578</td>\n",
       "      <td>0.264250</td>\n",
       "      <td>0.613447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">high_low_5</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.998658</td>\n",
       "      <td>0.366141</td>\n",
       "      <td>0.148689</td>\n",
       "      <td>0.025713</td>\n",
       "      <td>0.147549</td>\n",
       "      <td>-4.806153</td>\n",
       "      <td>0.377422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.998658</td>\n",
       "      <td>0.520054</td>\n",
       "      <td>0.038322</td>\n",
       "      <td>0.003369</td>\n",
       "      <td>0.026423</td>\n",
       "      <td>0.239323</td>\n",
       "      <td>0.556814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.996943</td>\n",
       "      <td>0.318502</td>\n",
       "      <td>0.052824</td>\n",
       "      <td>0.007192</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>-0.624011</td>\n",
       "      <td>0.389474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.998658</td>\n",
       "      <td>0.585767</td>\n",
       "      <td>0.034969</td>\n",
       "      <td>0.003029</td>\n",
       "      <td>0.023603</td>\n",
       "      <td>0.316111</td>\n",
       "      <td>0.623022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.998658</td>\n",
       "      <td>0.581828</td>\n",
       "      <td>0.035280</td>\n",
       "      <td>0.003021</td>\n",
       "      <td>0.023929</td>\n",
       "      <td>0.317764</td>\n",
       "      <td>0.615827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.998583</td>\n",
       "      <td>0.564813</td>\n",
       "      <td>0.036349</td>\n",
       "      <td>0.003251</td>\n",
       "      <td>0.024288</td>\n",
       "      <td>0.266019</td>\n",
       "      <td>0.582718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.996644</td>\n",
       "      <td>0.537861</td>\n",
       "      <td>0.038305</td>\n",
       "      <td>0.003421</td>\n",
       "      <td>0.025677</td>\n",
       "      <td>0.227415</td>\n",
       "      <td>0.568824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.998658</td>\n",
       "      <td>0.572924</td>\n",
       "      <td>0.035871</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.025223</td>\n",
       "      <td>0.321972</td>\n",
       "      <td>0.607117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.998583</td>\n",
       "      <td>0.564815</td>\n",
       "      <td>0.036349</td>\n",
       "      <td>0.003251</td>\n",
       "      <td>0.024288</td>\n",
       "      <td>0.266022</td>\n",
       "      <td>0.582723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">label_high_10</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.734228</td>\n",
       "      <td>0.095896</td>\n",
       "      <td>0.390636</td>\n",
       "      <td>0.164861</td>\n",
       "      <td>0.408918</td>\n",
       "      <td>-13.813186</td>\n",
       "      <td>0.092629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.731245</td>\n",
       "      <td>0.249367</td>\n",
       "      <td>0.074167</td>\n",
       "      <td>0.012336</td>\n",
       "      <td>0.049741</td>\n",
       "      <td>-0.108461</td>\n",
       "      <td>0.231632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.637062</td>\n",
       "      <td>0.143386</td>\n",
       "      <td>0.103763</td>\n",
       "      <td>0.031767</td>\n",
       "      <td>0.061110</td>\n",
       "      <td>-1.854325</td>\n",
       "      <td>0.104670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.734228</td>\n",
       "      <td>0.270128</td>\n",
       "      <td>0.067495</td>\n",
       "      <td>0.010773</td>\n",
       "      <td>0.045032</td>\n",
       "      <td>0.031977</td>\n",
       "      <td>0.281553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.733557</td>\n",
       "      <td>0.292331</td>\n",
       "      <td>0.067327</td>\n",
       "      <td>0.010517</td>\n",
       "      <td>0.044672</td>\n",
       "      <td>0.055023</td>\n",
       "      <td>0.285515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.733706</td>\n",
       "      <td>0.284786</td>\n",
       "      <td>0.066946</td>\n",
       "      <td>0.010279</td>\n",
       "      <td>0.044815</td>\n",
       "      <td>0.076416</td>\n",
       "      <td>0.216658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.685086</td>\n",
       "      <td>0.140748</td>\n",
       "      <td>0.082881</td>\n",
       "      <td>0.015665</td>\n",
       "      <td>0.054731</td>\n",
       "      <td>-0.407503</td>\n",
       "      <td>0.103992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.734452</td>\n",
       "      <td>0.310894</td>\n",
       "      <td>0.069915</td>\n",
       "      <td>0.010740</td>\n",
       "      <td>0.048766</td>\n",
       "      <td>0.035011</td>\n",
       "      <td>0.286244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.733706</td>\n",
       "      <td>0.284786</td>\n",
       "      <td>0.066946</td>\n",
       "      <td>0.010279</td>\n",
       "      <td>0.044813</td>\n",
       "      <td>0.076416</td>\n",
       "      <td>0.216656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">label_high_20</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.777256</td>\n",
       "      <td>0.031463</td>\n",
       "      <td>0.533647</td>\n",
       "      <td>0.358765</td>\n",
       "      <td>0.547722</td>\n",
       "      <td>-19.180045</td>\n",
       "      <td>0.009560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.776212</td>\n",
       "      <td>0.244077</td>\n",
       "      <td>0.096826</td>\n",
       "      <td>0.022327</td>\n",
       "      <td>0.065380</td>\n",
       "      <td>-0.255868</td>\n",
       "      <td>0.245048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.682103</td>\n",
       "      <td>0.116297</td>\n",
       "      <td>0.131615</td>\n",
       "      <td>0.060672</td>\n",
       "      <td>0.074005</td>\n",
       "      <td>-2.412704</td>\n",
       "      <td>0.124359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.777256</td>\n",
       "      <td>0.267705</td>\n",
       "      <td>0.084362</td>\n",
       "      <td>0.017709</td>\n",
       "      <td>0.059053</td>\n",
       "      <td>0.003885</td>\n",
       "      <td>0.282070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.777032</td>\n",
       "      <td>0.272255</td>\n",
       "      <td>0.085965</td>\n",
       "      <td>0.018097</td>\n",
       "      <td>0.058706</td>\n",
       "      <td>-0.017958</td>\n",
       "      <td>0.280592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.777032</td>\n",
       "      <td>0.279058</td>\n",
       "      <td>0.083948</td>\n",
       "      <td>0.016847</td>\n",
       "      <td>0.060103</td>\n",
       "      <td>0.052365</td>\n",
       "      <td>0.229728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.744146</td>\n",
       "      <td>0.110115</td>\n",
       "      <td>0.102953</td>\n",
       "      <td>0.027058</td>\n",
       "      <td>0.065840</td>\n",
       "      <td>-0.521957</td>\n",
       "      <td>0.107441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.777256</td>\n",
       "      <td>0.294539</td>\n",
       "      <td>0.091392</td>\n",
       "      <td>0.018920</td>\n",
       "      <td>0.065117</td>\n",
       "      <td>-0.064236</td>\n",
       "      <td>0.290375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.777032</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.083949</td>\n",
       "      <td>0.016847</td>\n",
       "      <td>0.060101</td>\n",
       "      <td>0.052372</td>\n",
       "      <td>0.229734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">label_high_5</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.698210</td>\n",
       "      <td>0.104913</td>\n",
       "      <td>0.197108</td>\n",
       "      <td>0.044630</td>\n",
       "      <td>0.205857</td>\n",
       "      <td>-4.427900</td>\n",
       "      <td>0.089399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.696048</td>\n",
       "      <td>0.246609</td>\n",
       "      <td>0.061397</td>\n",
       "      <td>0.008368</td>\n",
       "      <td>0.041222</td>\n",
       "      <td>-0.017769</td>\n",
       "      <td>0.233531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.599254</td>\n",
       "      <td>0.117590</td>\n",
       "      <td>0.083799</td>\n",
       "      <td>0.016827</td>\n",
       "      <td>0.053015</td>\n",
       "      <td>-1.046539</td>\n",
       "      <td>0.114258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.697390</td>\n",
       "      <td>0.301287</td>\n",
       "      <td>0.056971</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>0.037358</td>\n",
       "      <td>0.089160</td>\n",
       "      <td>0.281053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.698732</td>\n",
       "      <td>0.316480</td>\n",
       "      <td>0.056535</td>\n",
       "      <td>0.007415</td>\n",
       "      <td>0.037203</td>\n",
       "      <td>0.098165</td>\n",
       "      <td>0.296688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.697614</td>\n",
       "      <td>0.248769</td>\n",
       "      <td>0.057793</td>\n",
       "      <td>0.007715</td>\n",
       "      <td>0.037277</td>\n",
       "      <td>0.061650</td>\n",
       "      <td>0.186100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.653020</td>\n",
       "      <td>0.111492</td>\n",
       "      <td>0.063265</td>\n",
       "      <td>0.009516</td>\n",
       "      <td>0.040436</td>\n",
       "      <td>-0.157372</td>\n",
       "      <td>0.103417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.700969</td>\n",
       "      <td>0.318816</td>\n",
       "      <td>0.058133</td>\n",
       "      <td>0.007498</td>\n",
       "      <td>0.039366</td>\n",
       "      <td>0.088148</td>\n",
       "      <td>0.291807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.697614</td>\n",
       "      <td>0.248769</td>\n",
       "      <td>0.057793</td>\n",
       "      <td>0.007715</td>\n",
       "      <td>0.037274</td>\n",
       "      <td>0.061650</td>\n",
       "      <td>0.186101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">label_low_10</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.851380</td>\n",
       "      <td>0.255727</td>\n",
       "      <td>0.055023</td>\n",
       "      <td>0.005887</td>\n",
       "      <td>0.038198</td>\n",
       "      <td>0.014045</td>\n",
       "      <td>0.252602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.836987</td>\n",
       "      <td>0.235640</td>\n",
       "      <td>0.056193</td>\n",
       "      <td>0.006104</td>\n",
       "      <td>0.040099</td>\n",
       "      <td>-0.022414</td>\n",
       "      <td>0.237511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.716331</td>\n",
       "      <td>0.111224</td>\n",
       "      <td>0.073111</td>\n",
       "      <td>0.010037</td>\n",
       "      <td>0.053530</td>\n",
       "      <td>-0.681043</td>\n",
       "      <td>0.112186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.851007</td>\n",
       "      <td>0.303035</td>\n",
       "      <td>0.054244</td>\n",
       "      <td>0.005807</td>\n",
       "      <td>0.037537</td>\n",
       "      <td>0.027315</td>\n",
       "      <td>0.306749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.851380</td>\n",
       "      <td>0.324344</td>\n",
       "      <td>0.053743</td>\n",
       "      <td>0.005681</td>\n",
       "      <td>0.037099</td>\n",
       "      <td>0.048419</td>\n",
       "      <td>0.319544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.850932</td>\n",
       "      <td>0.285087</td>\n",
       "      <td>0.054961</td>\n",
       "      <td>0.005948</td>\n",
       "      <td>0.037519</td>\n",
       "      <td>0.003712</td>\n",
       "      <td>0.298701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.844370</td>\n",
       "      <td>0.205720</td>\n",
       "      <td>0.056041</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>0.039831</td>\n",
       "      <td>-0.023688</td>\n",
       "      <td>0.222281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.849963</td>\n",
       "      <td>0.313238</td>\n",
       "      <td>0.053807</td>\n",
       "      <td>0.005668</td>\n",
       "      <td>0.037649</td>\n",
       "      <td>0.050702</td>\n",
       "      <td>0.309306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.850932</td>\n",
       "      <td>0.285085</td>\n",
       "      <td>0.054961</td>\n",
       "      <td>0.005948</td>\n",
       "      <td>0.037519</td>\n",
       "      <td>0.003713</td>\n",
       "      <td>0.298701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">label_low_20</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.886950</td>\n",
       "      <td>0.250468</td>\n",
       "      <td>0.061071</td>\n",
       "      <td>0.007114</td>\n",
       "      <td>0.043295</td>\n",
       "      <td>-0.027033</td>\n",
       "      <td>0.266205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.875019</td>\n",
       "      <td>0.253723</td>\n",
       "      <td>0.061975</td>\n",
       "      <td>0.007227</td>\n",
       "      <td>0.044873</td>\n",
       "      <td>-0.043450</td>\n",
       "      <td>0.244284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.762192</td>\n",
       "      <td>0.120023</td>\n",
       "      <td>0.078882</td>\n",
       "      <td>0.011334</td>\n",
       "      <td>0.059125</td>\n",
       "      <td>-0.636399</td>\n",
       "      <td>0.114935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.887025</td>\n",
       "      <td>0.334142</td>\n",
       "      <td>0.059890</td>\n",
       "      <td>0.006905</td>\n",
       "      <td>0.042254</td>\n",
       "      <td>0.003065</td>\n",
       "      <td>0.340903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.887025</td>\n",
       "      <td>0.349974</td>\n",
       "      <td>0.059233</td>\n",
       "      <td>0.006719</td>\n",
       "      <td>0.042107</td>\n",
       "      <td>0.029984</td>\n",
       "      <td>0.345673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.886875</td>\n",
       "      <td>0.313163</td>\n",
       "      <td>0.060942</td>\n",
       "      <td>0.007110</td>\n",
       "      <td>0.043209</td>\n",
       "      <td>-0.026582</td>\n",
       "      <td>0.331691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.884340</td>\n",
       "      <td>0.243225</td>\n",
       "      <td>0.060560</td>\n",
       "      <td>0.006973</td>\n",
       "      <td>0.043623</td>\n",
       "      <td>-0.006738</td>\n",
       "      <td>0.250649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.886428</td>\n",
       "      <td>0.323396</td>\n",
       "      <td>0.059563</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>0.042107</td>\n",
       "      <td>0.019025</td>\n",
       "      <td>0.324515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.886875</td>\n",
       "      <td>0.313158</td>\n",
       "      <td>0.060942</td>\n",
       "      <td>0.007110</td>\n",
       "      <td>0.043214</td>\n",
       "      <td>-0.026585</td>\n",
       "      <td>0.331683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">label_low_5</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.816555</td>\n",
       "      <td>0.216448</td>\n",
       "      <td>0.050994</td>\n",
       "      <td>0.005175</td>\n",
       "      <td>0.034500</td>\n",
       "      <td>0.010857</td>\n",
       "      <td>0.230499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.799105</td>\n",
       "      <td>0.225233</td>\n",
       "      <td>0.051877</td>\n",
       "      <td>0.005259</td>\n",
       "      <td>0.036591</td>\n",
       "      <td>-0.005375</td>\n",
       "      <td>0.225451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.680537</td>\n",
       "      <td>0.115531</td>\n",
       "      <td>0.067557</td>\n",
       "      <td>0.008744</td>\n",
       "      <td>0.049270</td>\n",
       "      <td>-0.671439</td>\n",
       "      <td>0.125558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.816033</td>\n",
       "      <td>0.302126</td>\n",
       "      <td>0.049645</td>\n",
       "      <td>0.004951</td>\n",
       "      <td>0.033953</td>\n",
       "      <td>0.053560</td>\n",
       "      <td>0.303306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.817375</td>\n",
       "      <td>0.314652</td>\n",
       "      <td>0.049300</td>\n",
       "      <td>0.004863</td>\n",
       "      <td>0.033761</td>\n",
       "      <td>0.070326</td>\n",
       "      <td>0.310753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.816480</td>\n",
       "      <td>0.260549</td>\n",
       "      <td>0.050540</td>\n",
       "      <td>0.005145</td>\n",
       "      <td>0.034016</td>\n",
       "      <td>0.016543</td>\n",
       "      <td>0.263162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.804176</td>\n",
       "      <td>0.190012</td>\n",
       "      <td>0.051919</td>\n",
       "      <td>0.005354</td>\n",
       "      <td>0.036028</td>\n",
       "      <td>-0.023422</td>\n",
       "      <td>0.202159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.816555</td>\n",
       "      <td>0.303002</td>\n",
       "      <td>0.049504</td>\n",
       "      <td>0.004898</td>\n",
       "      <td>0.033997</td>\n",
       "      <td>0.063808</td>\n",
       "      <td>0.302008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.816480</td>\n",
       "      <td>0.260549</td>\n",
       "      <td>0.050540</td>\n",
       "      <td>0.005145</td>\n",
       "      <td>0.034018</td>\n",
       "      <td>0.016547</td>\n",
       "      <td>0.263167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Accuracy      Corr       MAE       MSE  \\\n",
       "center_10     AdaBoost               0.420134  0.024308  0.137910  0.023743   \n",
       "              Bagging                0.529157  0.142673  0.060803  0.007523   \n",
       "              DecisionTreeRegressor  0.514840  0.042630  0.082384  0.015517   \n",
       "              GradientBoosting       0.523117  0.182304  0.057013  0.006771   \n",
       "              LightGBM               0.545861  0.211869  0.056660  0.006695   \n",
       "              LinearRegression       0.473676  0.142694  0.057490  0.006836   \n",
       "              NeuralNetwork          0.521178  0.040402  0.060525  0.007945   \n",
       "              RandomForest           0.538404  0.215088  0.057601  0.006812   \n",
       "              Ridge                  0.473676  0.142691  0.057490  0.006836   \n",
       "center_20     AdaBoost               0.422222 -0.043726  0.188177  0.052017   \n",
       "              Bagging                0.505369  0.124060  0.073593  0.011323   \n",
       "              DecisionTreeRegressor  0.506935  0.034175  0.099583  0.030483   \n",
       "              GradientBoosting       0.470619  0.129694  0.068047  0.009725   \n",
       "              LightGBM               0.501939  0.157070  0.067977  0.009661   \n",
       "              LinearRegression       0.433855  0.117598  0.068197  0.009514   \n",
       "              NeuralNetwork          0.480239  0.031122  0.085463  0.015097   \n",
       "              RandomForest           0.495600  0.168425  0.069705  0.009984   \n",
       "              Ridge                  0.433930  0.117602  0.068197  0.009514   \n",
       "center_5      AdaBoost               0.418121  0.050884  0.092301  0.011706   \n",
       "              Bagging                0.552349  0.160580  0.053799  0.005928   \n",
       "              DecisionTreeRegressor  0.522222  0.059820  0.072053  0.010862   \n",
       "              GradientBoosting       0.564952  0.213276  0.050575  0.005436   \n",
       "              LightGBM               0.575913  0.239190  0.050289  0.005362   \n",
       "              LinearRegression       0.503952  0.120182  0.051432  0.005617   \n",
       "              NeuralNetwork          0.543177  0.100149  0.052673  0.005917   \n",
       "              RandomForest           0.561372  0.217538  0.051010  0.005479   \n",
       "              Ridge                  0.503952  0.120178  0.051432  0.005617   \n",
       "high_low_10   AdaBoost               0.999627  0.263731  0.287472  0.095012   \n",
       "              Bagging                0.999627  0.473107  0.049735  0.006187   \n",
       "              DecisionTreeRegressor  0.999329  0.279398  0.070124  0.015602   \n",
       "              GradientBoosting       0.999627  0.544686  0.043947  0.005150   \n",
       "              LightGBM               0.999627  0.535395  0.045206  0.005226   \n",
       "              LinearRegression       0.999553  0.557353  0.044527  0.005110   \n",
       "              NeuralNetwork          0.991573  0.410532  0.054709  0.007554   \n",
       "              RandomForest           0.999627  0.549571  0.045880  0.005102   \n",
       "              Ridge                  0.999553  0.557355  0.044526  0.005109   \n",
       "high_low_20   AdaBoost               1.000000  0.318262  0.384869  0.175188   \n",
       "              Bagging                1.000000  0.408949  0.070104  0.014434   \n",
       "              DecisionTreeRegressor  1.000000  0.219531  0.098577  0.040542   \n",
       "              GradientBoosting       1.000000  0.491420  0.056553  0.010486   \n",
       "              LightGBM               1.000000  0.487026  0.058922  0.010610   \n",
       "              LinearRegression       1.000000  0.519990  0.055974  0.009858   \n",
       "              NeuralNetwork          0.990306  0.343723  0.071632  0.015190   \n",
       "              RandomForest           1.000000  0.494399  0.062270  0.011091   \n",
       "              Ridge                  1.000000  0.519998  0.055973  0.009858   \n",
       "high_low_5    AdaBoost               0.998658  0.366141  0.148689  0.025713   \n",
       "              Bagging                0.998658  0.520054  0.038322  0.003369   \n",
       "              DecisionTreeRegressor  0.996943  0.318502  0.052824  0.007192   \n",
       "              GradientBoosting       0.998658  0.585767  0.034969  0.003029   \n",
       "              LightGBM               0.998658  0.581828  0.035280  0.003021   \n",
       "              LinearRegression       0.998583  0.564813  0.036349  0.003251   \n",
       "              NeuralNetwork          0.996644  0.537861  0.038305  0.003421   \n",
       "              RandomForest           0.998658  0.572924  0.035871  0.003003   \n",
       "              Ridge                  0.998583  0.564815  0.036349  0.003251   \n",
       "label_high_10 AdaBoost               0.734228  0.095896  0.390636  0.164861   \n",
       "              Bagging                0.731245  0.249367  0.074167  0.012336   \n",
       "              DecisionTreeRegressor  0.637062  0.143386  0.103763  0.031767   \n",
       "              GradientBoosting       0.734228  0.270128  0.067495  0.010773   \n",
       "              LightGBM               0.733557  0.292331  0.067327  0.010517   \n",
       "              LinearRegression       0.733706  0.284786  0.066946  0.010279   \n",
       "              NeuralNetwork          0.685086  0.140748  0.082881  0.015665   \n",
       "              RandomForest           0.734452  0.310894  0.069915  0.010740   \n",
       "              Ridge                  0.733706  0.284786  0.066946  0.010279   \n",
       "label_high_20 AdaBoost               0.777256  0.031463  0.533647  0.358765   \n",
       "              Bagging                0.776212  0.244077  0.096826  0.022327   \n",
       "              DecisionTreeRegressor  0.682103  0.116297  0.131615  0.060672   \n",
       "              GradientBoosting       0.777256  0.267705  0.084362  0.017709   \n",
       "              LightGBM               0.777032  0.272255  0.085965  0.018097   \n",
       "              LinearRegression       0.777032  0.279058  0.083948  0.016847   \n",
       "              NeuralNetwork          0.744146  0.110115  0.102953  0.027058   \n",
       "              RandomForest           0.777256  0.294539  0.091392  0.018920   \n",
       "              Ridge                  0.777032  0.279070  0.083949  0.016847   \n",
       "label_high_5  AdaBoost               0.698210  0.104913  0.197108  0.044630   \n",
       "              Bagging                0.696048  0.246609  0.061397  0.008368   \n",
       "              DecisionTreeRegressor  0.599254  0.117590  0.083799  0.016827   \n",
       "              GradientBoosting       0.697390  0.301287  0.056971  0.007489   \n",
       "              LightGBM               0.698732  0.316480  0.056535  0.007415   \n",
       "              LinearRegression       0.697614  0.248769  0.057793  0.007715   \n",
       "              NeuralNetwork          0.653020  0.111492  0.063265  0.009516   \n",
       "              RandomForest           0.700969  0.318816  0.058133  0.007498   \n",
       "              Ridge                  0.697614  0.248769  0.057793  0.007715   \n",
       "label_low_10  AdaBoost               0.851380  0.255727  0.055023  0.005887   \n",
       "              Bagging                0.836987  0.235640  0.056193  0.006104   \n",
       "              DecisionTreeRegressor  0.716331  0.111224  0.073111  0.010037   \n",
       "              GradientBoosting       0.851007  0.303035  0.054244  0.005807   \n",
       "              LightGBM               0.851380  0.324344  0.053743  0.005681   \n",
       "              LinearRegression       0.850932  0.285087  0.054961  0.005948   \n",
       "              NeuralNetwork          0.844370  0.205720  0.056041  0.006112   \n",
       "              RandomForest           0.849963  0.313238  0.053807  0.005668   \n",
       "              Ridge                  0.850932  0.285085  0.054961  0.005948   \n",
       "label_low_20  AdaBoost               0.886950  0.250468  0.061071  0.007114   \n",
       "              Bagging                0.875019  0.253723  0.061975  0.007227   \n",
       "              DecisionTreeRegressor  0.762192  0.120023  0.078882  0.011334   \n",
       "              GradientBoosting       0.887025  0.334142  0.059890  0.006905   \n",
       "              LightGBM               0.887025  0.349974  0.059233  0.006719   \n",
       "              LinearRegression       0.886875  0.313163  0.060942  0.007110   \n",
       "              NeuralNetwork          0.884340  0.243225  0.060560  0.006973   \n",
       "              RandomForest           0.886428  0.323396  0.059563  0.006795   \n",
       "              Ridge                  0.886875  0.313158  0.060942  0.007110   \n",
       "label_low_5   AdaBoost               0.816555  0.216448  0.050994  0.005175   \n",
       "              Bagging                0.799105  0.225233  0.051877  0.005259   \n",
       "              DecisionTreeRegressor  0.680537  0.115531  0.067557  0.008744   \n",
       "              GradientBoosting       0.816033  0.302126  0.049645  0.004951   \n",
       "              LightGBM               0.817375  0.314652  0.049300  0.004863   \n",
       "              LinearRegression       0.816480  0.260549  0.050540  0.005145   \n",
       "              NeuralNetwork          0.804176  0.190012  0.051919  0.005354   \n",
       "              RandomForest           0.816555  0.303002  0.049504  0.004898   \n",
       "              Ridge                  0.816480  0.260549  0.050540  0.005145   \n",
       "\n",
       "                                        MedAE         R2  SpearmanCorr  \n",
       "center_10     AdaBoost               0.132745  -2.506103      0.024630  \n",
       "              Bagging                0.042488  -0.110913      0.132909  \n",
       "              DecisionTreeRegressor  0.055470  -1.291317      0.052611  \n",
       "              GradientBoosting       0.039317   0.000153      0.187757  \n",
       "              LightGBM               0.039192   0.011337      0.205938  \n",
       "              LinearRegression       0.040137  -0.009502      0.107155  \n",
       "              NeuralNetwork          0.041319  -0.173178      0.063202  \n",
       "              RandomForest           0.040249  -0.005902      0.203765  \n",
       "              Ridge                  0.040137  -0.009503      0.107155  \n",
       "center_20     AdaBoost               0.167179  -4.778048     -0.087202  \n",
       "              Bagging                0.052272  -0.257751      0.120921  \n",
       "              DecisionTreeRegressor  0.063645  -2.386030      0.047454  \n",
       "              GradientBoosting       0.048773  -0.080281      0.141435  \n",
       "              LightGBM               0.048408  -0.073149      0.156370  \n",
       "              LinearRegression       0.049734  -0.056841      0.073709  \n",
       "              NeuralNetwork          0.060035  -0.676960      0.037134  \n",
       "              RandomForest           0.050305  -0.109001      0.169386  \n",
       "              Ridge                  0.049732  -0.056840      0.073695  \n",
       "center_5      AdaBoost               0.085299  -1.083084      0.061834  \n",
       "              Bagging                0.037040  -0.054902      0.157430  \n",
       "              DecisionTreeRegressor  0.049425  -0.932837      0.066658  \n",
       "              GradientBoosting       0.034041   0.032634      0.206408  \n",
       "              LightGBM               0.033998   0.045828      0.230815  \n",
       "              LinearRegression       0.034597   0.000391      0.101465  \n",
       "              NeuralNetwork          0.035364  -0.052852      0.084550  \n",
       "              RandomForest           0.034763   0.025096      0.216564  \n",
       "              Ridge                  0.034598   0.000392      0.101468  \n",
       "high_low_10   AdaBoost               0.287934 -12.359087      0.256781  \n",
       "              Bagging                0.033184   0.130021      0.557675  \n",
       "              DecisionTreeRegressor  0.041750  -1.193737      0.400595  \n",
       "              GradientBoosting       0.029389   0.275831      0.627276  \n",
       "              LightGBM               0.030195   0.265179      0.614326  \n",
       "              LinearRegression       0.029892   0.281580      0.592527  \n",
       "              NeuralNetwork          0.035088  -0.062193      0.479203  \n",
       "              RandomForest           0.031954   0.282604      0.608181  \n",
       "              Ridge                  0.029892   0.281585      0.592534  \n",
       "high_low_20   AdaBoost               0.359848 -12.074703      0.347164  \n",
       "              Bagging                0.042751  -0.077274      0.561044  \n",
       "              DecisionTreeRegressor  0.054965  -2.025705      0.379155  \n",
       "              GradientBoosting       0.036619   0.217389      0.642803  \n",
       "              LightGBM               0.037573   0.208125      0.616175  \n",
       "              LinearRegression       0.037580   0.264238      0.613436  \n",
       "              NeuralNetwork          0.044098  -0.133639      0.450248  \n",
       "              RandomForest           0.040587   0.172270      0.614976  \n",
       "              Ridge                  0.037578   0.264250      0.613447  \n",
       "high_low_5    AdaBoost               0.147549  -4.806153      0.377422  \n",
       "              Bagging                0.026423   0.239323      0.556814  \n",
       "              DecisionTreeRegressor  0.034300  -0.624011      0.389474  \n",
       "              GradientBoosting       0.023603   0.316111      0.623022  \n",
       "              LightGBM               0.023929   0.317764      0.615827  \n",
       "              LinearRegression       0.024288   0.266019      0.582718  \n",
       "              NeuralNetwork          0.025677   0.227415      0.568824  \n",
       "              RandomForest           0.025223   0.321972      0.607117  \n",
       "              Ridge                  0.024288   0.266022      0.582723  \n",
       "label_high_10 AdaBoost               0.408918 -13.813186      0.092629  \n",
       "              Bagging                0.049741  -0.108461      0.231632  \n",
       "              DecisionTreeRegressor  0.061110  -1.854325      0.104670  \n",
       "              GradientBoosting       0.045032   0.031977      0.281553  \n",
       "              LightGBM               0.044672   0.055023      0.285515  \n",
       "              LinearRegression       0.044815   0.076416      0.216658  \n",
       "              NeuralNetwork          0.054731  -0.407503      0.103992  \n",
       "              RandomForest           0.048766   0.035011      0.286244  \n",
       "              Ridge                  0.044813   0.076416      0.216656  \n",
       "label_high_20 AdaBoost               0.547722 -19.180045      0.009560  \n",
       "              Bagging                0.065380  -0.255868      0.245048  \n",
       "              DecisionTreeRegressor  0.074005  -2.412704      0.124359  \n",
       "              GradientBoosting       0.059053   0.003885      0.282070  \n",
       "              LightGBM               0.058706  -0.017958      0.280592  \n",
       "              LinearRegression       0.060103   0.052365      0.229728  \n",
       "              NeuralNetwork          0.065840  -0.521957      0.107441  \n",
       "              RandomForest           0.065117  -0.064236      0.290375  \n",
       "              Ridge                  0.060101   0.052372      0.229734  \n",
       "label_high_5  AdaBoost               0.205857  -4.427900      0.089399  \n",
       "              Bagging                0.041222  -0.017769      0.233531  \n",
       "              DecisionTreeRegressor  0.053015  -1.046539      0.114258  \n",
       "              GradientBoosting       0.037358   0.089160      0.281053  \n",
       "              LightGBM               0.037203   0.098165      0.296688  \n",
       "              LinearRegression       0.037277   0.061650      0.186100  \n",
       "              NeuralNetwork          0.040436  -0.157372      0.103417  \n",
       "              RandomForest           0.039366   0.088148      0.291807  \n",
       "              Ridge                  0.037274   0.061650      0.186101  \n",
       "label_low_10  AdaBoost               0.038198   0.014045      0.252602  \n",
       "              Bagging                0.040099  -0.022414      0.237511  \n",
       "              DecisionTreeRegressor  0.053530  -0.681043      0.112186  \n",
       "              GradientBoosting       0.037537   0.027315      0.306749  \n",
       "              LightGBM               0.037099   0.048419      0.319544  \n",
       "              LinearRegression       0.037519   0.003712      0.298701  \n",
       "              NeuralNetwork          0.039831  -0.023688      0.222281  \n",
       "              RandomForest           0.037649   0.050702      0.309306  \n",
       "              Ridge                  0.037519   0.003713      0.298701  \n",
       "label_low_20  AdaBoost               0.043295  -0.027033      0.266205  \n",
       "              Bagging                0.044873  -0.043450      0.244284  \n",
       "              DecisionTreeRegressor  0.059125  -0.636399      0.114935  \n",
       "              GradientBoosting       0.042254   0.003065      0.340903  \n",
       "              LightGBM               0.042107   0.029984      0.345673  \n",
       "              LinearRegression       0.043209  -0.026582      0.331691  \n",
       "              NeuralNetwork          0.043623  -0.006738      0.250649  \n",
       "              RandomForest           0.042107   0.019025      0.324515  \n",
       "              Ridge                  0.043214  -0.026585      0.331683  \n",
       "label_low_5   AdaBoost               0.034500   0.010857      0.230499  \n",
       "              Bagging                0.036591  -0.005375      0.225451  \n",
       "              DecisionTreeRegressor  0.049270  -0.671439      0.125558  \n",
       "              GradientBoosting       0.033953   0.053560      0.303306  \n",
       "              LightGBM               0.033761   0.070326      0.310753  \n",
       "              LinearRegression       0.034016   0.016543      0.263162  \n",
       "              NeuralNetwork          0.036028  -0.023422      0.202159  \n",
       "              RandomForest           0.033997   0.063808      0.302008  \n",
       "              Ridge                  0.034018   0.016547      0.263167  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Corr</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MedAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>SpearmanCorr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">center_10</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.478334</td>\n",
       "      <td>-0.018609</td>\n",
       "      <td>0.131317</td>\n",
       "      <td>0.022351</td>\n",
       "      <td>0.124837</td>\n",
       "      <td>-2.010599</td>\n",
       "      <td>-0.027991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.520083</td>\n",
       "      <td>0.090203</td>\n",
       "      <td>0.061900</td>\n",
       "      <td>0.008392</td>\n",
       "      <td>0.042218</td>\n",
       "      <td>-0.130367</td>\n",
       "      <td>0.081493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.510692</td>\n",
       "      <td>0.059255</td>\n",
       "      <td>0.085736</td>\n",
       "      <td>0.017572</td>\n",
       "      <td>0.057252</td>\n",
       "      <td>-1.366928</td>\n",
       "      <td>0.048949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.523846</td>\n",
       "      <td>0.095961</td>\n",
       "      <td>0.056892</td>\n",
       "      <td>0.007623</td>\n",
       "      <td>0.037574</td>\n",
       "      <td>-0.026755</td>\n",
       "      <td>0.117475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.523565</td>\n",
       "      <td>0.131547</td>\n",
       "      <td>0.057493</td>\n",
       "      <td>0.007502</td>\n",
       "      <td>0.038505</td>\n",
       "      <td>-0.010480</td>\n",
       "      <td>0.097976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.484630</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>0.057428</td>\n",
       "      <td>0.007762</td>\n",
       "      <td>0.038197</td>\n",
       "      <td>-0.045522</td>\n",
       "      <td>-0.017808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.497819</td>\n",
       "      <td>0.017389</td>\n",
       "      <td>0.062699</td>\n",
       "      <td>0.009266</td>\n",
       "      <td>0.041736</td>\n",
       "      <td>-0.248152</td>\n",
       "      <td>0.014831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.526801</td>\n",
       "      <td>0.129083</td>\n",
       "      <td>0.058123</td>\n",
       "      <td>0.007613</td>\n",
       "      <td>0.039285</td>\n",
       "      <td>-0.025474</td>\n",
       "      <td>0.115414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.484665</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.057428</td>\n",
       "      <td>0.007762</td>\n",
       "      <td>0.038196</td>\n",
       "      <td>-0.045512</td>\n",
       "      <td>-0.017801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">center_20</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.487584</td>\n",
       "      <td>0.074908</td>\n",
       "      <td>0.197171</td>\n",
       "      <td>0.057260</td>\n",
       "      <td>0.174910</td>\n",
       "      <td>-3.468416</td>\n",
       "      <td>0.040184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.504185</td>\n",
       "      <td>0.079143</td>\n",
       "      <td>0.082362</td>\n",
       "      <td>0.015610</td>\n",
       "      <td>0.055407</td>\n",
       "      <td>-0.218167</td>\n",
       "      <td>0.065939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.487479</td>\n",
       "      <td>0.028296</td>\n",
       "      <td>0.110585</td>\n",
       "      <td>0.034094</td>\n",
       "      <td>0.072657</td>\n",
       "      <td>-1.660590</td>\n",
       "      <td>0.002317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.501899</td>\n",
       "      <td>0.097456</td>\n",
       "      <td>0.075057</td>\n",
       "      <td>0.013457</td>\n",
       "      <td>0.049450</td>\n",
       "      <td>-0.050148</td>\n",
       "      <td>0.092979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.509778</td>\n",
       "      <td>0.124375</td>\n",
       "      <td>0.075819</td>\n",
       "      <td>0.013414</td>\n",
       "      <td>0.050081</td>\n",
       "      <td>-0.046832</td>\n",
       "      <td>0.091972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.484806</td>\n",
       "      <td>0.015151</td>\n",
       "      <td>0.075160</td>\n",
       "      <td>0.013422</td>\n",
       "      <td>0.050346</td>\n",
       "      <td>-0.047430</td>\n",
       "      <td>-0.010972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.490398</td>\n",
       "      <td>0.021702</td>\n",
       "      <td>0.094370</td>\n",
       "      <td>0.020238</td>\n",
       "      <td>0.064933</td>\n",
       "      <td>-0.579342</td>\n",
       "      <td>0.013965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.505381</td>\n",
       "      <td>0.117938</td>\n",
       "      <td>0.077196</td>\n",
       "      <td>0.013777</td>\n",
       "      <td>0.051989</td>\n",
       "      <td>-0.075133</td>\n",
       "      <td>0.099631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.484841</td>\n",
       "      <td>0.015186</td>\n",
       "      <td>0.075159</td>\n",
       "      <td>0.013422</td>\n",
       "      <td>0.050339</td>\n",
       "      <td>-0.047394</td>\n",
       "      <td>-0.010932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">center_5</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.460537</td>\n",
       "      <td>-0.003574</td>\n",
       "      <td>0.085981</td>\n",
       "      <td>0.010604</td>\n",
       "      <td>0.079301</td>\n",
       "      <td>-0.896244</td>\n",
       "      <td>-0.001081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.535031</td>\n",
       "      <td>0.117570</td>\n",
       "      <td>0.052278</td>\n",
       "      <td>0.006111</td>\n",
       "      <td>0.035404</td>\n",
       "      <td>-0.092857</td>\n",
       "      <td>0.113192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.506401</td>\n",
       "      <td>0.037868</td>\n",
       "      <td>0.072967</td>\n",
       "      <td>0.011416</td>\n",
       "      <td>0.050205</td>\n",
       "      <td>-1.041484</td>\n",
       "      <td>0.042347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.545371</td>\n",
       "      <td>0.139397</td>\n",
       "      <td>0.048161</td>\n",
       "      <td>0.005538</td>\n",
       "      <td>0.031251</td>\n",
       "      <td>0.009652</td>\n",
       "      <td>0.151832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.550577</td>\n",
       "      <td>0.174177</td>\n",
       "      <td>0.048482</td>\n",
       "      <td>0.005506</td>\n",
       "      <td>0.031594</td>\n",
       "      <td>0.015432</td>\n",
       "      <td>0.150301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.501161</td>\n",
       "      <td>0.013362</td>\n",
       "      <td>0.048790</td>\n",
       "      <td>0.005742</td>\n",
       "      <td>0.031423</td>\n",
       "      <td>-0.026917</td>\n",
       "      <td>0.022006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.517797</td>\n",
       "      <td>0.005810</td>\n",
       "      <td>0.052914</td>\n",
       "      <td>0.007550</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>-0.350227</td>\n",
       "      <td>0.029755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.545231</td>\n",
       "      <td>0.155331</td>\n",
       "      <td>0.049087</td>\n",
       "      <td>0.005586</td>\n",
       "      <td>0.032592</td>\n",
       "      <td>0.001081</td>\n",
       "      <td>0.147102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.501125</td>\n",
       "      <td>0.013375</td>\n",
       "      <td>0.048790</td>\n",
       "      <td>0.005742</td>\n",
       "      <td>0.031425</td>\n",
       "      <td>-0.026902</td>\n",
       "      <td>0.022017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">high_low_10</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.997819</td>\n",
       "      <td>0.297252</td>\n",
       "      <td>0.297183</td>\n",
       "      <td>0.102173</td>\n",
       "      <td>0.294551</td>\n",
       "      <td>-8.864832</td>\n",
       "      <td>0.313208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.997819</td>\n",
       "      <td>0.413359</td>\n",
       "      <td>0.058038</td>\n",
       "      <td>0.009637</td>\n",
       "      <td>0.037468</td>\n",
       "      <td>0.069561</td>\n",
       "      <td>0.510808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.997538</td>\n",
       "      <td>0.236098</td>\n",
       "      <td>0.078607</td>\n",
       "      <td>0.022978</td>\n",
       "      <td>0.043955</td>\n",
       "      <td>-1.218556</td>\n",
       "      <td>0.368528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.997819</td>\n",
       "      <td>0.457151</td>\n",
       "      <td>0.051773</td>\n",
       "      <td>0.008599</td>\n",
       "      <td>0.033226</td>\n",
       "      <td>0.169734</td>\n",
       "      <td>0.587221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.997819</td>\n",
       "      <td>0.480977</td>\n",
       "      <td>0.052337</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.033696</td>\n",
       "      <td>0.214496</td>\n",
       "      <td>0.567521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.997749</td>\n",
       "      <td>0.447606</td>\n",
       "      <td>0.052149</td>\n",
       "      <td>0.008430</td>\n",
       "      <td>0.033827</td>\n",
       "      <td>0.186119</td>\n",
       "      <td>0.536681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.991840</td>\n",
       "      <td>0.348159</td>\n",
       "      <td>0.060552</td>\n",
       "      <td>0.010966</td>\n",
       "      <td>0.036526</td>\n",
       "      <td>-0.058757</td>\n",
       "      <td>0.441758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.997819</td>\n",
       "      <td>0.481564</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.008261</td>\n",
       "      <td>0.036452</td>\n",
       "      <td>0.202381</td>\n",
       "      <td>0.569616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.997749</td>\n",
       "      <td>0.447615</td>\n",
       "      <td>0.052148</td>\n",
       "      <td>0.008430</td>\n",
       "      <td>0.033826</td>\n",
       "      <td>0.186131</td>\n",
       "      <td>0.536692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">high_low_20</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.991735</td>\n",
       "      <td>0.270569</td>\n",
       "      <td>0.380675</td>\n",
       "      <td>0.183563</td>\n",
       "      <td>0.353059</td>\n",
       "      <td>-6.232500</td>\n",
       "      <td>0.295399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.991735</td>\n",
       "      <td>0.325626</td>\n",
       "      <td>0.092074</td>\n",
       "      <td>0.025729</td>\n",
       "      <td>0.056461</td>\n",
       "      <td>-0.013724</td>\n",
       "      <td>0.440898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.991735</td>\n",
       "      <td>0.171144</td>\n",
       "      <td>0.118570</td>\n",
       "      <td>0.055549</td>\n",
       "      <td>0.065400</td>\n",
       "      <td>-1.188648</td>\n",
       "      <td>0.303937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.991735</td>\n",
       "      <td>0.345238</td>\n",
       "      <td>0.083003</td>\n",
       "      <td>0.024412</td>\n",
       "      <td>0.049887</td>\n",
       "      <td>0.038141</td>\n",
       "      <td>0.508551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.991735</td>\n",
       "      <td>0.370231</td>\n",
       "      <td>0.084171</td>\n",
       "      <td>0.023055</td>\n",
       "      <td>0.050663</td>\n",
       "      <td>0.091616</td>\n",
       "      <td>0.487113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.991664</td>\n",
       "      <td>0.367991</td>\n",
       "      <td>0.081610</td>\n",
       "      <td>0.022414</td>\n",
       "      <td>0.051466</td>\n",
       "      <td>0.116861</td>\n",
       "      <td>0.472462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.985017</td>\n",
       "      <td>0.255760</td>\n",
       "      <td>0.093917</td>\n",
       "      <td>0.029102</td>\n",
       "      <td>0.053591</td>\n",
       "      <td>-0.146641</td>\n",
       "      <td>0.362691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.991735</td>\n",
       "      <td>0.376705</td>\n",
       "      <td>0.086946</td>\n",
       "      <td>0.023243</td>\n",
       "      <td>0.054784</td>\n",
       "      <td>0.084194</td>\n",
       "      <td>0.487698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.991664</td>\n",
       "      <td>0.368006</td>\n",
       "      <td>0.081609</td>\n",
       "      <td>0.022414</td>\n",
       "      <td>0.051475</td>\n",
       "      <td>0.116876</td>\n",
       "      <td>0.472480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">high_low_5</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.997327</td>\n",
       "      <td>0.346770</td>\n",
       "      <td>0.156975</td>\n",
       "      <td>0.028636</td>\n",
       "      <td>0.153993</td>\n",
       "      <td>-4.033517</td>\n",
       "      <td>0.367377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.997327</td>\n",
       "      <td>0.460496</td>\n",
       "      <td>0.040782</td>\n",
       "      <td>0.004692</td>\n",
       "      <td>0.027529</td>\n",
       "      <td>0.175178</td>\n",
       "      <td>0.545088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.995076</td>\n",
       "      <td>0.263044</td>\n",
       "      <td>0.056999</td>\n",
       "      <td>0.010329</td>\n",
       "      <td>0.034060</td>\n",
       "      <td>-0.815535</td>\n",
       "      <td>0.368994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.997327</td>\n",
       "      <td>0.526772</td>\n",
       "      <td>0.036676</td>\n",
       "      <td>0.004130</td>\n",
       "      <td>0.024418</td>\n",
       "      <td>0.274102</td>\n",
       "      <td>0.614411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.997327</td>\n",
       "      <td>0.531082</td>\n",
       "      <td>0.037085</td>\n",
       "      <td>0.004099</td>\n",
       "      <td>0.024807</td>\n",
       "      <td>0.279427</td>\n",
       "      <td>0.604291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.997151</td>\n",
       "      <td>0.484786</td>\n",
       "      <td>0.037756</td>\n",
       "      <td>0.004414</td>\n",
       "      <td>0.025178</td>\n",
       "      <td>0.224096</td>\n",
       "      <td>0.566273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.994759</td>\n",
       "      <td>0.461581</td>\n",
       "      <td>0.039990</td>\n",
       "      <td>0.004719</td>\n",
       "      <td>0.026040</td>\n",
       "      <td>0.170455</td>\n",
       "      <td>0.546449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.997327</td>\n",
       "      <td>0.506526</td>\n",
       "      <td>0.038728</td>\n",
       "      <td>0.004283</td>\n",
       "      <td>0.026827</td>\n",
       "      <td>0.247095</td>\n",
       "      <td>0.595250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.997151</td>\n",
       "      <td>0.484799</td>\n",
       "      <td>0.037755</td>\n",
       "      <td>0.004414</td>\n",
       "      <td>0.025179</td>\n",
       "      <td>0.224109</td>\n",
       "      <td>0.566281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">label_high_10</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.779439</td>\n",
       "      <td>0.061282</td>\n",
       "      <td>0.381954</td>\n",
       "      <td>0.159306</td>\n",
       "      <td>0.398873</td>\n",
       "      <td>-10.218295</td>\n",
       "      <td>0.030216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.771103</td>\n",
       "      <td>0.194885</td>\n",
       "      <td>0.079023</td>\n",
       "      <td>0.016503</td>\n",
       "      <td>0.050876</td>\n",
       "      <td>-0.162169</td>\n",
       "      <td>0.190137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.646666</td>\n",
       "      <td>0.098609</td>\n",
       "      <td>0.109624</td>\n",
       "      <td>0.037095</td>\n",
       "      <td>0.064640</td>\n",
       "      <td>-1.612199</td>\n",
       "      <td>0.077939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.779228</td>\n",
       "      <td>0.236709</td>\n",
       "      <td>0.069794</td>\n",
       "      <td>0.013777</td>\n",
       "      <td>0.044770</td>\n",
       "      <td>0.029855</td>\n",
       "      <td>0.257074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.778243</td>\n",
       "      <td>0.269169</td>\n",
       "      <td>0.070171</td>\n",
       "      <td>0.013456</td>\n",
       "      <td>0.044353</td>\n",
       "      <td>0.052453</td>\n",
       "      <td>0.249099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.778665</td>\n",
       "      <td>0.185199</td>\n",
       "      <td>0.070445</td>\n",
       "      <td>0.013943</td>\n",
       "      <td>0.045580</td>\n",
       "      <td>0.018160</td>\n",
       "      <td>0.179212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.712753</td>\n",
       "      <td>0.108316</td>\n",
       "      <td>0.087986</td>\n",
       "      <td>0.019508</td>\n",
       "      <td>0.055530</td>\n",
       "      <td>-0.373744</td>\n",
       "      <td>0.082978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.779192</td>\n",
       "      <td>0.258860</td>\n",
       "      <td>0.072973</td>\n",
       "      <td>0.013997</td>\n",
       "      <td>0.048192</td>\n",
       "      <td>0.014319</td>\n",
       "      <td>0.252100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.778665</td>\n",
       "      <td>0.185212</td>\n",
       "      <td>0.070444</td>\n",
       "      <td>0.013943</td>\n",
       "      <td>0.045577</td>\n",
       "      <td>0.018171</td>\n",
       "      <td>0.179231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">label_high_20</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.815419</td>\n",
       "      <td>0.117124</td>\n",
       "      <td>0.545098</td>\n",
       "      <td>0.368266</td>\n",
       "      <td>0.559415</td>\n",
       "      <td>-12.466396</td>\n",
       "      <td>0.104557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.812570</td>\n",
       "      <td>0.195820</td>\n",
       "      <td>0.106065</td>\n",
       "      <td>0.032572</td>\n",
       "      <td>0.067394</td>\n",
       "      <td>-0.191077</td>\n",
       "      <td>0.208057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.691299</td>\n",
       "      <td>0.092262</td>\n",
       "      <td>0.143060</td>\n",
       "      <td>0.071397</td>\n",
       "      <td>0.081330</td>\n",
       "      <td>-1.610775</td>\n",
       "      <td>0.084727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.815384</td>\n",
       "      <td>0.203916</td>\n",
       "      <td>0.093441</td>\n",
       "      <td>0.029509</td>\n",
       "      <td>0.060109</td>\n",
       "      <td>-0.079054</td>\n",
       "      <td>0.284256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.815032</td>\n",
       "      <td>0.244074</td>\n",
       "      <td>0.094062</td>\n",
       "      <td>0.027364</td>\n",
       "      <td>0.059949</td>\n",
       "      <td>-0.000606</td>\n",
       "      <td>0.258291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.815314</td>\n",
       "      <td>0.207995</td>\n",
       "      <td>0.092055</td>\n",
       "      <td>0.026440</td>\n",
       "      <td>0.062671</td>\n",
       "      <td>0.033155</td>\n",
       "      <td>0.221539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.768676</td>\n",
       "      <td>0.103317</td>\n",
       "      <td>0.110356</td>\n",
       "      <td>0.037319</td>\n",
       "      <td>0.068177</td>\n",
       "      <td>-0.364645</td>\n",
       "      <td>0.101254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.815490</td>\n",
       "      <td>0.251876</td>\n",
       "      <td>0.098735</td>\n",
       "      <td>0.028045</td>\n",
       "      <td>0.065801</td>\n",
       "      <td>-0.025531</td>\n",
       "      <td>0.274139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.815314</td>\n",
       "      <td>0.208039</td>\n",
       "      <td>0.092054</td>\n",
       "      <td>0.026439</td>\n",
       "      <td>0.062674</td>\n",
       "      <td>0.033188</td>\n",
       "      <td>0.221573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">label_high_5</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.734700</td>\n",
       "      <td>0.092733</td>\n",
       "      <td>0.192856</td>\n",
       "      <td>0.043362</td>\n",
       "      <td>0.199650</td>\n",
       "      <td>-3.532514</td>\n",
       "      <td>0.032827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.711557</td>\n",
       "      <td>0.191896</td>\n",
       "      <td>0.062644</td>\n",
       "      <td>0.010009</td>\n",
       "      <td>0.040494</td>\n",
       "      <td>-0.046169</td>\n",
       "      <td>0.165691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.597918</td>\n",
       "      <td>0.089446</td>\n",
       "      <td>0.086861</td>\n",
       "      <td>0.019462</td>\n",
       "      <td>0.053605</td>\n",
       "      <td>-1.034316</td>\n",
       "      <td>0.080623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.733821</td>\n",
       "      <td>0.241204</td>\n",
       "      <td>0.056852</td>\n",
       "      <td>0.009068</td>\n",
       "      <td>0.035396</td>\n",
       "      <td>0.052199</td>\n",
       "      <td>0.246830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.730972</td>\n",
       "      <td>0.271305</td>\n",
       "      <td>0.056939</td>\n",
       "      <td>0.008917</td>\n",
       "      <td>0.035183</td>\n",
       "      <td>0.067889</td>\n",
       "      <td>0.233647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.732942</td>\n",
       "      <td>0.175027</td>\n",
       "      <td>0.057870</td>\n",
       "      <td>0.009343</td>\n",
       "      <td>0.036327</td>\n",
       "      <td>0.023363</td>\n",
       "      <td>0.155636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.664638</td>\n",
       "      <td>0.088963</td>\n",
       "      <td>0.065253</td>\n",
       "      <td>0.011528</td>\n",
       "      <td>0.040325</td>\n",
       "      <td>-0.204936</td>\n",
       "      <td>0.080216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.732907</td>\n",
       "      <td>0.254974</td>\n",
       "      <td>0.058617</td>\n",
       "      <td>0.009080</td>\n",
       "      <td>0.037669</td>\n",
       "      <td>0.050942</td>\n",
       "      <td>0.235183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.732942</td>\n",
       "      <td>0.175053</td>\n",
       "      <td>0.057869</td>\n",
       "      <td>0.009343</td>\n",
       "      <td>0.036328</td>\n",
       "      <td>0.023380</td>\n",
       "      <td>0.155651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">label_low_10</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.839125</td>\n",
       "      <td>0.209199</td>\n",
       "      <td>0.052645</td>\n",
       "      <td>0.005638</td>\n",
       "      <td>0.036069</td>\n",
       "      <td>0.032245</td>\n",
       "      <td>0.194094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.825936</td>\n",
       "      <td>0.167936</td>\n",
       "      <td>0.055790</td>\n",
       "      <td>0.006172</td>\n",
       "      <td>0.039570</td>\n",
       "      <td>-0.059369</td>\n",
       "      <td>0.171865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.721405</td>\n",
       "      <td>0.106890</td>\n",
       "      <td>0.072969</td>\n",
       "      <td>0.010169</td>\n",
       "      <td>0.053115</td>\n",
       "      <td>-0.745397</td>\n",
       "      <td>0.108881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.838738</td>\n",
       "      <td>0.235674</td>\n",
       "      <td>0.052217</td>\n",
       "      <td>0.005591</td>\n",
       "      <td>0.035800</td>\n",
       "      <td>0.040291</td>\n",
       "      <td>0.227156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.838668</td>\n",
       "      <td>0.230371</td>\n",
       "      <td>0.052891</td>\n",
       "      <td>0.005663</td>\n",
       "      <td>0.036842</td>\n",
       "      <td>0.027977</td>\n",
       "      <td>0.226664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.838386</td>\n",
       "      <td>0.186979</td>\n",
       "      <td>0.052660</td>\n",
       "      <td>0.005796</td>\n",
       "      <td>0.035226</td>\n",
       "      <td>0.005158</td>\n",
       "      <td>0.189099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.831669</td>\n",
       "      <td>0.154839</td>\n",
       "      <td>0.056572</td>\n",
       "      <td>0.006546</td>\n",
       "      <td>0.040424</td>\n",
       "      <td>-0.123588</td>\n",
       "      <td>0.163965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.837929</td>\n",
       "      <td>0.222782</td>\n",
       "      <td>0.052983</td>\n",
       "      <td>0.005667</td>\n",
       "      <td>0.037021</td>\n",
       "      <td>0.027309</td>\n",
       "      <td>0.222156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.838386</td>\n",
       "      <td>0.186989</td>\n",
       "      <td>0.052659</td>\n",
       "      <td>0.005796</td>\n",
       "      <td>0.035231</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>0.189107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">label_low_20</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.861635</td>\n",
       "      <td>0.136632</td>\n",
       "      <td>0.070669</td>\n",
       "      <td>0.011431</td>\n",
       "      <td>0.043725</td>\n",
       "      <td>-0.041823</td>\n",
       "      <td>0.133656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.852947</td>\n",
       "      <td>0.097892</td>\n",
       "      <td>0.073458</td>\n",
       "      <td>0.012051</td>\n",
       "      <td>0.047095</td>\n",
       "      <td>-0.098338</td>\n",
       "      <td>0.115693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.744654</td>\n",
       "      <td>0.050631</td>\n",
       "      <td>0.092057</td>\n",
       "      <td>0.016842</td>\n",
       "      <td>0.064200</td>\n",
       "      <td>-0.535023</td>\n",
       "      <td>0.060033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.861459</td>\n",
       "      <td>0.134859</td>\n",
       "      <td>0.070425</td>\n",
       "      <td>0.011492</td>\n",
       "      <td>0.043452</td>\n",
       "      <td>-0.047391</td>\n",
       "      <td>0.144092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.860791</td>\n",
       "      <td>0.131478</td>\n",
       "      <td>0.071171</td>\n",
       "      <td>0.011551</td>\n",
       "      <td>0.044744</td>\n",
       "      <td>-0.052812</td>\n",
       "      <td>0.146309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.861248</td>\n",
       "      <td>0.128364</td>\n",
       "      <td>0.070724</td>\n",
       "      <td>0.011611</td>\n",
       "      <td>0.043049</td>\n",
       "      <td>-0.058265</td>\n",
       "      <td>0.135610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.858434</td>\n",
       "      <td>0.089398</td>\n",
       "      <td>0.073816</td>\n",
       "      <td>0.012785</td>\n",
       "      <td>0.048188</td>\n",
       "      <td>-0.165263</td>\n",
       "      <td>0.112928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.860755</td>\n",
       "      <td>0.123695</td>\n",
       "      <td>0.071145</td>\n",
       "      <td>0.011534</td>\n",
       "      <td>0.044926</td>\n",
       "      <td>-0.051225</td>\n",
       "      <td>0.145896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.861248</td>\n",
       "      <td>0.128389</td>\n",
       "      <td>0.070723</td>\n",
       "      <td>0.011611</td>\n",
       "      <td>0.043047</td>\n",
       "      <td>-0.058244</td>\n",
       "      <td>0.135623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">label_low_5</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.809757</td>\n",
       "      <td>0.203575</td>\n",
       "      <td>0.045896</td>\n",
       "      <td>0.004297</td>\n",
       "      <td>0.031621</td>\n",
       "      <td>0.036864</td>\n",
       "      <td>0.196345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.792945</td>\n",
       "      <td>0.195619</td>\n",
       "      <td>0.048573</td>\n",
       "      <td>0.004674</td>\n",
       "      <td>0.034573</td>\n",
       "      <td>-0.047650</td>\n",
       "      <td>0.201043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.685777</td>\n",
       "      <td>0.080108</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.009258</td>\n",
       "      <td>0.049495</td>\n",
       "      <td>-1.075137</td>\n",
       "      <td>0.093706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.809370</td>\n",
       "      <td>0.261767</td>\n",
       "      <td>0.045258</td>\n",
       "      <td>0.004183</td>\n",
       "      <td>0.031618</td>\n",
       "      <td>0.062387</td>\n",
       "      <td>0.263141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.809159</td>\n",
       "      <td>0.262591</td>\n",
       "      <td>0.045797</td>\n",
       "      <td>0.004240</td>\n",
       "      <td>0.032450</td>\n",
       "      <td>0.049681</td>\n",
       "      <td>0.260743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.809018</td>\n",
       "      <td>0.204451</td>\n",
       "      <td>0.045656</td>\n",
       "      <td>0.004349</td>\n",
       "      <td>0.030967</td>\n",
       "      <td>0.025303</td>\n",
       "      <td>0.209576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.799733</td>\n",
       "      <td>0.150892</td>\n",
       "      <td>0.048196</td>\n",
       "      <td>0.004880</td>\n",
       "      <td>0.033340</td>\n",
       "      <td>-0.093742</td>\n",
       "      <td>0.176873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.807295</td>\n",
       "      <td>0.250070</td>\n",
       "      <td>0.045948</td>\n",
       "      <td>0.004263</td>\n",
       "      <td>0.032554</td>\n",
       "      <td>0.044544</td>\n",
       "      <td>0.252709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.809018</td>\n",
       "      <td>0.204461</td>\n",
       "      <td>0.045655</td>\n",
       "      <td>0.004349</td>\n",
       "      <td>0.030968</td>\n",
       "      <td>0.025313</td>\n",
       "      <td>0.209583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Accuracy      Corr       MAE       MSE  \\\n",
       "center_10     AdaBoost               0.478334 -0.018609  0.131317  0.022351   \n",
       "              Bagging                0.520083  0.090203  0.061900  0.008392   \n",
       "              DecisionTreeRegressor  0.510692  0.059255  0.085736  0.017572   \n",
       "              GradientBoosting       0.523846  0.095961  0.056892  0.007623   \n",
       "              LightGBM               0.523565  0.131547  0.057493  0.007502   \n",
       "              LinearRegression       0.484630  0.000766  0.057428  0.007762   \n",
       "              NeuralNetwork          0.497819  0.017389  0.062699  0.009266   \n",
       "              RandomForest           0.526801  0.129083  0.058123  0.007613   \n",
       "              Ridge                  0.484665  0.000775  0.057428  0.007762   \n",
       "center_20     AdaBoost               0.487584  0.074908  0.197171  0.057260   \n",
       "              Bagging                0.504185  0.079143  0.082362  0.015610   \n",
       "              DecisionTreeRegressor  0.487479  0.028296  0.110585  0.034094   \n",
       "              GradientBoosting       0.501899  0.097456  0.075057  0.013457   \n",
       "              LightGBM               0.509778  0.124375  0.075819  0.013414   \n",
       "              LinearRegression       0.484806  0.015151  0.075160  0.013422   \n",
       "              NeuralNetwork          0.490398  0.021702  0.094370  0.020238   \n",
       "              RandomForest           0.505381  0.117938  0.077196  0.013777   \n",
       "              Ridge                  0.484841  0.015186  0.075159  0.013422   \n",
       "center_5      AdaBoost               0.460537 -0.003574  0.085981  0.010604   \n",
       "              Bagging                0.535031  0.117570  0.052278  0.006111   \n",
       "              DecisionTreeRegressor  0.506401  0.037868  0.072967  0.011416   \n",
       "              GradientBoosting       0.545371  0.139397  0.048161  0.005538   \n",
       "              LightGBM               0.550577  0.174177  0.048482  0.005506   \n",
       "              LinearRegression       0.501161  0.013362  0.048790  0.005742   \n",
       "              NeuralNetwork          0.517797  0.005810  0.052914  0.007550   \n",
       "              RandomForest           0.545231  0.155331  0.049087  0.005586   \n",
       "              Ridge                  0.501125  0.013375  0.048790  0.005742   \n",
       "high_low_10   AdaBoost               0.997819  0.297252  0.297183  0.102173   \n",
       "              Bagging                0.997819  0.413359  0.058038  0.009637   \n",
       "              DecisionTreeRegressor  0.997538  0.236098  0.078607  0.022978   \n",
       "              GradientBoosting       0.997819  0.457151  0.051773  0.008599   \n",
       "              LightGBM               0.997819  0.480977  0.052337  0.008136   \n",
       "              LinearRegression       0.997749  0.447606  0.052149  0.008430   \n",
       "              NeuralNetwork          0.991840  0.348159  0.060552  0.010966   \n",
       "              RandomForest           0.997819  0.481564  0.054054  0.008261   \n",
       "              Ridge                  0.997749  0.447615  0.052148  0.008430   \n",
       "high_low_20   AdaBoost               0.991735  0.270569  0.380675  0.183563   \n",
       "              Bagging                0.991735  0.325626  0.092074  0.025729   \n",
       "              DecisionTreeRegressor  0.991735  0.171144  0.118570  0.055549   \n",
       "              GradientBoosting       0.991735  0.345238  0.083003  0.024412   \n",
       "              LightGBM               0.991735  0.370231  0.084171  0.023055   \n",
       "              LinearRegression       0.991664  0.367991  0.081610  0.022414   \n",
       "              NeuralNetwork          0.985017  0.255760  0.093917  0.029102   \n",
       "              RandomForest           0.991735  0.376705  0.086946  0.023243   \n",
       "              Ridge                  0.991664  0.368006  0.081609  0.022414   \n",
       "high_low_5    AdaBoost               0.997327  0.346770  0.156975  0.028636   \n",
       "              Bagging                0.997327  0.460496  0.040782  0.004692   \n",
       "              DecisionTreeRegressor  0.995076  0.263044  0.056999  0.010329   \n",
       "              GradientBoosting       0.997327  0.526772  0.036676  0.004130   \n",
       "              LightGBM               0.997327  0.531082  0.037085  0.004099   \n",
       "              LinearRegression       0.997151  0.484786  0.037756  0.004414   \n",
       "              NeuralNetwork          0.994759  0.461581  0.039990  0.004719   \n",
       "              RandomForest           0.997327  0.506526  0.038728  0.004283   \n",
       "              Ridge                  0.997151  0.484799  0.037755  0.004414   \n",
       "label_high_10 AdaBoost               0.779439  0.061282  0.381954  0.159306   \n",
       "              Bagging                0.771103  0.194885  0.079023  0.016503   \n",
       "              DecisionTreeRegressor  0.646666  0.098609  0.109624  0.037095   \n",
       "              GradientBoosting       0.779228  0.236709  0.069794  0.013777   \n",
       "              LightGBM               0.778243  0.269169  0.070171  0.013456   \n",
       "              LinearRegression       0.778665  0.185199  0.070445  0.013943   \n",
       "              NeuralNetwork          0.712753  0.108316  0.087986  0.019508   \n",
       "              RandomForest           0.779192  0.258860  0.072973  0.013997   \n",
       "              Ridge                  0.778665  0.185212  0.070444  0.013943   \n",
       "label_high_20 AdaBoost               0.815419  0.117124  0.545098  0.368266   \n",
       "              Bagging                0.812570  0.195820  0.106065  0.032572   \n",
       "              DecisionTreeRegressor  0.691299  0.092262  0.143060  0.071397   \n",
       "              GradientBoosting       0.815384  0.203916  0.093441  0.029509   \n",
       "              LightGBM               0.815032  0.244074  0.094062  0.027364   \n",
       "              LinearRegression       0.815314  0.207995  0.092055  0.026440   \n",
       "              NeuralNetwork          0.768676  0.103317  0.110356  0.037319   \n",
       "              RandomForest           0.815490  0.251876  0.098735  0.028045   \n",
       "              Ridge                  0.815314  0.208039  0.092054  0.026439   \n",
       "label_high_5  AdaBoost               0.734700  0.092733  0.192856  0.043362   \n",
       "              Bagging                0.711557  0.191896  0.062644  0.010009   \n",
       "              DecisionTreeRegressor  0.597918  0.089446  0.086861  0.019462   \n",
       "              GradientBoosting       0.733821  0.241204  0.056852  0.009068   \n",
       "              LightGBM               0.730972  0.271305  0.056939  0.008917   \n",
       "              LinearRegression       0.732942  0.175027  0.057870  0.009343   \n",
       "              NeuralNetwork          0.664638  0.088963  0.065253  0.011528   \n",
       "              RandomForest           0.732907  0.254974  0.058617  0.009080   \n",
       "              Ridge                  0.732942  0.175053  0.057869  0.009343   \n",
       "label_low_10  AdaBoost               0.839125  0.209199  0.052645  0.005638   \n",
       "              Bagging                0.825936  0.167936  0.055790  0.006172   \n",
       "              DecisionTreeRegressor  0.721405  0.106890  0.072969  0.010169   \n",
       "              GradientBoosting       0.838738  0.235674  0.052217  0.005591   \n",
       "              LightGBM               0.838668  0.230371  0.052891  0.005663   \n",
       "              LinearRegression       0.838386  0.186979  0.052660  0.005796   \n",
       "              NeuralNetwork          0.831669  0.154839  0.056572  0.006546   \n",
       "              RandomForest           0.837929  0.222782  0.052983  0.005667   \n",
       "              Ridge                  0.838386  0.186989  0.052659  0.005796   \n",
       "label_low_20  AdaBoost               0.861635  0.136632  0.070669  0.011431   \n",
       "              Bagging                0.852947  0.097892  0.073458  0.012051   \n",
       "              DecisionTreeRegressor  0.744654  0.050631  0.092057  0.016842   \n",
       "              GradientBoosting       0.861459  0.134859  0.070425  0.011492   \n",
       "              LightGBM               0.860791  0.131478  0.071171  0.011551   \n",
       "              LinearRegression       0.861248  0.128364  0.070724  0.011611   \n",
       "              NeuralNetwork          0.858434  0.089398  0.073816  0.012785   \n",
       "              RandomForest           0.860755  0.123695  0.071145  0.011534   \n",
       "              Ridge                  0.861248  0.128389  0.070723  0.011611   \n",
       "label_low_5   AdaBoost               0.809757  0.203575  0.045896  0.004297   \n",
       "              Bagging                0.792945  0.195619  0.048573  0.004674   \n",
       "              DecisionTreeRegressor  0.685777  0.080108  0.068966  0.009258   \n",
       "              GradientBoosting       0.809370  0.261767  0.045258  0.004183   \n",
       "              LightGBM               0.809159  0.262591  0.045797  0.004240   \n",
       "              LinearRegression       0.809018  0.204451  0.045656  0.004349   \n",
       "              NeuralNetwork          0.799733  0.150892  0.048196  0.004880   \n",
       "              RandomForest           0.807295  0.250070  0.045948  0.004263   \n",
       "              Ridge                  0.809018  0.204461  0.045655  0.004349   \n",
       "\n",
       "                                        MedAE         R2  SpearmanCorr  \n",
       "center_10     AdaBoost               0.124837  -2.010599     -0.027991  \n",
       "              Bagging                0.042218  -0.130367      0.081493  \n",
       "              DecisionTreeRegressor  0.057252  -1.366928      0.048949  \n",
       "              GradientBoosting       0.037574  -0.026755      0.117475  \n",
       "              LightGBM               0.038505  -0.010480      0.097976  \n",
       "              LinearRegression       0.038197  -0.045522     -0.017808  \n",
       "              NeuralNetwork          0.041736  -0.248152      0.014831  \n",
       "              RandomForest           0.039285  -0.025474      0.115414  \n",
       "              Ridge                  0.038196  -0.045512     -0.017801  \n",
       "center_20     AdaBoost               0.174910  -3.468416      0.040184  \n",
       "              Bagging                0.055407  -0.218167      0.065939  \n",
       "              DecisionTreeRegressor  0.072657  -1.660590      0.002317  \n",
       "              GradientBoosting       0.049450  -0.050148      0.092979  \n",
       "              LightGBM               0.050081  -0.046832      0.091972  \n",
       "              LinearRegression       0.050346  -0.047430     -0.010972  \n",
       "              NeuralNetwork          0.064933  -0.579342      0.013965  \n",
       "              RandomForest           0.051989  -0.075133      0.099631  \n",
       "              Ridge                  0.050339  -0.047394     -0.010932  \n",
       "center_5      AdaBoost               0.079301  -0.896244     -0.001081  \n",
       "              Bagging                0.035404  -0.092857      0.113192  \n",
       "              DecisionTreeRegressor  0.050205  -1.041484      0.042347  \n",
       "              GradientBoosting       0.031251   0.009652      0.151832  \n",
       "              LightGBM               0.031594   0.015432      0.150301  \n",
       "              LinearRegression       0.031423  -0.026917      0.022006  \n",
       "              NeuralNetwork          0.034188  -0.350227      0.029755  \n",
       "              RandomForest           0.032592   0.001081      0.147102  \n",
       "              Ridge                  0.031425  -0.026902      0.022017  \n",
       "high_low_10   AdaBoost               0.294551  -8.864832      0.313208  \n",
       "              Bagging                0.037468   0.069561      0.510808  \n",
       "              DecisionTreeRegressor  0.043955  -1.218556      0.368528  \n",
       "              GradientBoosting       0.033226   0.169734      0.587221  \n",
       "              LightGBM               0.033696   0.214496      0.567521  \n",
       "              LinearRegression       0.033827   0.186119      0.536681  \n",
       "              NeuralNetwork          0.036526  -0.058757      0.441758  \n",
       "              RandomForest           0.036452   0.202381      0.569616  \n",
       "              Ridge                  0.033826   0.186131      0.536692  \n",
       "high_low_20   AdaBoost               0.353059  -6.232500      0.295399  \n",
       "              Bagging                0.056461  -0.013724      0.440898  \n",
       "              DecisionTreeRegressor  0.065400  -1.188648      0.303937  \n",
       "              GradientBoosting       0.049887   0.038141      0.508551  \n",
       "              LightGBM               0.050663   0.091616      0.487113  \n",
       "              LinearRegression       0.051466   0.116861      0.472462  \n",
       "              NeuralNetwork          0.053591  -0.146641      0.362691  \n",
       "              RandomForest           0.054784   0.084194      0.487698  \n",
       "              Ridge                  0.051475   0.116876      0.472480  \n",
       "high_low_5    AdaBoost               0.153993  -4.033517      0.367377  \n",
       "              Bagging                0.027529   0.175178      0.545088  \n",
       "              DecisionTreeRegressor  0.034060  -0.815535      0.368994  \n",
       "              GradientBoosting       0.024418   0.274102      0.614411  \n",
       "              LightGBM               0.024807   0.279427      0.604291  \n",
       "              LinearRegression       0.025178   0.224096      0.566273  \n",
       "              NeuralNetwork          0.026040   0.170455      0.546449  \n",
       "              RandomForest           0.026827   0.247095      0.595250  \n",
       "              Ridge                  0.025179   0.224109      0.566281  \n",
       "label_high_10 AdaBoost               0.398873 -10.218295      0.030216  \n",
       "              Bagging                0.050876  -0.162169      0.190137  \n",
       "              DecisionTreeRegressor  0.064640  -1.612199      0.077939  \n",
       "              GradientBoosting       0.044770   0.029855      0.257074  \n",
       "              LightGBM               0.044353   0.052453      0.249099  \n",
       "              LinearRegression       0.045580   0.018160      0.179212  \n",
       "              NeuralNetwork          0.055530  -0.373744      0.082978  \n",
       "              RandomForest           0.048192   0.014319      0.252100  \n",
       "              Ridge                  0.045577   0.018171      0.179231  \n",
       "label_high_20 AdaBoost               0.559415 -12.466396      0.104557  \n",
       "              Bagging                0.067394  -0.191077      0.208057  \n",
       "              DecisionTreeRegressor  0.081330  -1.610775      0.084727  \n",
       "              GradientBoosting       0.060109  -0.079054      0.284256  \n",
       "              LightGBM               0.059949  -0.000606      0.258291  \n",
       "              LinearRegression       0.062671   0.033155      0.221539  \n",
       "              NeuralNetwork          0.068177  -0.364645      0.101254  \n",
       "              RandomForest           0.065801  -0.025531      0.274139  \n",
       "              Ridge                  0.062674   0.033188      0.221573  \n",
       "label_high_5  AdaBoost               0.199650  -3.532514      0.032827  \n",
       "              Bagging                0.040494  -0.046169      0.165691  \n",
       "              DecisionTreeRegressor  0.053605  -1.034316      0.080623  \n",
       "              GradientBoosting       0.035396   0.052199      0.246830  \n",
       "              LightGBM               0.035183   0.067889      0.233647  \n",
       "              LinearRegression       0.036327   0.023363      0.155636  \n",
       "              NeuralNetwork          0.040325  -0.204936      0.080216  \n",
       "              RandomForest           0.037669   0.050942      0.235183  \n",
       "              Ridge                  0.036328   0.023380      0.155651  \n",
       "label_low_10  AdaBoost               0.036069   0.032245      0.194094  \n",
       "              Bagging                0.039570  -0.059369      0.171865  \n",
       "              DecisionTreeRegressor  0.053115  -0.745397      0.108881  \n",
       "              GradientBoosting       0.035800   0.040291      0.227156  \n",
       "              LightGBM               0.036842   0.027977      0.226664  \n",
       "              LinearRegression       0.035226   0.005158      0.189099  \n",
       "              NeuralNetwork          0.040424  -0.123588      0.163965  \n",
       "              RandomForest           0.037021   0.027309      0.222156  \n",
       "              Ridge                  0.035231   0.005168      0.189107  \n",
       "label_low_20  AdaBoost               0.043725  -0.041823      0.133656  \n",
       "              Bagging                0.047095  -0.098338      0.115693  \n",
       "              DecisionTreeRegressor  0.064200  -0.535023      0.060033  \n",
       "              GradientBoosting       0.043452  -0.047391      0.144092  \n",
       "              LightGBM               0.044744  -0.052812      0.146309  \n",
       "              LinearRegression       0.043049  -0.058265      0.135610  \n",
       "              NeuralNetwork          0.048188  -0.165263      0.112928  \n",
       "              RandomForest           0.044926  -0.051225      0.145896  \n",
       "              Ridge                  0.043047  -0.058244      0.135623  \n",
       "label_low_5   AdaBoost               0.031621   0.036864      0.196345  \n",
       "              Bagging                0.034573  -0.047650      0.201043  \n",
       "              DecisionTreeRegressor  0.049495  -1.075137      0.093706  \n",
       "              GradientBoosting       0.031618   0.062387      0.263141  \n",
       "              LightGBM               0.032450   0.049681      0.260743  \n",
       "              LinearRegression       0.030967   0.025303      0.209576  \n",
       "              NeuralNetwork          0.033340  -0.093742      0.176873  \n",
       "              RandomForest           0.032554   0.044544      0.252709  \n",
       "              Ridge                  0.030968   0.025313      0.209583  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 説明変数の重要度\n",
    "RandomForest, GradientBoosting\tが特にスコアが高い為、この二つを確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'label_low_20')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 学習済みモデルを指定\n",
    "save_path = os.path.join(save_dir, 'RandomForest_label_high_20.pickle')\n",
    "with open(save_path, mode='rb') as fp:\n",
    "    rf = pickle.load(fp)\n",
    "\n",
    "# 重要度順を取得\n",
    "sorted_idx = rf.feature_importances_.argsort()\n",
    "# プロット\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "ax = fig.add_subplot(2, 2, 1)\n",
    "ax.barh(train_XY.columns.drop(Y_cols)[sorted_idx], rf.feature_importances_[sorted_idx])\n",
    "ax.set_xlabel(\"Random Forest Feature Importance\")\n",
    "plt.title('label_high_20')\n",
    "\n",
    "# 学習済みモデルを指定\n",
    "save_path = os.path.join(save_dir, 'RandomForest_label_low_20.pickle')\n",
    "with open(save_path, mode='rb') as fp:\n",
    "    rf = pickle.load(fp)\n",
    "\n",
    "# 重要度順を取得\n",
    "sorted_idx = rf.feature_importances_.argsort()\n",
    "ax = fig.add_subplot(2, 2, 2)\n",
    "ax.barh(train_XY.columns.drop(Y_cols)[sorted_idx], rf.feature_importances_[sorted_idx])\n",
    "ax.set_xlabel(\"Random Forest Feature Importance\")\n",
    "plt.title('label_low_20')\n",
    "\n",
    "# 学習済みモデルを指定\n",
    "save_path = os.path.join(save_dir, 'GradientBoosting_label_high_20.pickle')\n",
    "with open(save_path, mode='rb') as fp:\n",
    "    rf = pickle.load(fp)\n",
    "\n",
    "# 重要度順を取得\n",
    "sorted_idx = rf.feature_importances_.argsort()\n",
    "# プロット\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "ax = fig.add_subplot(2, 2, 3)\n",
    "ax.barh(train_XY.columns.drop(Y_cols)[sorted_idx], rf.feature_importances_[sorted_idx])\n",
    "ax.set_xlabel(\"GradientBoosting Importance\")\n",
    "plt.title('label_high_20')\n",
    "\n",
    "# 学習済みモデルを指定\n",
    "save_path = os.path.join(save_dir, 'GradientBoosting_label_low_20.pickle')\n",
    "with open(save_path, mode='rb') as fp:\n",
    "    rf = pickle.load(fp)\n",
    "\n",
    "# 重要度順を取得\n",
    "sorted_idx = rf.feature_importances_.argsort()\n",
    "ax = fig.add_subplot(2, 2, 4)\n",
    "ax.barh(train_XY.columns.drop(Y_cols)[sorted_idx], rf.feature_importances_[sorted_idx])\n",
    "ax.set_xlabel(\"GradientBoosting Feature Importance\")\n",
    "plt.title('label_low_20')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<メモ>\n",
    "* ボラティリティは重要度がかなり高い  \n",
    "  ⇒期間が長いものを追加してもよいかも  \n",
    "* キリ番(RNDR)が効いているのは新たな発見\n",
    "* 売買高との関係を見てみる\n",
    "* CF系はあまり効果がない ⇒ one-hotベクトルか\n",
    "* 配当利回りは割と効いている\n",
    "* ヒストリカルボラティリティの推移に関する変数を追加  \n",
    "  ⇒単純に移動平均？平均ボラティリティというものがあるらしい。値幅(高値ー安値)の平均で算出することもあり。  \n",
    "* ~~一日の変動(終値-始値)に関する指標を追加~~ ← 変化率で表現できてそう\n",
    "* 曜日、業種に関するone-hotベクトル\n",
    "* 来期予測系もかなり効いている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
